{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SP Conference-Hetero.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2qSNYEZJvXo",
        "cellView": "form"
      },
      "source": [
        "#@title PyG Installation { form-width: \"25%\" }\n",
        "# enter these commands in CLI to install Pytorch-Geometric\n",
        "!pip install -q torch-scatter -f https://pytorch-geometric.com/whl/torch-1.9.0+cu111.html\n",
        "!pip install -q torch-sparse -f https://pytorch-geometric.com/whl/torch-1.9.0+cu111.html\n",
        "!pip install -q git+https://github.com/rusty1s/pytorch_geometric.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQ7zuNoJKXec",
        "cellView": "form"
      },
      "source": [
        "#@title Module Imports { form-width: \"20%\" }\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.nn import Module,\\\n",
        "                     ModuleList,\\\n",
        "                     Embedding,\\\n",
        "                     BatchNorm1d,\\\n",
        "                     LogSoftmax,\\\n",
        "                     Softmax,\\\n",
        "                     Linear,\\\n",
        "                     NLLLoss,\\\n",
        "                     CrossEntropyLoss\n",
        "from torch.optim import Adam\n",
        "import torch.nn.functional as F\n",
        "import torch_geometric as PyG\n",
        "from torch_geometric.data import Data, HeteroData\n",
        "from torch_geometric.nn.conv import RGCNConv, GINConv, GATConv, HeteroConv, GCNConv\n",
        "from torch_geometric.utils import to_networkx\n",
        "from collections import OrderedDict as od\n",
        "import logging\n",
        "import json\n",
        "from typing import NoReturn\n",
        "import typing\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnJRJ5pTW_rR",
        "cellView": "form",
        "outputId": "5214e682-f451-4220-8c92-c70d8c8bc5f3"
      },
      "source": [
        "#@title Global Variables\n",
        "# Global Values\n",
        "WON = 0\n",
        "LOST_TO = 1\n",
        "TIED_WITH = 2\n",
        "PLAYED_IN = 3\n",
        "USED = 4\n",
        "BEFORE = 5\n",
        "AFTER = 6\n",
        "\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'Device is {DEVICE}')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device is cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mH-QslHEJdRg",
        "cellView": "form"
      },
      "source": [
        "#@title GNN Model { form-width: \"10%\" }\n",
        "class GNN(Module):\n",
        "  def __init__(self, embedding_dims: tuple, conv_dims: list, fully_connected_dims: list, dropout: dict)-> NoReturn:\n",
        "    super(GNN, self).__init__()\n",
        "\n",
        "    self.mode = None # 'train' or 'test' or 'dev' later \n",
        "    self.output_dim = 3 #home_result: win, lose, tie\n",
        "    self.num_relations = 7 #win/lose/tie/play/use/after/before\n",
        "    self.dropout = dropout\n",
        "\n",
        "    #one-hot to latent\n",
        "    self.embed = Embedding(embedding_dims[0], embedding_dims[1])\n",
        "\n",
        "    conv_list = [\n",
        "                  RGCNConv(embedding_dims[1], conv_dims[0], self.num_relations)\n",
        "                ] + \\\n",
        "                [\n",
        "                  RGCNConv(conv_dims[i], conv_dims[i+1], self.num_relations)\n",
        "                  for i in range(len(conv_dims[:-1]))\n",
        "                ]\n",
        "  \n",
        "    batch_norm_list = [\n",
        "                         BatchNorm1d(conv_dims[i])\n",
        "                         for i in range(len(conv_dims[:-1]))\n",
        "                      ]\n",
        "\n",
        "    fully_connected_list =   [\n",
        "                                Linear(2*conv_dims[-1], fully_connected_dims[0])\n",
        "                             ] + \\\n",
        "                             [\n",
        "                                Linear(fully_connected_dims[i], fully_connected_dims[i+1])\n",
        "                                for i in range(len(fully_connected_dims[:-1]))\n",
        "                             ] + \\\n",
        "                             [\n",
        "                                Linear(fully_connected_dims[-1], self.output_dim)\n",
        "                             ]\n",
        "    #graph conv layers\n",
        "    self.conv_layers = ModuleList(conv_list)\n",
        "    #batch normalization layers\n",
        "    self.batch_norm_layers = ModuleList(batch_norm_list)\n",
        "    #fully connected dense layers\n",
        "    self.fully_connected_layers = ModuleList(fully_connected_list)\n",
        "\n",
        "    self.classifier = LogSoftmax()\n",
        "\n",
        "    \n",
        "  def reset_parameters(self):\n",
        "        for conv in self.conv_layers:\n",
        "            conv.reset_parameters()\n",
        "        for bn in self.batch_norm_layers:\n",
        "            bn.reset_parameters()\n",
        "        for fc in self.fully_connected_layers:\n",
        "            fc.reset_parameters()\n",
        "          \n",
        "\n",
        "  def forward(self, x:torch.Tensor, edge_index:torch.Tensor, edge_type:torch.Tensor, home_list:list, away_list:list) -> torch.Tensor:\n",
        "    x = self.embed(x)\n",
        "    if self.training:\n",
        "      x = F.dropout(x, p=self.dropout[\"emb\"])\n",
        "\n",
        "    for conv, bn in zip(self.conv_layers[:-1], self.batch_norm_layers):\n",
        "      x = conv(x, edge_index=edge_index, edge_type=edge_type)\n",
        "      x = bn(x)\n",
        "      x = F.relu(x)\n",
        "      if self.training:\n",
        "        x = F.dropout(x, p=self.dropout[\"conv\"])\n",
        "\n",
        "\n",
        "    x = self.conv_layers[-1](x, edge_index, edge_type)\n",
        "    if self.training:\n",
        "      x = F.dropout(x, p=self.dropout[\"conv\"])\n",
        "\n",
        "    ##################################### End of Encoder \n",
        "\n",
        "    pred = list()\n",
        "    for home_team, away_team in zip(home_list, away_list):\n",
        "      h = torch.cat((x[home_team], x[away_team]))\n",
        "\n",
        "      for fc in self.fully_connected_layers[:-1]:\n",
        "        h = fc(h)\n",
        "        h = F.relu(h)\n",
        "        if self.training:\n",
        "          h = F.dropout(h, p=self.dropout[\"fc\"])\n",
        "\n",
        "      h = self.fully_connected_layers[-1](h)\n",
        "      if self.training:\n",
        "        h = F.dropout(h, p=self.dropout[\"fc\"])\n",
        "      pred.append(self.classifier(h))\n",
        "\n",
        "    return torch.stack(pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dV9ja7WmvjSW",
        "cellView": "form"
      },
      "source": [
        "#@title HeteroGNN Model { form-width: \"10%\" }\n",
        "class HeteroGNN(Module):\n",
        "  def __init__(self, embedding_dims: tuple, conv_dims: list, fully_connected_dims: list, dropout: dict)-> NoReturn:\n",
        "    super(HeteroGNN, self).__init__()\n",
        "\n",
        "    self.mode = None # 'train' or 'test' or 'dev' later \n",
        "    self.output_dim = 3 #home_result: win, lose, tie\n",
        "    self.num_relations = 7 #win/lose/tie/play/use/after/before\n",
        "    self.dropout = dropout\n",
        "\n",
        "    #one-hot to latent\n",
        "    self.embed = Embedding(embedding_dims[0], embedding_dims[1])\n",
        "    \n",
        "    conv_list = [\n",
        "                  HeteroConv(\n",
        "                      {\n",
        "                          ('team', 'won', 'team'): GCNConv(embedding_dims[-1], conv_dims[0]),\n",
        "                          ('team', 'lost_to', 'team'): GCNConv(embedding_dims[-1], conv_dims[0]),\n",
        "                          ('team', 'tied_with', 'team'): GCNConv(embedding_dims[-1], conv_dims[0]),\n",
        "                          ('player', 'played_for', 'team'): GATConv(embedding_dims[-1], conv_dims[0], heads=1),\n",
        "                          ('team', 'used', 'player'): GATConv(embedding_dims[-1], conv_dims[0], heads=1),\n",
        "                          ('player', 'is_before', 'player'): GCNConv(embedding_dims[-1], conv_dims[0]),\n",
        "                          ('player', 'is_after', 'player'): GCNConv(embedding_dims[-1], conv_dims[0]),\n",
        "                          ('team', 'is_before', 'team'): GCNConv(embedding_dims[-1], conv_dims[0]),\n",
        "                          ('team', 'is_after', 'team'): GCNConv(embedding_dims[-1], conv_dims[0])\n",
        "                      }, aggr='sum'\n",
        "                  )\n",
        "                ] + \\\n",
        "                [\n",
        "                  HeteroConv(\n",
        "                      {\n",
        "                          ('team', 'won', 'team'): GCNConv(conv_dims[i], conv_dims[i+1]),\n",
        "                          ('team', 'lost_to', 'team'): GCNConv(conv_dims[i], conv_dims[i+1]),\n",
        "                          ('team', 'tied_with', 'team'): GCNConv(conv_dims[i], conv_dims[i+1]),\n",
        "                          ('player', 'played_for', 'team'): GATConv(conv_dims[i], conv_dims[i+1], heads=1),\n",
        "                          ('team', 'used', 'player'): GATConv(conv_dims[i], conv_dims[i+1], heads=1),\n",
        "                          ('player', 'is_before', 'player'): GCNConv(conv_dims[i], conv_dims[i+1]),\n",
        "                          ('player', 'is_after', 'player'): GCNConv(conv_dims[i], conv_dims[i+1]),\n",
        "                          ('team', 'is_before', 'team'): GCNConv(conv_dims[i], conv_dims[i+1]),\n",
        "                          ('team', 'is_after', 'team'): GCNConv(conv_dims[i], conv_dims[i+1])\n",
        "                      }, aggr='sum'\n",
        "                  )\n",
        "                  for i in range(len(conv_dims[:-1]))\n",
        "                ]\n",
        "\n",
        "\n",
        "              \n",
        "\n",
        "  \n",
        "    # batch_norm_list = [\n",
        "    #                      BatchNorm1d(conv_dims[i])\n",
        "    #                      for i in range(len(conv_dims[:-1]))\n",
        "    #                   ]\n",
        "\n",
        "    fully_connected_list =   [\n",
        "                                Linear(2*conv_dims[-1], fully_connected_dims[0])\n",
        "                             ] + \\\n",
        "                             [\n",
        "                                Linear(fully_connected_dims[i], fully_connected_dims[i+1])\n",
        "                                for i in range(len(fully_connected_dims[:-1]))\n",
        "                             ] + \\\n",
        "                             [\n",
        "                                Linear(fully_connected_dims[-1], self.output_dim)\n",
        "                             ]\n",
        "    #graph conv layers\n",
        "    self.conv_layers = ModuleList(conv_list)\n",
        "    #batch normalization layers\n",
        "\n",
        "    # self.batch_norm_layers = ModuleList(batch_norm_list)\n",
        "\n",
        "    #fully connected dense layers\n",
        "    self.fully_connected_layers = ModuleList(fully_connected_list)\n",
        "\n",
        "    self.classifier = LogSoftmax(dim=0)\n",
        "      \n",
        "\n",
        "  def reset_parameters(self):\n",
        "      self.embed.reset_parameters()\n",
        "      for conv in self.conv_layers:\n",
        "          # for layer in conv:\n",
        "          #   layer.reset_parameters()\n",
        "          conv.reset_parameters()\n",
        "      # for bn in self.batch_norm_layers:\n",
        "      #     bn.reset_parameters()\n",
        "      for fc in self.fully_connected_layers:\n",
        "          fc.reset_parameters()\n",
        "\n",
        "\n",
        "  def forward(self, data: HeteroData) -> torch.Tensor:\n",
        "    x_dict = data.x_dict\n",
        "    home_list = data.home_list\n",
        "    away_list = data.away_list\n",
        "\n",
        "    edge_index_dict = data.edge_index_dict\n",
        "    x_dict = {key: self.embed(x) for key, x in x_dict.items()}\n",
        "    \n",
        "    if self.training:\n",
        "      x_dict = {key: F.dropout(x, p=self.dropout[\"emb\"]) for key, x in x_dict.items()}\n",
        "\n",
        "    # for conv, bn in zip(self.conv_layers[:-1], self.batch_norm_layers):\n",
        "    for conv in self.conv_layers[:-1]:\n",
        "      x_dict = conv(x_dict, edge_index_dict=edge_index_dict)\n",
        "      x_dict = {key: F.relu(x) for key, x in x_dict.items()}\n",
        "      if self.training:\n",
        "        x_dict = {key: F.dropout(x, p=self.dropout[\"conv\"]) for key, x in x_dict.items()}\n",
        "\n",
        "    x_dict = self.conv_layers[-1](x_dict, edge_index_dict=edge_index_dict)\n",
        "    if self.training:\n",
        "      x_dict = {key: F.dropout(x, p=self.dropout[\"conv\"]) for key, x in x_dict.items()}\n",
        "\n",
        "    ##################################### End of Encoder \n",
        "    h = torch.cat(\n",
        "        (x_dict['team'][home_list], x_dict['team'][away_list]),\n",
        "        dim=1\n",
        "    )\n",
        "\n",
        "    for fc in self.fully_connected_layers[:-1]:\n",
        "      h = fc(h)\n",
        "      h = F.relu(h)\n",
        "      if self.training:\n",
        "        h = F.dropout(h, p=self.dropout[\"fc\"])\n",
        "\n",
        "    h = self.fully_connected_layers[-1](h)\n",
        "    if self.training:\n",
        "      h = F.dropout(h, p=self.dropout[\"fc\"])\n",
        "\n",
        "    return self.classifier(h)\n",
        "\n",
        "    "
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bDOBoy9YJdW",
        "cellView": "form"
      },
      "source": [
        "#@title remove_redundancy(players) { form-width: \"15%\" }\n",
        "def remove_redundancy(players: list) -> list:\n",
        "  new_players = list()\n",
        "\n",
        "  for player in players:\n",
        "    if 'Own' in player:\n",
        "      player = player.replace('Own', '')\n",
        "    if 'Pen. Scored' in player:\n",
        "      player = player.replace('Pen. Scored', '')\n",
        "    if 'Pen. Score' in player:\n",
        "      player = player.replace('Pen. Score', '')\n",
        "    if 'Own' in player or 'Scored' in player or 'Score' in player:\n",
        "      print(player)\n",
        "      #SHOULD NOT PRINT IF CODE IS CORRECT\n",
        "    else:\n",
        "      new_players.append(player.strip())\n",
        "  return new_players"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76-OzUe-8V6_",
        "cellView": "form"
      },
      "source": [
        "#@title extract_players(home_lineup, away_lineup) { form-width: \"15%\" }\n",
        "def extract_players(home_lineup: str, away_lineup: str) -> list:\n",
        "  home_players = home_lineup[:-2].split(' - ')\n",
        "  away_players = away_lineup[:-2].split(' - ')\n",
        "  \n",
        "  return remove_redundancy(home_players), remove_redundancy(away_players)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdvbloHFNou-",
        "cellView": "form"
      },
      "source": [
        "#@title stats(df, show_players, show_teams, show_results) { form-width: \"10%\" }\n",
        "def stats(df: pd.DataFrame, show_players: bool=False, show_teams: bool=False, show_results: bool=False) -> NoReturn:\n",
        "  players_set = set()\n",
        "  players_list = list()\n",
        "  teams_set = set()\n",
        "\n",
        "  teams_list = list()\n",
        "  results = dict()\n",
        "  for index, (h_team, a_team, result, h_lineup, a_lineup) in df.iterrows():\n",
        "    home_players, away_players = extract_players(h_lineup, a_lineup)\n",
        "    players_set.update(home_players + away_players)\n",
        "    players_list.extend(home_players + away_players)\n",
        "    if result == 'home':\n",
        "      results.update({f'{h_team} #Wins': results.get(f'{h_team} #Wins', 0)+1})\n",
        "      results.update({f'{a_team} #Losses': results.get(f'{a_team} #Losses', 0)+1})\n",
        "    elif result == 'tie':\n",
        "      results.update({f'{h_team} #Ties': results.get(f'{h_team} #Ties', 0)+1})\n",
        "      results.update({f'{a_team} #Ties': results.get(f'{a_team} #Ties', 0)+1})\n",
        "    else:\n",
        "      results.update({f'{a_team} #Wins': results.get(f'{a_team} #Wins', 0)+1})\n",
        "      results.update({f'{h_team} #Losses': results.get(f'{h_team} #Losses', 0)+1})\n",
        "\n",
        "    teams_list.extend([h_team, a_team])\n",
        "    teams_set.update([h_team, a_team])\n",
        "    \n",
        "  if show_players:\n",
        "    for player in players_set:\n",
        "      print(f'{player} played in {players_list.count(player)} matches.')\n",
        "  if show_teams:\n",
        "    for team in teams_set:\n",
        "      print(f'{team} played {teams_list.count(team)} matches.')\n",
        "  if show_results:\n",
        "    results = od(sorted(results.items()))\n",
        "    for key, val in results.items():\n",
        "      print(f'{key}: {val}')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21iE53JDdbfE",
        "cellView": "form"
      },
      "source": [
        "#@title extract_entities(df) { form-width: \"15%\" }\n",
        "def extract_entities(df: pd.DataFrame) -> typing.Tuple[set, set]:\n",
        "  players_set = set()\n",
        "  players_list = list()\n",
        "  teams_set = set()\n",
        "\n",
        "  teams_list = list()\n",
        "  # results = dict()\n",
        "  for index, (h_team, a_team, result, h_lineup, a_lineup) in df.iterrows():\n",
        "    home_players, away_players = extract_players(h_lineup, a_lineup)\n",
        "\n",
        "    players_set.update(home_players + away_players)\n",
        "    teams_set.update([h_team, a_team])\n",
        "    \n",
        "  \n",
        "  return teams_set, players_set"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFDbVt67eJOR",
        "cellView": "form"
      },
      "source": [
        "#@title gen_entites(df) { form-width: \"15%\" }\n",
        "def gen_entities(df: pd.DataFrame) -> dict:\n",
        "  teams, players = extract_entities(df)\n",
        "  entities = {entity: index for index, entity in enumerate(list(players) + list(teams))}\n",
        "  return entities"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHLHaaFaond8",
        "cellView": "form"
      },
      "source": [
        "#@title nodes_gen(df) OK_HETERO { form-width: \"15%\" }\n",
        "\n",
        "def nodes_gen(df: pd.DataFrame) -> typing.Tuple[dict, dict]:\n",
        "  player_nodes = dict()\n",
        "  team_nodes = dict()\n",
        "  player_node_counter = 0\n",
        "  team_node_counter = 0\n",
        "\n",
        "  for index, (h_team, a_team, result, h_lineup, a_lineup) in df.iterrows():\n",
        "      home_players, away_players = extract_players(h_lineup, a_lineup)\n",
        "\n",
        "      for player_index, player in enumerate(home_players):\n",
        "        player_nodes[f'{player}@{index}'] = player_node_counter\n",
        "        player_node_counter += 1\n",
        "      for player_index, player in enumerate(away_players):\n",
        "        player_nodes[f'{player}@{index}'] = player_node_counter\n",
        "        player_node_counter += 1\n",
        "\n",
        "      team_nodes[f'{h_team}*{index}'] = team_node_counter\n",
        "      team_node_counter += 1\n",
        "\n",
        "      team_nodes[f'{a_team}*{index}'] = team_node_counter\n",
        "      team_node_counter += 1\n",
        "\n",
        "  return player_nodes, team_nodes\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aAQy1k6SIwn",
        "cellView": "form"
      },
      "source": [
        "#@title show_edges(df, edge, edge_type) USELESS { form-width: \"15%\" }\n",
        "def show_edges(df: pd.DataFrame, edge: torch.Tensor, edge_type: torch.Tensor, tt:str) -> NoReturn:\n",
        "  types = {\n",
        "      0: 'Won',\n",
        "      1: 'Lost To',\n",
        "      2: 'Tied With',\n",
        "      3: 'Played For',\n",
        "      4: 'Used As Player',\n",
        "      5: 'Is Before',\n",
        "      6: 'Is After'\n",
        "  }\n",
        "  t = {'p': 0, 't':1}\n",
        "  nodes = nodes_gen(df)[t[tt]]\n",
        "  r = {k:v for v, k in nodes.items()}\n",
        "  for i in range(edge_type.shape[0]):\n",
        "    head = int(edge[0][i].item())\n",
        "    tail = int(edge[1][i].item())\n",
        "    relation = int(edge_type[i].item())\n",
        "    arrow = f'=== {types[relation]} ===>'\n",
        "    print(f'{r[head]:<32}   {arrow}   {r[tail]:>32}')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdqdirL9lxjP",
        "cellView": "form"
      },
      "source": [
        "#@title home_won_gen(df) OK_HETERO { form-width: \"15%\" }\n",
        "def home_won_gen(df: pd.DataFrame, full_data_frame=None) -> typing.Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
        "  home_winning_matches = df.loc[df['result'] == 'home']\n",
        "  home_winners = home_winning_matches['home_team']\n",
        "  away_losers = home_winning_matches['away_team']\n",
        "\n",
        "  winning_hashes = list()\n",
        "  losing_hashes = list()\n",
        "\n",
        "  for home, away, match in zip(home_winners, away_losers, home_winners.index):\n",
        "    winning_hashes.append(f'{home}*{match}')\n",
        "    losing_hashes.append(f'{away}*{match}')\n",
        "\n",
        "  winning_nodes = list()\n",
        "  losing_nodes = list()\n",
        "\n",
        "  if full_data_frame is None:\n",
        "    full_data_frame = df\n",
        "  _, team_nodes = nodes_gen(full_data_frame)\n",
        "\n",
        "  for winner, loser in zip(winning_hashes, losing_hashes):\n",
        "    winning_nodes.append(team_nodes[winner]) \n",
        "    losing_nodes.append(team_nodes[loser])\n",
        "\n",
        "  won_edges = torch.tensor(\n",
        "      [\n",
        "      winning_nodes,\n",
        "      losing_nodes\n",
        "      ], \n",
        "      dtype=torch.long,\n",
        "      device=DEVICE\n",
        "  )\n",
        "\n",
        "  lost_edges = torch.tensor(\n",
        "      [\n",
        "      losing_nodes,\n",
        "      winning_nodes\n",
        "      ],\n",
        "      dtype=torch.long,\n",
        "      device=DEVICE\n",
        "  )\n",
        "\n",
        "  return won_edges, lost_edges"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LypA1Sinw94O",
        "cellView": "form"
      },
      "source": [
        "#@title away_won_gen(df) OK_HETERO { form-width: \"15%\" }\n",
        "def away_won_gen(df: pd.DataFrame, full_data_frame=None) -> typing.Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
        "  away_winning_matches = df.loc[df['result'] == 'away']\n",
        "  away_winners = away_winning_matches['away_team']\n",
        "  home_losers = away_winning_matches['home_team']\n",
        "\n",
        "  winning_hashes = list()\n",
        "  losing_hashes = list()\n",
        "\n",
        "  for home, away, match in zip(home_losers, away_winners, away_winners.index):\n",
        "    winning_hashes.append(f'{away}*{match}')\n",
        "    losing_hashes.append(f'{home}*{match}')\n",
        "\n",
        "  winning_nodes = list()\n",
        "  losing_nodes = list()\n",
        "\n",
        "  if full_data_frame is None:\n",
        "    full_data_frame = df\n",
        "  _, team_nodes = nodes_gen(full_data_frame)\n",
        "\n",
        "  for winner, loser in zip(winning_hashes, losing_hashes):\n",
        "    winning_nodes.append(team_nodes[winner]) \n",
        "    losing_nodes.append(team_nodes[loser])\n",
        "\n",
        "  won_edges = torch.tensor(\n",
        "      [\n",
        "      winning_nodes,\n",
        "      losing_nodes\n",
        "      ],\n",
        "      dtype=torch.long,\n",
        "      device=DEVICE\n",
        "  )\n",
        "\n",
        "  lost_edges = torch.tensor(\n",
        "      [\n",
        "      losing_nodes,\n",
        "      winning_nodes\n",
        "      ],\n",
        "      dtype=torch.long,\n",
        "      device=DEVICE\n",
        "  )\n",
        "  \n",
        "  return won_edges, lost_edges"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQUZPKoQyEYp",
        "cellView": "form"
      },
      "source": [
        "#@title tied_gen(df) OK_HETERO { form-width: \"15%\" }\n",
        "def tied_gen(df: pd.DataFrame, full_data_frame=None) -> typing.Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
        "  tied_matches = df.loc[df['result'] == 'tie']\n",
        "  home_teams = tied_matches['home_team']\n",
        "  away_teams = tied_matches['away_team']\n",
        "\n",
        "  home_hashes = list()\n",
        "  away_hashes = list()\n",
        "\n",
        "  for home, away, match in zip(home_teams, away_teams, away_teams.index):\n",
        "    away_hashes.append(f'{away}*{match}')\n",
        "    home_hashes.append(f'{home}*{match}')\n",
        "\n",
        "  home_nodes = list()\n",
        "  away_nodes = list()\n",
        "\n",
        "  if full_data_frame is None:\n",
        "    full_data_frame = df\n",
        "  _, team_nodes = nodes_gen(full_data_frame)\n",
        "\n",
        "  for home, away in zip(home_hashes, away_hashes):\n",
        "    home_nodes.append(team_nodes[home]) \n",
        "    away_nodes.append(team_nodes[away])\n",
        "\n",
        "  home_tied_edges = torch.tensor(\n",
        "      [\n",
        "      home_nodes,\n",
        "      away_nodes\n",
        "      ],\n",
        "      dtype=torch.long,\n",
        "      device=DEVICE\n",
        "  )\n",
        "\n",
        "  away_tied_edges = torch.tensor(\n",
        "      [\n",
        "      away_nodes,\n",
        "      home_nodes\n",
        "      ], \n",
        "      dtype=torch.long,\n",
        "      device=DEVICE\n",
        "  )\n",
        "\n",
        "  return home_tied_edges, away_tied_edges"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIGBYohP5znW",
        "cellView": "form"
      },
      "source": [
        "#@title played_used_gen(df) OK_HETERO { form-width: \"15%\" }\n",
        "def played_used_gen(df: pd.DataFrame) -> typing.Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
        "  team_nodes = list()\n",
        "  player_nodes = list()\n",
        "\n",
        "  p_nodes, t_nodes = nodes_gen(df)\n",
        "\n",
        "  for index, (h_team, a_team, result, h_lineup, a_lineup) in df.iterrows():\n",
        "    home_players, away_players = extract_players(h_lineup, a_lineup)\n",
        "\n",
        "    for home_player, away_player in zip(home_players, away_players):\n",
        "      player_nodes.append(p_nodes[f'{home_player}@{index}'])\n",
        "      team_nodes.append(t_nodes[f'{h_team}*{index}'])\n",
        "      player_nodes.append(p_nodes[f'{away_player}@{index}'])\n",
        "      team_nodes.append(t_nodes[f'{a_team}*{index}'])\n",
        "\n",
        "  played_in_edges = torch.tensor(\n",
        "      [\n",
        "       player_nodes,\n",
        "       team_nodes\n",
        "      ],\n",
        "      dtype=torch.long,\n",
        "      device=DEVICE\n",
        "  )\n",
        "\n",
        "  used_edges = torch.tensor(\n",
        "      [\n",
        "       team_nodes,\n",
        "       player_nodes\n",
        "      ],\n",
        "      dtype=torch.long,\n",
        "      device=DEVICE\n",
        "  ) \n",
        "\n",
        "  return played_in_edges, used_edges"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kily_SD775Ic",
        "cellView": "form"
      },
      "source": [
        "#@title players_before_after_gen(df) OK_HETERO { form-width: \"15%\" }\n",
        "#TODO\n",
        "def players_before_after_gen(df: pd.DataFrame) -> typing.Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
        "  player_match_hashes = list()\n",
        "\n",
        "  for index, (h_team, a_team, result, h_lineup, a_lineup) in df.iterrows():\n",
        "      home_players, away_players = extract_players(h_lineup, a_lineup)\n",
        "\n",
        "      for player in home_players + away_players:\n",
        "        player_match_hashes.append(f'{player}@{index}')\n",
        "\n",
        "\n",
        "\n",
        "  sorted_hashes = sorted(\n",
        "      player_match_hashes,\n",
        "      key=lambda w: (w.split('@')[0], int(w.split('@')[1]))\n",
        "  )\n",
        "\n",
        "  before_nodes = list()\n",
        "  after_nodes = list()\n",
        "\n",
        "  player_nodes, _ = nodes_gen(df)\n",
        "\n",
        "  for index, hash in enumerate(sorted_hashes):\n",
        "    player, match = hash.split('@')\n",
        "    before_node = player_nodes[hash]\n",
        "    try:\n",
        "      after_node = player_nodes[sorted_hashes[index+1]]\n",
        "      before_name = player_match_hashes[before_node].split('@')[0]\n",
        "      after_name = player_match_hashes[after_node].split('@')[0]\n",
        "      if before_name == after_name:\n",
        "        before_nodes.append(before_node)\n",
        "        after_nodes.append(after_node)\n",
        "    except:\n",
        "      pass\n",
        "  before_edges = torch.tensor(\n",
        "      [\n",
        "      before_nodes,\n",
        "      after_nodes\n",
        "      ], dtype=torch.long,\n",
        "      device=DEVICE\n",
        "  )\n",
        "\n",
        "  after_edges = torch.tensor(\n",
        "      [\n",
        "      after_nodes,\n",
        "      before_nodes\n",
        "      ], dtype=torch.long,\n",
        "      device=DEVICE\n",
        "  )\n",
        "\n",
        "  return before_edges, after_edges"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lk24VmcKFTF_",
        "cellView": "form"
      },
      "source": [
        "#@title teams_before_after_gen(df) OK_HETERO { form-width: \"15%\" }\n",
        "def teams_before_after_gen(df: pd.DataFrame) -> typing.Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
        "  team_match_hashes = list()\n",
        "\n",
        "  for index, (h_team, a_team, result, h_lineup, a_lineup) in df.iterrows():\n",
        "      team_match_hashes.append(f'{h_team}*{index}')\n",
        "      team_match_hashes.append(f'{a_team}*{index}')\n",
        "\n",
        "  sorted_hashes = sorted(\n",
        "      team_match_hashes,\n",
        "      key= lambda w: (w.split('*')[0], int(w.split('*')[1]))\n",
        "  )\n",
        "\n",
        "  before_nodes = list()\n",
        "  after_nodes = list()\n",
        "\n",
        "  _, team_nodes = nodes_gen(df)\n",
        "\n",
        "  for index, hash in enumerate(sorted_hashes):\n",
        "    team, match = hash.split('*')\n",
        "    before_node = team_nodes[hash]\n",
        "    try:\n",
        "      after_node = team_nodes[sorted_hashes[index+1]]\n",
        "      before_name = team_match_hashes[before_node].split('*')[0]\n",
        "      after_name = team_match_hashes[after_node].split('*')[0]\n",
        "      if before_name == after_name:\n",
        "        before_nodes.append(before_node)\n",
        "        after_nodes.append(after_node)\n",
        "    except:\n",
        "      pass\n",
        "  before_edges = torch.tensor(\n",
        "      [\n",
        "      before_nodes,\n",
        "      after_nodes\n",
        "      ], dtype=torch.long,\n",
        "      device=DEVICE\n",
        "  )\n",
        "\n",
        "  after_edges = torch.tensor(\n",
        "      [\n",
        "      after_nodes,\n",
        "      before_nodes\n",
        "      ], dtype=torch.long,\n",
        "      device=DEVICE\n",
        "  )\n",
        "\n",
        "  return before_edges, after_edges"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rq0Mmxoxi6Sz",
        "cellView": "form"
      },
      "source": [
        "#@title complete_graph_gen(df, for_players, for_teams) OK_HETERO { form-width: \"10%\" }\n",
        "def complete_graph_edge_gen(df: pd.DataFrame, for_players: bool=True, for_teams: bool=True) -> dict:\n",
        "  home_won, away_lost = home_won_gen(df)\n",
        "  away_won, home_lost = away_won_gen(df)\n",
        "  home_tied, away_tied = tied_gen(df)\n",
        "  player_played, team_used = played_used_gen(df)\n",
        "\n",
        "  if for_players:\n",
        "    player_before, player_after = players_before_after_gen(df)\n",
        "  if for_teams:\n",
        "    team_before, team_after = teams_before_after_gen(df)\n",
        "  won_edge_index = torch.cat(\n",
        "      (home_won, away_won),\n",
        "      dim=1\n",
        "  )\n",
        "  lost_edge_index = torch.cat(\n",
        "      (away_lost, home_lost),\n",
        "      dim=1\n",
        "  )\n",
        "  tied_edge_index = torch.cat(\n",
        "      (home_tied, away_tied),\n",
        "      dim=1\n",
        "  )\n",
        "  edge_index = {\n",
        "      'won': won_edge_index,\n",
        "      'lost': lost_edge_index,\n",
        "      'tied': tied_edge_index,\n",
        "      'played': player_played,\n",
        "      'used': team_used,\n",
        "      'p_after':player_after,\n",
        "      'p_before': player_before,\n",
        "      't_after': team_after,\n",
        "      't_before': team_after\n",
        "  }   \n",
        "  return edge_index"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8N_vya3_PB75",
        "cellView": "form"
      },
      "source": [
        "#@title supervision_graph_gen(df, for_players, for_teams, log_supervision_matches) OK_HETERO { form-width: \"10%\" }\n",
        "def supervision_graph_gen(df : pd.DataFrame, messaging: list, supervision: list, for_players: bool=True, for_teams: bool=True, log_supervision_matches: bool=False) -> typing.Tuple[torch.Tensor, torch.Tensor]:\n",
        "  if log_supervision_matches:\n",
        "    if model.mode == 'train':\n",
        "      mode = 'training'\n",
        "    elif model.mode == 'dev':\n",
        "      mode = 'validating'\n",
        "    elif model.mode == 'test':\n",
        "      mode = 'testing'\n",
        "    logging.info(\n",
        "        f'Messaging on matches ({messaging[0] + 1} -> {messaging[-1] + 1:>5}),\\ Model is {mode} on matches ({last_match+2} -> {last_match + 11})'\n",
        "    )\n",
        "\n",
        "  target_for_nodes = df\n",
        "\n",
        "  home_won, away_lost = home_won_gen(df.loc[messaging], full_data_frame=target_for_nodes)\n",
        "  away_won, home_lost = away_won_gen(df.loc[messaging], full_data_frame=target_for_nodes)\n",
        "  home_tied, away_tied = tied_gen(df.loc[messaging], full_data_frame=target_for_nodes)\n",
        "\n",
        "  player_played, team_used = played_used_gen(df)\n",
        "\n",
        "  if for_players:\n",
        "    player_before, player_after = players_before_after_gen(df)\n",
        "  if for_teams:\n",
        "    team_before, team_after = teams_before_after_gen(df)\n",
        "\n",
        "  won_edge_index = torch.cat(\n",
        "      (home_won, away_won),\n",
        "      dim=1\n",
        "  )\n",
        "  lost_edge_index = torch.cat(\n",
        "      (away_lost, home_lost),\n",
        "      dim=1\n",
        "  )\n",
        "  tied_edge_index = torch.cat(\n",
        "      (home_tied, away_tied),\n",
        "      dim=1\n",
        "  )\n",
        "  edge_index = {\n",
        "      'won': won_edge_index,\n",
        "      'lost': lost_edge_index,\n",
        "      'tied': tied_edge_index,\n",
        "      'played': player_played,\n",
        "      'used': team_used,\n",
        "      'p_after':player_after,\n",
        "      'p_before': player_before,\n",
        "      't_after': team_after,\n",
        "      't_before': team_after\n",
        "  }  \n",
        "  return edge_index"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCWPYy3aPjhg",
        "cellView": "form"
      },
      "source": [
        "#@title data_gen(df, remove_supervision_links, for_players, for_teams, print_edges, log_supervision_matches) OK_HETERO { form-width: \"10%\" }\n",
        "def data_gen(df: pd.DataFrame, messaging: list, supervision: list=None, remove_supervision_links: bool=True, for_players: bool=True, for_teams: bool=True, print_edges: bool=False, log_supervision_matches: bool=False) -> HeteroData:\n",
        "  if print_edges:\n",
        "    show_edges(df, edge_index, edge_type)\n",
        "  if remove_supervision_links:\n",
        "    edge_index = supervision_graph_gen(\n",
        "        df,\n",
        "        messaging=messaging,\n",
        "        supervision=supervision,\n",
        "        for_players=for_players,\n",
        "        for_teams=for_teams,\n",
        "        log_supervision_matches=log_supervision_matches\n",
        "    )\n",
        "    y = torch.tensor(\n",
        "        df.loc[supervision]['result'].map(home_result).values,\n",
        "        device=DEVICE\n",
        "    )\n",
        "\n",
        "  else:\n",
        "    if supervision is None:\n",
        "      supervision = df.index\n",
        "    if messaging is None:\n",
        "      messaging = df.index\n",
        "    edge_index = complete_graph_edge_gen(df, for_players, for_teams)\n",
        "    y = torch.tensor(\n",
        "        df.loc[supervision]['result'].map(home_result).values,\n",
        "        device=DEVICE\n",
        "    )\n",
        "\n",
        "  data = HeteroData()\n",
        "  data['player'].x = torch.unique(edge_index['played'][0]).to(DEVICE).type(torch.int64)\n",
        "  data['team'].x = torch.unique(edge_index['used'][0]).to(DEVICE).type(torch.int64)\n",
        "  \n",
        "  data['team', 'won', 'team'].edge_index = edge_index['won']\n",
        "  data['team', 'lost_to', 'team'].edge_index = edge_index['lost']\n",
        "  data['team', 'tied_with', 'team'].edge_index = edge_index['tied']\n",
        "  data['player', 'played_for', 'team'].edge_index = edge_index['played']\n",
        "  data['team', 'used', 'player'].edge_index = edge_index['used']\n",
        "  data['player', 'is_before', 'player'].edge_index = edge_index['p_before']\n",
        "  data['player', 'is_after', 'player'].edge_index = edge_index['p_after']\n",
        "  data['team', 'is_before', 'team'].edge_index = edge_index['t_before']\n",
        "  data['team', 'is_after', 'team'].edge_index = edge_index['t_after']\n",
        "  data.y = y\n",
        "\n",
        "  return data"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T13E2VxefgaL",
        "cellView": "form"
      },
      "source": [
        "#@title visualzie_graph(df, width, height, title, remove_supervision_links) { form-width: \"10%\" }\n",
        "def visualize_graph(df:pd.DataFrame, width: int=20, height: int=20, title: str=None, remove_supervision_links: bool=False) -> NoReturn:\n",
        "  import networkx as nx\n",
        "  import matplotlib.pyplot as plt\n",
        "  nodes = nodes_gen(df)\n",
        "  r = {k:v for v, k in nodes.items()}\n",
        "  d = data_gen(df, remove_supervision_links=remove_supervision_links)\n",
        "  G = to_networkx(d)\n",
        "  types = {\n",
        "        0: 'Won',\n",
        "        1: 'Lost To',\n",
        "        2: 'Tied With',\n",
        "        3: 'Played For',\n",
        "        4: 'Used As Player',\n",
        "        5: 'Is Before',\n",
        "        6: 'Is After'\n",
        "  }\n",
        "\n",
        "  type_color = {\n",
        "      0: '#00ff00', #won\n",
        "      1: '#ff0000', #lost to\n",
        "      2: '#e6d70e', #tied with\n",
        "      3: '#1338f0', #played for\n",
        "      4: '#f01373', #used as player\n",
        "      5: '#0f072e', #is before\n",
        "      6: '#d909cb' #is after\n",
        "  }\n",
        "\n",
        "  double_edge_types = {\n",
        "      0: '(Won[green] - Lost to[red])',\n",
        "      1: '(Lost to[red] - Won[green])',\n",
        "      2: '(Tied with[yellow])',\n",
        "      3: '(Played for[blue] - Used as Player[pink])',\n",
        "      4: '(Used as Player[pink] - Played for[blue])',\n",
        "      5: '(Is Before[dark blue] - Is After[purple])',\n",
        "      6: '(Is After[purple] - Is Before[dark blue])'\n",
        "  }\n",
        "\n",
        "  link_colors = dict(zip(\n",
        "        types.values(),\n",
        "        type_color.values()\n",
        "      )\n",
        "  )\n",
        "\n",
        "  node_colors = {\n",
        "      'player-color': '#8f0ba1',\n",
        "      'team-color': '#02fae1'   \n",
        "  }\n",
        "\n",
        "  all_colors = link_colors.copy()\n",
        "  all_colors.update(node_colors)\n",
        "\n",
        "  \n",
        "\n",
        "  for color_use in all_colors.keys():\n",
        "      plt.scatter([],[], c=[all_colors[color_use]], label=f'{color_use}')\n",
        "\n",
        "  edge_colors = list()\n",
        "  edge_labels = dict()\n",
        "\n",
        "  ######################################################## NOT OPTIMIZED\n",
        "  for edge in G.edges():\n",
        "    e = torch.tensor(edge, device=DEVICE)\n",
        "    for index, node_node in enumerate(d.edge_index.t()):\n",
        "      if torch.equal(e, node_node):\n",
        "        edge_colors.append(type_color[d.edge_type[index].item()])\n",
        "        label = double_edge_types[d.edge_type[index].item()]\n",
        "        edge_labels.update({edge:label})\n",
        "  colors = list()\n",
        "  node_labels = dict()\n",
        "  for node in G.nodes():\n",
        "    if '@' in r[node]:\n",
        "      colors.append(all_colors['player-color'])\n",
        "      node_labels.update({node: r[node].split('@')[0]})\n",
        "    elif '*' in r[node]:\n",
        "      colors.append(all_colors['team-color'])\n",
        "      node_labels.update({node:r[node].split('*')[0]})\n",
        "  ######################################################## NOT OPTIMIZED\n",
        "\n",
        "  fig = plt.gcf()\n",
        "  fig.set_size_inches(width, height)\n",
        "  pos = nx.spring_layout(G)\n",
        "  nx.draw_networkx_nodes(G, pos, node_color=colors)\n",
        "  nx.draw_networkx_labels(G, pos, labels=node_labels)\n",
        "  nx.draw_networkx_edges(G, pos, edge_color=edge_colors, connectionstyle='arc3,rad=0.05')\n",
        "  nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels)\n",
        "  plt.legend()\n",
        "  plt.title(title)\n",
        "  fig.show()\n",
        "  plt.show()"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cx2_quEQdyY",
        "cellView": "form"
      },
      "source": [
        "#@title batch_gen(df, entities, log_supervision_matches) OK_HETERO { form-width: \"5%\" }\n",
        "def batch_gen(df: pd.DataFrame, entities: dict, messaging: list=None, supervision: list=None, remove_supervision_links: bool=True, log_supervision_matches: bool=False) -> HeteroData:\n",
        "  graph = data_gen(\n",
        "      df,\n",
        "      messaging=messaging,\n",
        "      supervision=supervision, \n",
        "      remove_supervision_links=remove_supervision_links,\n",
        "      log_supervision_matches=log_supervision_matches\n",
        "  )\n",
        "  \n",
        "  home_teams = list()\n",
        "  away_teams = list()\n",
        "\n",
        "  p_nodes, t_nodes = nodes_gen(df)\n",
        "  nodes = {**p_nodes, **t_nodes}\n",
        "  \n",
        "  if supervision is None:\n",
        "    supervision = df.index\n",
        "\n",
        "  indices = dict()\n",
        "  for hash, index in nodes.items():\n",
        "    if '@' in hash:\n",
        "      player = hash.split('@')[0]\n",
        "      player_id = entities[player]\n",
        "      indices.update({index:player_id})\n",
        "    elif '*' in hash:\n",
        "      team = hash.split('*')[0]\n",
        "      team_id = entities[team]\n",
        "      indices.update({index: team_id})\n",
        "  for index, (h_team, a_team, result, h_lineup, a_lineup) in df.loc[supervision].iterrows():\n",
        "      home_teams.append(nodes[f'{h_team}*{index}'])\n",
        "      away_teams.append(nodes[f'{a_team}*{index}'])\n",
        "\n",
        "  features_player = torch.tensor(\n",
        "      [indices[i.item()] for i in graph['player'].x],\n",
        "      device=DEVICE\n",
        "  )\n",
        "  features_team = torch.tensor(\n",
        "      [indices[i.item()] for i in graph['team'].x],\n",
        "      device=DEVICE\n",
        "  )\n",
        "\n",
        "  graph['player'].x = features_player\n",
        "  graph['team'].x = features_team\n",
        "  graph.home_list = home_teams\n",
        "  graph.away_list = away_teams\n",
        "  \n",
        "  return graph"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lB8wip7OtAJp",
        "cellView": "form"
      },
      "source": [
        "#@title train(model, dataset, optimizer, loss_fn) { form-width: \"15%\" }\n",
        "def train(model: HeteroGNN, data: HeteroData, optimizer: torch.optim, loss_fn: torch.nn.modules.loss) -> typing.Tuple[float, int, int]:\n",
        "  batch_loss = 0\n",
        "\n",
        "  model.train()\n",
        "  out = model(data)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  loss = loss_fn(out, data.y)\n",
        "  batch_loss = loss.item()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  prediction = out.argmax(dim=-1)\n",
        "  correct = (prediction == data.y).sum().item()\n",
        "  all = data.y.shape[0]\n",
        "\n",
        "  return batch_loss, correct, all"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yVJnE1o1V8a",
        "cellView": "form"
      },
      "source": [
        "#@title evaluate(model, dataset) { form-width: \"25px\" }\n",
        "@torch.no_grad()\n",
        "def evaluate(model: HeteroGNN, data: HeteroConv) -> typing.Tuple[int, int]:\n",
        "  model.eval()\n",
        "\n",
        "  # for child in model.children():\n",
        "  #   for ii in range(len(child)):\n",
        "  #       if type(child[ii]) == BatchNorm1d:\n",
        "  #           child[ii].track_running_stats = False\n",
        "\n",
        "  out = model(data)\n",
        "  prediction = out.argmax(dim=-1)\n",
        "  correct = (prediction == data.y).sum().item()\n",
        "  all = data.y.shape[0]\n",
        "  model.train()\n",
        "\n",
        "  return correct, all"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Cuee66-M_HL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "2aac040f-410a-4d47-bfac-096cda42e109"
      },
      "source": [
        "#@title Dataset Download { form-width: \"15%\" }\n",
        "import requests\n",
        "from os import getcwd\n",
        "\n",
        "url_epl = \"https://raw.githubusercontent.com/jokecamp/FootballData/master/EPL%202011-2019/PL_scraped_ord.csv\"\n",
        "url_fk = \"https://raw.githubusercontent.com/masoudmousavi/Sports-Analysis-with-GNNs/conference/FakeData_EPL.csv?token=ARGPVT7NDP7RPGMPITHI4ETBNGQ22\"\n",
        "# current_directory = getcwd()\n",
        "filename_rl = 'dataset.csv'\n",
        "filename_fk = 'fake.csv'\n",
        "req_rl = requests.get(url_epl)\n",
        "req_fk = requests.get(url_fk)\n",
        "\n",
        "dataset_filename = filename_rl\n",
        "\n",
        "if req_rl.status_code == 200:\n",
        "  with open(filename_rl, 'wb') as fp:\n",
        "    fp.write(req_rl.content)\n",
        "else:\n",
        "  print(f'Error downloading file at {url_epl}')\n",
        "if req_fk.status_code == 200:\n",
        "  with open(filename_fk, 'wb') as fp:\n",
        "    fp.write(req_fk.content)\n",
        "else:\n",
        "  print(f'Error downloading file at {url_fk}')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error downloading file at https://raw.githubusercontent.com/masoudmousavi/Sports-Analysis-with-GNNs/conference/FakeData_EPL.csv?token=ARGPVT7NDP7RPGMPITHI4ETBNGQ22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PcBerm8OOKR",
        "cellView": "form"
      },
      "source": [
        "#@title Dataset Loading and Cleaning { form-width: \"15px\" }\n",
        "dataset = pd.read_csv(\n",
        "    dataset_filename,\n",
        "    encoding='latin-1',\n",
        "    usecols=['home_team', 'away_team', 'result', 'home_lineup', 'away_lineup']\n",
        ")\n",
        "corrupted = dataset.loc[pd.isna(dataset['away_lineup']) | pd.isna(dataset['home_lineup'])]\n",
        "dataset = dataset.drop(corrupted.index, axis=0)\n",
        "dataset = dataset.reset_index(drop=True)\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2iqtsxu3A8k",
        "cellView": "form"
      },
      "source": [
        "#@title Log { form-width: \"15%\" }\n",
        "logging.basicConfig(\n",
        "    filename='model-logs.log',\n",
        "    filemode='w',\n",
        "    level=logging.INFO\n",
        ")\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3nK5OCX4nIw",
        "cellView": "form"
      },
      "source": [
        "#@title Hyperparameters File\n",
        "hp_file = open('hyperparameters.json', 'w')\n",
        "hyperparameters = {\n",
        "    \"learning_rate\": 1e-3,\n",
        "    \"num_epochs\": 200,\n",
        "    \"fc_dropout\":0.01,\n",
        "    \"conv_dropout\": 0.01,\n",
        "    \"emb_dropout\": 0.01,\n",
        "    \"train_messaging_graph_size\": 440,\n",
        "    \"val_messaging_graph_size\": 440,\n",
        "    \"test_messaging_graph_size\": 440,\n",
        "    \"iter_size\": 10,\n",
        "    \"val_week_denom\": 50,\n",
        "    \"test_week_denom\": 60,\n",
        "    \"embedding_dim\": 32,\n",
        "    \"conv_dims\":[\n",
        "          32,\n",
        "          32, \n",
        "          32,\n",
        "          32\n",
        "    ],\n",
        "    \"fully_connected_dims\":[\n",
        "              32,\n",
        "              32\n",
        "    ]\n",
        "}\n",
        "\n",
        "json.dump(hyperparameters, hp_file)\n",
        "hp_file.close()"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbAnO5WibS9g",
        "cellView": "form"
      },
      "source": [
        "#@title Model and Model Hyperparameters { form-width: \"15%\" }\n",
        "log_supervision_matches = True\n",
        "with open('hyperparameters.json', 'r') as hp_file:\n",
        "  hyperparameters = json.load(hp_file)\n",
        "learning_rate = hyperparameters[\"learning_rate\"]\n",
        "num_epochs = hyperparameters[\"num_epochs\"]\n",
        "fc_dropout = hyperparameters[\"fc_dropout\"]\n",
        "conv_dropout = hyperparameters[\"conv_dropout\"]\n",
        "emb_dropout = hyperparameters[\"emb_dropout\"]\n",
        "\n",
        "remove_supervision_links = True\n",
        "\n",
        "entities = gen_entities(dataset)\n",
        "\n",
        "######################################## Scheme 4\n",
        "train_messaging_graph_size = hyperparameters[\"train_messaging_graph_size\"]\n",
        "val_messaging_graph_size = hyperparameters[\"val_messaging_graph_size\"]\n",
        "test_messaging_graph_size = hyperparameters[\"test_messaging_graph_size\"]\n",
        "iter_size = hyperparameters[\"iter_size\"]\n",
        "val_week_denom = hyperparameters[\"val_week_denom\"]\n",
        "test_week_denom = hyperparameters[\"test_week_denom\"]\n",
        "######################################## Parameters\n",
        "\n",
        "model = HeteroGNN(\n",
        "    embedding_dims=(\n",
        "        max(entities.values()) + 1,\n",
        "        hyperparameters[\"embedding_dim\"]\n",
        "    ),\n",
        "    conv_dims=hyperparameters[\"conv_dims\"],\n",
        "    fully_connected_dims=hyperparameters[\"fully_connected_dims\"],\n",
        "    dropout={\n",
        "        \"emb\": emb_dropout,\n",
        "        \"conv\": conv_dropout,\n",
        "        \"fc\": fc_dropout\n",
        "    }\n",
        ").to(DEVICE)\n",
        "\n",
        "print(model)\n",
        "\n",
        "optimizer = Adam(\n",
        "    model.parameters(),\n",
        "    lr=learning_rate\n",
        ")\n",
        "criterion = NLLLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mb39S2BEh2a",
        "cellView": "form"
      },
      "source": [
        "#@title Data Batch Maker { form-width: \"15%\" }\n",
        "train_batches = list()\n",
        "val_batches = list()\n",
        "test_batches = list()\n",
        "\n",
        "for i in range(train_messaging_graph_size, dataset.shape[0], iter_size):\n",
        "      if i % val_week_denom == 0:\n",
        "        ######################## Validation ########################\n",
        "        from_match = i - val_messaging_graph_size\n",
        "        to_match = i - 1\n",
        "        model.mode = 'dev'\n",
        "\n",
        "        validation_df = dataset.loc[from_match: to_match, :]\n",
        "        val_graph_data = batch_gen(\n",
        "              validation_df,\n",
        "              entities=entities,\n",
        "              messaging=validation_df.index,\n",
        "              remove_supervision_links=remove_supervision_links,\n",
        "              log_supervision_matches=log_supervision_matches\n",
        "          )\n",
        "        val_batches.append(val_graph_data)\n",
        "\n",
        "      elif i % test_week_denom == 0:\n",
        "        ######################## Test ########################\n",
        "        model.eval()\n",
        "        model.mode = 'test'\n",
        "        \n",
        "        from_match = i - test_messaging_graph_size\n",
        "        to_match = i - 1\n",
        "\n",
        "        test_df = dataset.loc[from_match: to_match, :]\n",
        "        test_graph_data = batch_gen(\n",
        "            test_df,\n",
        "            entities=entities,\n",
        "            messaging=test_df.index,\n",
        "            remove_supervision_links=remove_supervision_links,\n",
        "            log_supervision_matches=log_supervision_matches\n",
        "        )\n",
        "        \n",
        "        test_batches.append(test_graph_data)\n",
        "\n",
        "      else:\n",
        "        ######################## Train ########################\n",
        "\n",
        "        from_match = i - train_messaging_graph_size\n",
        "        to_match = i - 1\n",
        "        model.mode = 'train'\n",
        "\n",
        "        train_df = dataset.loc[from_match: to_match, :]\n",
        "        train_graph_data = batch_gen(\n",
        "            train_df,\n",
        "            entities=entities,\n",
        "            messaging=train_df.index,\n",
        "            remove_supervision_links=remove_supervision_links,\n",
        "            log_supervision_matches=log_supervision_matches\n",
        "        )\n",
        "\n",
        "        train_batches.append(train_graph_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cRCBDz5FJVj",
        "cellView": "form"
      },
      "source": [
        "#@title Model Fitting Moving Partial Graph { form-width: \"15%\" }\n",
        "try:\n",
        "  train_losses = list()\n",
        "  train_accuracies = list()\n",
        "  val_accuracies = list()\n",
        "  \n",
        "  for epoch in range(num_epochs):\n",
        "    epoch_loss = 0\n",
        "    val_correct = 0\n",
        "    val_all = 0\n",
        "    train_all = 0\n",
        "    train_correct = 0\n",
        "\n",
        "    for index, train_graph_data in enumerate(train_batches):\n",
        "       ######################## Train ########################\n",
        "        model.train()\n",
        "        model.mode = 'train'\n",
        "\n",
        "        train_batch_loss, train_batch_correct, train_batch_all = train(\n",
        "              model=model,\n",
        "              data=train_graph_data,\n",
        "              optimizer=optimizer,\n",
        "              loss_fn=criterion\n",
        "          )\n",
        "\n",
        "        print(f'Batch {index + 1} of Epoch {epoch}: Accuracy: {train_batch_correct / train_batch_all:.4f}')\n",
        "\n",
        "        epoch_loss += train_batch_loss\n",
        "        train_correct += train_batch_correct\n",
        "        train_all += train_batch_all\n",
        "\n",
        "        ######################## Validation ########################\n",
        "        model.eval()\n",
        "        model.mode = 'dev'\n",
        "\n",
        "        val_batch_correct, val_batch_all = evaluate(\n",
        "            model=model,\n",
        "            data=val_batches[index%len(val_batches)]\n",
        "        )\n",
        "\n",
        "        val_correct += val_batch_correct\n",
        "        val_all += val_batch_all\n",
        "      \n",
        "    ########## end of epoch ###########\n",
        "    print(f'{\"=\"*32} Epoch {epoch + 1} {\"=\"*32}')\n",
        "    print(f'Train Loss:          {epoch_loss:.4f}')\n",
        "    print(f'Train Cost:          {epoch_loss / train_all:.4f}')\n",
        "    print(f'Train Accuracy:      {train_correct * 100 / train_all:.3f}%')\n",
        "    print(f'Validation Accuracy: {val_correct * 100 / val_all:.3f}%')\n",
        "    logging.info(f'{\"=\"*32} Epoch {epoch + 1} {\"=\"*32}')\n",
        "    logging.info(f'Train Loss:          {epoch_loss:.4f}')\n",
        "    logging.info(f'Train Cost:          {epoch_loss / train_all:.4f}')\n",
        "    logging.info(f'Train Accuracy:      {train_correct * 100 / train_all:.3f}%')\n",
        "    logging.info(f'Validation Accuracy: {val_correct * 100 / val_all:.3f}%')\n",
        "\n",
        "    train_losses.append(epoch_loss)\n",
        "    train_accuracies.append(train_correct * 100 / train_all)\n",
        "    val_accuracies.append(val_correct * 100 / val_all)\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqnGTPwygA5O",
        "cellView": "form"
      },
      "source": [
        "#@title Results { form-width: \"15%\" }\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "t = [i for i in list(range(len(train_losses)))]\n",
        "t = np.array(t)\n",
        "y1 = np.array(train_losses)\n",
        "y2 = np.array(train_accuracies)\n",
        "y3 = np.array(val_accuracies)\n",
        "fig = plt.gcf()\n",
        "plt.plot(t, y1)\n",
        "plt.title(\"Train Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "#plt.legend(['Train', 'Validation'])\n",
        "fig.set_size_inches(20, 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnPbCyM_R3mE",
        "cellView": "form"
      },
      "source": [
        "#@title Model Test { form-width: \"25%\" }\n",
        "\n",
        "test_correct = 0\n",
        "test_all = 0\n",
        "\n",
        "for test_graph_data in test_batches:\n",
        "  model.eval()\n",
        "  model.mode = 'test'\n",
        "\n",
        "  test_batch_correct, test_batch_all = evaluate(\n",
        "      model=model,\n",
        "      data=test_graph_data\n",
        "  )\n",
        "  test_correct += test_batch_correct\n",
        "  test_all += test_batch_all\n",
        "\n",
        "print(f'Test Accuracy: {test_correct * 100 / test_all:.3f}%')\n",
        "logging.info('=' * 70)\n",
        "logging.info(f'Test Accuracy: {test_correct * 100 / test_all:.3f}%')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CawLz0bIJkCD",
        "cellView": "form"
      },
      "source": [
        "# @title Model Save\n",
        "torch.save(model.state_dict(), 'model.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTRZlmyTCWli",
        "cellView": "form"
      },
      "source": [
        "#@title VERY IMPORTANT MAIN { form-width: \"15%\" }\n",
        "\n",
        "# this is the data frame from which you want to create your graph\n",
        "dss = dataset.loc[0: 10]\n",
        "\n",
        "# messaging which should be an iterable of indices contains matches that are in the message-passing graph\n",
        "messaging = [0, 1, 3, 5, 6, 9, 10]\n",
        "\n",
        "# supervision which should be an iterable of indices contains matches that are removed\n",
        "# from the message-passing graph and are used for Link Prediction\n",
        "# could also be None if remove_supervision_links is False\n",
        "supervision=[2, 4, 7, 8] \n",
        "\n",
        "# hd is the HeteroData graph \n",
        "hd = batch_gen(\n",
        "    dss,\n",
        "    entities=entities, # must never be anything else\n",
        "    messaging = messaging, \n",
        "    supervision=supervision, \n",
        "    remove_supervision_links=True\n",
        ")\n",
        "\n",
        "hd_ei = hd.edge_index_dict\n",
        "print('\"won\" edge_list')\n",
        "print(hd_ei[('team', 'won', 'team')].t())\n",
        "print('#' * 64)\n",
        "player_nodes, team_nodes = nodes_gen(dss)\n",
        "player_hashes = {value: key for key, value in player_nodes.items()}\n",
        "team_hashes = {value: key for key, value in team_nodes.items()}\n",
        "\n",
        "print('Team nodes and hashes')\n",
        "for i, j in team_nodes.items():\n",
        "  print(f'{j:<40}{i}')\n",
        "print('#' * 64)\n",
        "print('Result of supervision matches')\n",
        "print(hd.y)\n",
        "print('#' * 64)\n",
        "print('home teams')\n",
        "print(hd.home_list)\n",
        "print('#' * 64)\n",
        "print('away teams')\n",
        "print(hd.away_list)\n",
        "print('#' * 64)\n",
        "print('home nodes')\n",
        "print([team_hashes[team_node] for team_node in hd.home_list])\n",
        "print('#' * 64)\n",
        "print('away nodes')\n",
        "print([team_hashes[team_node] for team_node in hd.away_list])\n",
        "dss\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "fTEsrUB1bbIy"
      },
      "source": [
        "#@title Custom Train Method { form-width: \"15%\" }\n",
        "model.reset_parameters()\n",
        "dataframe = dataset.loc[0:599, :]\n",
        "messaging_indcs = dataframe.sample(frac=0.85).index\n",
        "supervision_indcs = dataframe.drop(messaging_indc).index\n",
        "hetero_data = batch_gen(\n",
        "    dataframe, \n",
        "    entities, \n",
        "    remove_supervision_links=True,\n",
        "    messaging=messaging_indcs,\n",
        "    supervision=supervision_indcs\n",
        ")\n",
        "for _ in range(15):\n",
        "  print(train(model, hetero_data, optimizer, criterion))\n",
        "\n",
        "hetero_data2 = batch_gen(\n",
        "    dataframe, \n",
        "    entities, \n",
        "    remove_supervision_links=False,\n",
        "    supervision=supervision_indcs\n",
        ")\n",
        "\n",
        "for _ in range(150):\n",
        "  print(train(model, hetero_data2, optimizer, criterion))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDZDgbsEAusX",
        "cellView": "form"
      },
      "source": [
        "#@title Custom Training Method 2  { form-width: \"15%\" }\n",
        "\n",
        "ds = dataset.loc[:6549, :]\n",
        "\n",
        "hd = batch_gen(\n",
        "    ds,\n",
        "    entities=entities,\n",
        "    messaging=ds.index,\n",
        "    supervision=ds.sample(frac=0.3).index,\n",
        "    remove_supervision_links=False)\n",
        "for i in range(10000):\n",
        "  for j in range(300, 3200, 100):\n",
        "    ds = dataset.loc[j - 300:j - 1, :]\n",
        "    r = ds.sample(frac=0.1).index\n",
        "    hd = batch_gen(\n",
        "        ds,\n",
        "        entities=entities,\n",
        "        messaging=ds.index,\n",
        "        supervision=r,\n",
        "        remove_supervision_links=False\n",
        "    )\n",
        "    print(f'Epoch {i+1}: {train(model, hd, optimizer, criterion)}')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}