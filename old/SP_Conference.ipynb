{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SP Conference.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2qSNYEZJvXo",
        "cellView": "form"
      },
      "source": [
        "#@title PyG Installation { form-width: \"25%\" }\n",
        "# enter these commands in CLI to install Pytorch-Geometric\n",
        "!pip install -q torch-scatter -f https://pytorch-geometric.com/whl/torch-1.9.0+cu111.html\n",
        "!pip install -q torch-sparse -f https://pytorch-geometric.com/whl/torch-1.9.0+cu111.html\n",
        "!pip install -q git+https://github.com/rusty1s/pytorch_geometric.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQ7zuNoJKXec"
      },
      "source": [
        "#@title Module Imports { form-width: \"20%\" }\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.nn import Module,\\\n",
        "                     ModuleList,\\\n",
        "                     Embedding,\\\n",
        "                     BatchNorm1d,\\\n",
        "                     LogSoftmax,\\\n",
        "                     Softmax,\\\n",
        "                     Linear,\\\n",
        "                     NLLLoss,\\\n",
        "                     CrossEntropyLoss\n",
        "from torch.optim import Adam\n",
        "import torch.nn.functional as F\n",
        "import torch_geometric as PyG\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn.conv import RGCNConv\n",
        "from torch_geometric.utils import to_networkx\n",
        "from collections import OrderedDict as od\n",
        "import logging\n",
        "import json\n",
        "from typing import NoReturn\n",
        "import typing"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnJRJ5pTW_rR",
        "cellView": "form",
        "outputId": "cf433afa-88a1-45f0-843f-2540c770c15e"
      },
      "source": [
        "#@title Global Variables\n",
        "# Global Values\n",
        "WON = 0\n",
        "LOST_TO = 1\n",
        "TIED_WITH = 2\n",
        "PLAYED_IN = 3\n",
        "USED = 4\n",
        "BEFORE = 5\n",
        "AFTER = 6\n",
        "\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f'Device is {DEVICE}')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device is cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mH-QslHEJdRg",
        "cellView": "form"
      },
      "source": [
        "#@title GNN Model { form-width: \"10%\" }\n",
        "class GNN(Module):\n",
        "  def __init__(self, embedding_dims: tuple, conv_dims: list, fully_connected_dims: list, dropout: dict)-> NoReturn:\n",
        "    super(GNN, self).__init__()\n",
        "\n",
        "    self.mode = None # 'train' or 'test' or 'dev' later \n",
        "    self.output_dim = 3 #home_result: win, lose, tie\n",
        "    self.num_relations = 7 #win/lose/tie/play/use/after/before\n",
        "    self.dropout = dropout\n",
        "\n",
        "    #one-hot to latent\n",
        "    self.embed = Embedding(embedding_dims[0], embedding_dims[1])\n",
        "\n",
        "    conv_list = [\n",
        "                  RGCNConv(embedding_dims[1], conv_dims[0], self.num_relations)\n",
        "                ] + \\\n",
        "                [\n",
        "                  RGCNConv(conv_dims[i], conv_dims[i+1], self.num_relations)\n",
        "                  for i in range(len(conv_dims[:-1]))\n",
        "                ]\n",
        "  \n",
        "    batch_norm_list = [\n",
        "                         BatchNorm1d(conv_dims[i])\n",
        "                         for i in range(len(conv_dims[:-1]))\n",
        "                      ]\n",
        "\n",
        "    fully_connected_list =   [\n",
        "                                Linear(2*conv_dims[-1], fully_connected_dims[0])\n",
        "                             ] + \\\n",
        "                             [\n",
        "                                Linear(fully_connected_dims[i], fully_connected_dims[i+1])\n",
        "                                for i in range(len(fully_connected_dims[:-1]))\n",
        "                             ] + \\\n",
        "                             [\n",
        "                                Linear(fully_connected_dims[-1], self.output_dim)\n",
        "                             ]\n",
        "    #graph conv layers\n",
        "    self.conv_layers = ModuleList(conv_list)\n",
        "    #batch normalization layers\n",
        "    self.batch_norm_layers = ModuleList(batch_norm_list)\n",
        "    #fully connected dense layers\n",
        "    self.fully_connected_layers = ModuleList(fully_connected_list)\n",
        "\n",
        "    self.classifier = LogSoftmax()\n",
        "\n",
        "    \n",
        "  def reset_parameters(self):\n",
        "        for conv in self.conv_layers:\n",
        "            conv.reset_parameters()\n",
        "        for bn in self.batch_norm_layers:\n",
        "            bn.reset_parameters()\n",
        "        for fc in self.fully_connected_layers:\n",
        "            fc.reset_parameters()\n",
        "          \n",
        "\n",
        "  def forward(self, x:torch.Tensor, edge_index:torch.Tensor, edge_type:torch.Tensor, home_list:list, away_list:list) -> torch.Tensor:\n",
        "    x = self.embed(x)\n",
        "    if self.training:\n",
        "      x = F.dropout(x, p=self.dropout[\"emb\"])\n",
        "\n",
        "    for conv, bn in zip(self.conv_layers[:-1], self.batch_norm_layers):\n",
        "      x = conv(x, edge_index=edge_index, edge_type=edge_type)\n",
        "      x = bn(x)\n",
        "      x = F.relu(x)\n",
        "      if self.training:\n",
        "        x = F.dropout(x, p=self.dropout[\"conv\"])\n",
        "\n",
        "\n",
        "    x = self.conv_layers[-1](x, edge_index, edge_type)\n",
        "    if self.training:\n",
        "      x = F.dropout(x, p=self.dropout[\"conv\"])\n",
        "\n",
        "    ##################################### End of Encoder \n",
        "\n",
        "    pred = list()\n",
        "    for home_team, away_team in zip(home_list, away_list):\n",
        "      h = torch.cat((x[home_team], x[away_team]))\n",
        "\n",
        "      for fc in self.fully_connected_layers[:-1]:\n",
        "        h = fc(h)\n",
        "        h = F.relu(h)\n",
        "        if self.training:\n",
        "          h = F.dropout(h, p=self.dropout[\"fc\"])\n",
        "\n",
        "      h = self.fully_connected_layers[-1](h)\n",
        "      if self.training:\n",
        "        h = F.dropout(h, p=self.dropout[\"fc\"])\n",
        "      pred.append(self.classifier(h))\n",
        "\n",
        "    return torch.stack(pred)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6A79n7S5HuLn",
        "cellView": "form"
      },
      "source": [
        "#@title home_result(row)\n",
        "def home_result(row: str) -> int:\n",
        "  if row == 'home':\n",
        "    return WON\n",
        "  elif row == 'tie':\n",
        "    return TIED_WITH\n",
        "  elif row == 'away':\n",
        "    return LOST_TO"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bDOBoy9YJdW",
        "cellView": "form"
      },
      "source": [
        "#@title remove_redundancy(players) { form-width: \"15%\" }\n",
        "def remove_redundancy(players: list) -> list:\n",
        "  new_players = list()\n",
        "\n",
        "  for player in players:\n",
        "    if 'Own' in player:\n",
        "      player = player.replace('Own', '')\n",
        "    if 'Pen. Scored' in player:\n",
        "      player = player.replace('Pen. Scored', '')\n",
        "    if 'Pen. Score' in player:\n",
        "      player = player.replace('Pen. Score', '')\n",
        "    if 'Own' in player or 'Scored' in player or 'Score' in player:\n",
        "      print(player)\n",
        "      #SHOULD NOT PRINT IF CODE IS CORRECT\n",
        "    else:\n",
        "      new_players.append(player.strip())\n",
        "  return new_players"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76-OzUe-8V6_",
        "cellView": "form"
      },
      "source": [
        "#@title extract_players(home_lineup, away_lineup) { form-width: \"15%\" }\n",
        "def extract_players(home_lineup: str, away_lineup: str) -> list:\n",
        "  home_players = home_lineup[:-2].split(' - ')\n",
        "  away_players = away_lineup[:-2].split(' - ')\n",
        "  \n",
        "  return remove_redundancy(home_players), remove_redundancy(away_players)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdvbloHFNou-",
        "cellView": "form"
      },
      "source": [
        "#@title stats(df, show_players, show_teams, show_results) { form-width: \"10%\" }\n",
        "def stats(df: pd.DataFrame, show_players: bool=False, show_teams: bool=False, show_results: bool=False) -> NoReturn:\n",
        "  players_set = set()\n",
        "  players_list = list()\n",
        "  teams_set = set()\n",
        "\n",
        "  teams_list = list()\n",
        "  results = dict()\n",
        "  for index, (h_team, a_team, result, h_lineup, a_lineup) in df.iterrows():\n",
        "    home_players, away_players = extract_players(h_lineup, a_lineup)\n",
        "    players_set.update(home_players + away_players)\n",
        "    players_list.extend(home_players + away_players)\n",
        "    if result == 'home':\n",
        "      results.update({f'{h_team} #Wins': results.get(f'{h_team} #Wins', 0)+1})\n",
        "      results.update({f'{a_team} #Losses': results.get(f'{a_team} #Losses', 0)+1})\n",
        "    elif result == 'tie':\n",
        "      results.update({f'{h_team} #Ties': results.get(f'{h_team} #Ties', 0)+1})\n",
        "      results.update({f'{a_team} #Ties': results.get(f'{a_team} #Ties', 0)+1})\n",
        "    else:\n",
        "      results.update({f'{a_team} #Wins': results.get(f'{a_team} #Wins', 0)+1})\n",
        "      results.update({f'{h_team} #Losses': results.get(f'{h_team} #Losses', 0)+1})\n",
        "\n",
        "    teams_list.extend([h_team, a_team])\n",
        "    teams_set.update([h_team, a_team])\n",
        "    \n",
        "  if show_players:\n",
        "    for player in players_set:\n",
        "      print(f'{player} played in {players_list.count(player)} matches.')\n",
        "  if show_teams:\n",
        "    for team in teams_set:\n",
        "      print(f'{team} played {teams_list.count(team)} matches.')\n",
        "  if show_results:\n",
        "    results = od(sorted(results.items()))\n",
        "    for key, val in results.items():\n",
        "      print(f'{key}: {val}')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21iE53JDdbfE",
        "cellView": "form"
      },
      "source": [
        "#@title extract_entities(df) { form-width: \"15%\" }\n",
        "def extract_entities(df: pd.DataFrame) -> typing.Tuple[set, set]:\n",
        "  players_set = set()\n",
        "  players_list = list()\n",
        "  teams_set = set()\n",
        "\n",
        "  teams_list = list()\n",
        "  # results = dict()\n",
        "  for index, (h_team, a_team, result, h_lineup, a_lineup) in df.iterrows():\n",
        "    home_players, away_players = extract_players(h_lineup, a_lineup)\n",
        "\n",
        "    players_set.update(home_players + away_players)\n",
        "    teams_set.update([h_team, a_team])\n",
        "    \n",
        "  \n",
        "  return teams_set, players_set"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFDbVt67eJOR",
        "cellView": "form"
      },
      "source": [
        "#@title gen_entites(df) { form-width: \"15%\" }\n",
        "def gen_entities(df: pd.DataFrame) -> dict:\n",
        "  teams, players = extract_entities(df)\n",
        "  entities = {entity: index for index, entity in enumerate(list(players) + list(teams))}\n",
        "  return entities"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHLHaaFaond8"
      },
      "source": [
        "#@title nodes_gen(df) { form-width: \"15%\" }\n",
        "def nodes_gen(df: pd.DataFrame) -> dict:\n",
        "  nodes = dict()\n",
        "  node_counter = 0\n",
        "\n",
        "  for index, (h_team, a_team, result, h_lineup, a_lineup) in df.iterrows():\n",
        "      home_players, away_players = extract_players(h_lineup, a_lineup)\n",
        "\n",
        "      for player_index, player in enumerate(home_players):\n",
        "        nodes[f'{player}@{index}'] = node_counter\n",
        "        node_counter += 1\n",
        "      for player_index, player in enumerate(away_players):\n",
        "        nodes[f'{player}@{index}'] = node_counter\n",
        "        node_counter += 1\n",
        "\n",
        "      nodes[f'{h_team}*{index}'] = node_counter\n",
        "      node_counter += 1\n",
        "\n",
        "      nodes[f'{a_team}*{index}'] = node_counter\n",
        "      node_counter += 1\n",
        "\n",
        "  return nodes\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aAQy1k6SIwn",
        "cellView": "form"
      },
      "source": [
        "#@title show_edges(df, edge, edge_type) { form-width: \"15%\" }\n",
        "def show_edges(df: pd.DataFrame, edge: torch.Tensor, edge_type: torch.Tensor) -> NoReturn:\n",
        "  types = {\n",
        "      0: 'Won',\n",
        "      1: 'Lost To',\n",
        "      2: 'Tied With',\n",
        "      3: 'Played For',\n",
        "      4: 'Used As Player',\n",
        "      5: 'Is Before',\n",
        "      6: 'Is After'\n",
        "  }\n",
        "  nodes = nodes_gen(df)\n",
        "  r = {k:v for v, k in nodes.items()}\n",
        "  for i in range(edge_type.shape[0]):\n",
        "    head = int(edge[0][i].item())\n",
        "    tail = int(edge[1][i].item())\n",
        "    relation = int(edge_type[i].item())\n",
        "    arrow = f'=== {types[relation]} ===>'\n",
        "    print(f'{r[head]:<32}   {arrow}   {r[tail]:>32}')"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdqdirL9lxjP",
        "cellView": "form"
      },
      "source": [
        "#@title home_won_gen(df) { form-width: \"15%\" }\n",
        "def home_won_gen(df: pd.DataFrame) -> typing.Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
        "  home_winning_matches = df.loc[df['result'] == 'home']\n",
        "  home_winners = home_winning_matches['home_team']\n",
        "  away_losers = home_winning_matches['away_team']\n",
        "\n",
        "  winning_hashes = list()\n",
        "  losing_hashes = list()\n",
        "\n",
        "  for home, away, match in zip(home_winners, away_losers, home_winners.index):\n",
        "    winning_hashes.append(f'{home}*{match}')\n",
        "    losing_hashes.append(f'{away}*{match}')\n",
        "\n",
        "  winning_nodes = list()\n",
        "  losing_nodes = list()\n",
        "\n",
        "  nodes = nodes_gen(df)\n",
        "\n",
        "  for winner, loser in zip(winning_hashes, losing_hashes):\n",
        "    winning_nodes.append(nodes[winner]) \n",
        "    losing_nodes.append(nodes[loser])\n",
        "\n",
        "  won_edges = torch.tensor(\n",
        "      [\n",
        "      winning_nodes,\n",
        "      losing_nodes\n",
        "      ], \n",
        "      dtype=torch.long,\n",
        "      device=DEVICE\n",
        "  )\n",
        "\n",
        "  lost_edges = torch.tensor(\n",
        "      [\n",
        "      losing_nodes,\n",
        "      winning_nodes\n",
        "      ],\n",
        "      dtype=torch.long,\n",
        "      device=DEVICE\n",
        "  )\n",
        "\n",
        "  won_edge_types = torch.ones(won_edges.shape[1], dtype=torch.long, device=DEVICE) * WON\n",
        "  lost_edge_types = torch.ones(lost_edges.shape[1], dtype=torch.long, device=DEVICE) * LOST_TO \n",
        "\n",
        "  return won_edges, won_edge_types, lost_edges, lost_edge_types"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LypA1Sinw94O",
        "cellView": "form"
      },
      "source": [
        "#@title away_won_gen(df) { form-width: \"15%\" }\n",
        "def away_won_gen(df: pd.DataFrame) -> typing.Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
        "  away_winning_matches = df.loc[df['result'] == 'away']\n",
        "  away_winners = away_winning_matches['away_team']\n",
        "  home_losers = away_winning_matches['home_team']\n",
        "\n",
        "  winning_hashes = list()\n",
        "  losing_hashes = list()\n",
        "\n",
        "  for home, away, match in zip(home_losers, away_winners, away_winners.index):\n",
        "    winning_hashes.append(f'{away}*{match}')\n",
        "    losing_hashes.append(f'{home}*{match}')\n",
        "\n",
        "  winning_nodes = list()\n",
        "  losing_nodes = list()\n",
        "\n",
        "  nodes = nodes_gen(df)\n",
        "\n",
        "  for winner, loser in zip(winning_hashes, losing_hashes):\n",
        "    winning_nodes.append(nodes[winner]) \n",
        "    losing_nodes.append(nodes[loser])\n",
        "\n",
        "  won_edges = torch.tensor(\n",
        "      [\n",
        "      winning_nodes,\n",
        "      losing_nodes\n",
        "      ],\n",
        "      dtype=torch.long,\n",
        "      device=DEVICE\n",
        "  )\n",
        "\n",
        "  lost_edges = torch.tensor(\n",
        "      [\n",
        "      losing_nodes,\n",
        "      winning_nodes\n",
        "      ],\n",
        "      dtype=torch.long,\n",
        "      device=DEVICE\n",
        "  )\n",
        "  \n",
        "  won_edge_types = torch.ones(won_edges.shape[1], dtype=torch.long, device=DEVICE) * WON\n",
        "  lost_edge_types = torch.ones(lost_edges.shape[1], dtype=torch.long, device=DEVICE) * LOST_TO \n",
        "  \n",
        "  return won_edges, won_edge_types, lost_edges, lost_edge_types"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQUZPKoQyEYp",
        "cellView": "form"
      },
      "source": [
        "#@title tied_gen(df) { form-width: \"25%\" }\n",
        "def tied_gen(df: pd.DataFrame) -> typing.Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
        "  tied_matches = df.loc[df['result'] == 'tie']\n",
        "  home_teams = tied_matches['home_team']\n",
        "  away_teams = tied_matches['away_team']\n",
        "\n",
        "  home_hashes = list()\n",
        "  away_hashes = list()\n",
        "\n",
        "  for home, away, match in zip(home_teams, away_teams, away_teams.index):\n",
        "    away_hashes.append(f'{away}*{match}')\n",
        "    home_hashes.append(f'{home}*{match}')\n",
        "\n",
        "  home_nodes = list()\n",
        "  away_nodes = list()\n",
        "\n",
        "  nodes = nodes_gen(df)\n",
        "\n",
        "  for home, away in zip(home_hashes, away_hashes):\n",
        "    home_nodes.append(nodes[home]) \n",
        "    away_nodes.append(nodes[away])\n",
        "\n",
        "  home_tied_edges = torch.tensor(\n",
        "      [\n",
        "      home_nodes,\n",
        "      away_nodes\n",
        "      ],\n",
        "      dtype=torch.long,\n",
        "      device=DEVICE\n",
        "  )\n",
        "\n",
        "  away_tied_edges = torch.tensor(\n",
        "      [\n",
        "      away_nodes,\n",
        "      home_nodes\n",
        "      ], \n",
        "      dtype=torch.long,\n",
        "      device=DEVICE\n",
        "  )\n",
        "\n",
        "  home_tied_edge_types = torch.ones(home_tied_edges.shape[1], dtype=torch.long, device=DEVICE) * TIED_WITH\n",
        "  away_tied_edge_types = torch.ones(away_tied_edges.shape[1], dtype=torch.long, device=DEVICE) * TIED_WITH\n",
        "\n",
        "  return home_tied_edges, home_tied_edge_types, away_tied_edges, away_tied_edge_types"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIGBYohP5znW",
        "cellView": "form"
      },
      "source": [
        "#@title played_used_gen(df) { form-width: \"15%\" }\n",
        "def played_used_gen(df: pd.DataFrame) -> typing.Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
        "  team_nodes = list()\n",
        "  player_nodes = list()\n",
        "\n",
        "  nodes = nodes_gen(df)\n",
        "\n",
        "  for index, (h_team, a_team, result, h_lineup, a_lineup) in df.iterrows():\n",
        "    home_players, away_players = extract_players(h_lineup, a_lineup)\n",
        "\n",
        "    for home_player, away_player in zip(home_players, away_players):\n",
        "      player_nodes.append(nodes[f'{home_player}@{index}'])\n",
        "      team_nodes.append(nodes[f'{h_team}*{index}'])\n",
        "      player_nodes.append(nodes[f'{away_player}@{index}'])\n",
        "      team_nodes.append(nodes[f'{a_team}*{index}'])\n",
        "\n",
        "  played_in_edges = torch.tensor(\n",
        "      [\n",
        "       player_nodes,\n",
        "       team_nodes\n",
        "      ],\n",
        "      dtype=torch.long,\n",
        "      device=DEVICE\n",
        "  )\n",
        "\n",
        "  played_in_edge_types = torch.ones(played_in_edges.shape[1], dtype=torch.long, device=DEVICE) * PLAYED_IN\n",
        "\n",
        "  used_edges = torch.tensor(\n",
        "      [\n",
        "       team_nodes,\n",
        "       player_nodes\n",
        "      ],\n",
        "      dtype=torch.long,\n",
        "      device=DEVICE\n",
        "  ) \n",
        "\n",
        "  used_edge_types = torch.ones(used_edges.shape[1], dtype=torch.long, device=DEVICE) * USED\n",
        "\n",
        "  return played_in_edges, played_in_edge_types, used_edges, used_edge_types"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kily_SD775Ic",
        "cellView": "form"
      },
      "source": [
        "#@title players_before_after_gen(df) TODO { form-width: \"15%\" }\n",
        "#TODO\n",
        "def players_before_after_gen(df: pd.DataFrame) -> typing.Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
        "  player_match_hashes = list()\n",
        "\n",
        "  for index, (h_team, a_team, result, h_lineup, a_lineup) in df.iterrows():\n",
        "      home_players, away_players = extract_players(h_lineup, a_lineup)\n",
        "\n",
        "      for player in home_players + away_players:\n",
        "        player_match_hashes.append(f'{player}@{index}')\n",
        "\n",
        "\n",
        "\n",
        "  sorted_hashes = sorted(\n",
        "      player_match_hashes,\n",
        "      key=lambda w: (w.split('@')[0], int(w.split('@')[1]))\n",
        "  )\n",
        "\n",
        "  before_nodes = list()\n",
        "  after_nodes = list()\n",
        "\n",
        "  nodes = nodes_gen(df)\n",
        "\n",
        "  for index, hash in enumerate(sorted_hashes):\n",
        "    player, match = hash.split('@')\n",
        "    before_node = nodes[hash]\n",
        "    try:\n",
        "      after_node = nodes[sorted_hashes[index+1]]\n",
        "      before_name = hashes[before_node].split('@')[0]\n",
        "      after_name = hashes[after_node].split('@')[0]\n",
        "      if before_name == after_name:\n",
        "        before_nodes.append(before_node)\n",
        "        after_nodes.append(after_node)\n",
        "    except:\n",
        "      pass\n",
        "  before_edges = torch.tensor(\n",
        "      [\n",
        "      before_nodes,\n",
        "      after_nodes\n",
        "      ], dtype=torch.long,\n",
        "      device=DEVICE\n",
        "  )\n",
        "\n",
        "  before_edge_types = torch.ones(before_edges.shape[1], dtype=torch.long, device=DEVICE) * BEFORE\n",
        "\n",
        "  after_edges = torch.tensor(\n",
        "      [\n",
        "      after_nodes,\n",
        "      before_nodes\n",
        "      ], dtype=torch.long,\n",
        "      device=DEVICE\n",
        "  )\n",
        "\n",
        "  after_edge_types = torch.ones(after_edges.shape[1], dtype= torch.long, device=DEVICE) * AFTER\n",
        "\n",
        "  return before_edges, before_edge_types, after_edges, after_edge_types"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lk24VmcKFTF_",
        "cellView": "form"
      },
      "source": [
        "#@title teams_before_after_gen(df) { form-width: \"15%\" }\n",
        "def teams_before_after_gen(df: pd.DataFrame) -> typing.Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
        "  team_match_hashes = list()\n",
        "\n",
        "  for index, (h_team, a_team, result, h_lineup, a_lineup) in df.iterrows():\n",
        "      team_match_hashes.append(f'{h_team}*{index}')\n",
        "      team_match_hashes.append(f'{a_team}*{index}')\n",
        "\n",
        "  sorted_hashes = sorted(\n",
        "      team_match_hashes,\n",
        "      key= lambda w: (w.split('*')[0], int(w.split('*')[1]))\n",
        "  )\n",
        "\n",
        "  before_nodes = list()\n",
        "  after_nodes = list()\n",
        "\n",
        "  nodes = nodes_gen(df)\n",
        "\n",
        "  for index, hash in enumerate(sorted_hashes):\n",
        "    team, match = hash.split('*')\n",
        "    before_node = nodes[hash]\n",
        "    try:\n",
        "      after_node = nodes[sorted_hashes[index+1]]\n",
        "      before_name = hashes[before_node].split('*')[0]\n",
        "      after_name = hashes[after_node].split('*')[0]\n",
        "      if before_name == after_name:\n",
        "        before_nodes.append(before_node)\n",
        "        after_nodes.append(after_node)\n",
        "    except:\n",
        "      pass\n",
        "  before_edges = torch.tensor(\n",
        "      [\n",
        "      before_nodes,\n",
        "      after_nodes\n",
        "      ], dtype=torch.long,\n",
        "      device=DEVICE\n",
        "  )\n",
        "\n",
        "  before_edge_types = torch.ones(before_edges.shape[1], dtype=torch.long, device=DEVICE) * BEFORE\n",
        "\n",
        "  after_edges = torch.tensor(\n",
        "      [\n",
        "      after_nodes,\n",
        "      before_nodes\n",
        "      ], dtype=torch.long,\n",
        "      device=DEVICE\n",
        "  )\n",
        "\n",
        "  after_edge_types = torch.ones(after_edges.shape[1], dtype=torch.long, device=DEVICE) * AFTER\n",
        "\n",
        "  return before_edges, before_edge_types, after_edges, after_edge_types"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53RV4ZRUxgaG",
        "cellView": "form"
      },
      "source": [
        "#@title complete_graph_gen(df, for_players, for_teams) { form-width: \"10%\" }\n",
        "def complete_graph_edge_gen(df: pd.DataFrame, for_players: bool=True, for_teams: bool=True) -> typing.Tuple[torch.Tensor, torch.Tensor]:\n",
        "\n",
        "  home_win, won1, away_lost, lost1 = home_won_gen(df)\n",
        "  away_won, won2, home_lost, lost2 = away_won_gen(df)\n",
        "  home_tied, tied1, away_tied, tied2 = tied_gen(df)\n",
        "  player_played, played1, team_used, used1 = played_used_gen(df)\n",
        "\n",
        "  edge_index = torch.cat(\n",
        "        (home_win, away_lost, away_won, home_lost, home_tied, away_tied, player_played, team_used),\n",
        "        dim=1\n",
        "    )\n",
        "  \n",
        "  edge_type = torch.cat(\n",
        "        (won1, lost1, won2, lost2, tied1, tied2, played1, used1)\n",
        "    )\n",
        "\n",
        "  if for_players:\n",
        "    player_before, before1, player_after, after1 = players_before_after_gen(df)\n",
        "    edge_index = torch.cat((edge_index, player_before, player_after), dim=1)\n",
        "    edge_type = torch.cat((edge_type, before1, after1))\n",
        "  if for_teams:\n",
        "    team_before, before2, team_after, after2 = teams_before_after_gen(df)\n",
        "    edge_index = torch.cat((edge_index, team_before, team_after), dim=1)\n",
        "    edge_type = torch.cat((edge_type, before2, after2))\n",
        "\n",
        "  return edge_index, edge_type    "
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVhN2L8f1cBV"
      },
      "source": [
        "#@title supervision_graph_gen(df, for_players, for_teams, log_supervision_matches) { form-width: \"10%\" }\n",
        "#TODO idea1: messaging=[1, 2, 3, ..., 10], supervision=[11, 12, ..., 15]\n",
        "def supervision_graph_gen(df : pd.DataFrame, for_players: bool=True, for_teams: bool=True, log_supervision_matches: bool=False) -> typing.Tuple[torch.Tensor, torch.Tensor]:\n",
        "  ######################################################### TODO\n",
        "  if df.shape[0] > 10:\n",
        "    first_match = df.index[0]\n",
        "    last_match = df.index[-11]\n",
        "  else:\n",
        "    first_match = df.index[1]\n",
        "    last_match = df.index[df.shape[0] * -1]\n",
        "  ######################################################### TODO\n",
        "  if log_supervision_matches:\n",
        "    if model.mode == 'train':\n",
        "      mode = 'training'\n",
        "    elif model.mode == 'dev':\n",
        "      mode = 'validating'\n",
        "    elif model.mode == 'test':\n",
        "      mode = 'testing'\n",
        "    logging.info(\n",
        "        f'Messaging on matches ({first_match + 1} -> {last_match + 1:>5}),\\ Model is {mode} on matches ({last_match+2} -> {last_match + 11})'\n",
        "    )\n",
        "  ########################################### TODO\n",
        "  arg = df[messaging] [1, 2, 3, 10, 11, 12 ] \n",
        "  ########################################### TODO\n",
        "  home_win, won1, away_lost, lost1 = home_won_gen(df.loc[first_match: last_match, :])\n",
        "  away_won, won2, home_lost, lost2 = away_won_gen(df.loc[first_match: last_match, :])\n",
        "  home_tied, tied1, away_tied, tied2 = tied_gen(df.loc[first_match: last_match, :])\n",
        "  player_played, played1, team_used, used1 = played_used_gen(df)\n",
        "\n",
        "  edge_index = torch.cat(\n",
        "        (home_win, away_lost, away_won, home_lost, home_tied, away_tied, player_played, team_used),\n",
        "        dim=1\n",
        "    )\n",
        "  \n",
        "  edge_type = torch.cat(\n",
        "        (won1, lost1, won2, lost2, tied1, tied2, played1, used1)\n",
        "    )\n",
        "  \n",
        "  if for_players:\n",
        "    player_before, before1, player_after, after1 = players_before_after_gen(df)\n",
        "    edge_index = torch.cat((edge_index, player_before, player_after), dim=1)\n",
        "    edge_type = torch.cat((edge_type, before1, after1))\n",
        "  if for_teams:\n",
        "    team_before, before2, team_after, after2 = teams_before_after_gen(df)\n",
        "    edge_index = torch.cat((edge_index, team_before, team_after), dim=1)\n",
        "    edge_type = torch.cat((edge_type, before2, after2))\n",
        "\n",
        "  return edge_index, edge_type "
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgU60cSGL85X"
      },
      "source": [
        "#@title data_gen(df, remove_supervision_links, for_players, for_teams, print_edges, log_supervision_matches) { form-width: \"10%\" }\n",
        "def data_gen(df: pd.DataFrame, remove_supervision_links: bool=True, for_players: bool=True, for_teams: bool=True, print_edges: bool=False, log_supervision_matches: bool=False) -> Data:\n",
        "  if print_edges:\n",
        "    show_edges(df, edge_index, edge_type)\n",
        "  if remove_supervision_links:\n",
        "    edge_index, edge_type = supervision_graph_gen(df, for_players=for_players, for_teams=for_teams, log_supervision_matches=log_supervision_matches)\n",
        "    ##################################################################\n",
        "    if df.shape[0] > 10:\n",
        "      first_supervision_match = df.index[-10]\n",
        "      last_supervision_match = df.index[-1]\n",
        "    else:\n",
        "      first_supervision_match = df.index[0]\n",
        "      last_supervision_match = df.index[-1]\n",
        "    y = torch.tensor(\n",
        "        df.loc[first_supervision_match:last_supervision_match, :]['result'].map(home_result).values,\n",
        "        device=DEVICE\n",
        "    )\n",
        "    ###################################################################\n",
        "\n",
        "  else:\n",
        "    edge_index, edge_type = complete_graph_edge_gen(df, for_players, for_teams)\n",
        "    y = torch.tensor(\n",
        "        df['result'].map(home_result).values,\n",
        "        device=DEVICE\n",
        "    )\n",
        "\n",
        "  ############################## OK\n",
        "  x = torch.tensor(torch.unique(edge_index), dtype=torch.int64, device=DEVICE)\n",
        "  ############################## OK\n",
        "  \n",
        "  \n",
        "  data = Data(x=x, y=y, edge_index=edge_index, edge_type = edge_type)\n",
        "  return data"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T13E2VxefgaL",
        "cellView": "form"
      },
      "source": [
        "#@title visualzie_graph(df, width, height, title, remove_supervision_links) { form-width: \"10%\" }\n",
        "def visualize_graph(df:pd.DataFrame, width: int=20, height: int=20, title: str=None, remove_supervision_links: bool=False) -> NoReturn:\n",
        "  import networkx as nx\n",
        "  import matplotlib.pyplot as plt\n",
        "  nodes = nodes_gen(df)\n",
        "  r = {k:v for v, k in nodes.items()}\n",
        "  d = data_gen(df, remove_supervision_links=remove_supervision_links)\n",
        "  G = to_networkx(d)\n",
        "  types = {\n",
        "        0: 'Won',\n",
        "        1: 'Lost To',\n",
        "        2: 'Tied With',\n",
        "        3: 'Played For',\n",
        "        4: 'Used As Player',\n",
        "        5: 'Is Before',\n",
        "        6: 'Is After'\n",
        "  }\n",
        "\n",
        "  type_color = {\n",
        "      0: '#00ff00', #won\n",
        "      1: '#ff0000', #lost to\n",
        "      2: '#e6d70e', #tied with\n",
        "      3: '#1338f0', #played for\n",
        "      4: '#f01373', #used as player\n",
        "      5: '#0f072e', #is before\n",
        "      6: '#d909cb' #is after\n",
        "  }\n",
        "\n",
        "  double_edge_types = {\n",
        "      0: '(Won[green] - Lost to[red])',\n",
        "      1: '(Lost to[red] - Won[green])',\n",
        "      2: '(Tied with[yellow])',\n",
        "      3: '(Played for[blue] - Used as Player[pink])',\n",
        "      4: '(Used as Player[pink] - Played for[blue])',\n",
        "      5: '(Is Before[dark blue] - Is After[purple])',\n",
        "      6: '(Is After[purple] - Is Before[dark blue])'\n",
        "  }\n",
        "\n",
        "  link_colors = dict(zip(\n",
        "        types.values(),\n",
        "        type_color.values()\n",
        "      )\n",
        "  )\n",
        "\n",
        "  node_colors = {\n",
        "      'player-color': '#8f0ba1',\n",
        "      'team-color': '#02fae1'   \n",
        "  }\n",
        "\n",
        "  all_colors = link_colors.copy()\n",
        "  all_colors.update(node_colors)\n",
        "\n",
        "  \n",
        "\n",
        "  for color_use in all_colors.keys():\n",
        "      plt.scatter([],[], c=[all_colors[color_use]], label=f'{color_use}')\n",
        "\n",
        "  edge_colors = list()\n",
        "  edge_labels = dict()\n",
        "\n",
        "  ######################################################## NOT OPTIMIZED\n",
        "  for edge in G.edges():\n",
        "    e = torch.tensor(edge, device=DEVICE)\n",
        "    for index, node_node in enumerate(d.edge_index.t()):\n",
        "      if torch.equal(e, node_node):\n",
        "        edge_colors.append(type_color[d.edge_type[index].item()])\n",
        "        label = double_edge_types[d.edge_type[index].item()]\n",
        "        edge_labels.update({edge:label})\n",
        "  colors = list()\n",
        "  node_labels = dict()\n",
        "  for node in G.nodes():\n",
        "    if '@' in r[node]:\n",
        "      colors.append(all_colors['player-color'])\n",
        "      node_labels.update({node: r[node].split('@')[0]})\n",
        "    elif '*' in r[node]:\n",
        "      colors.append(all_colors['team-color'])\n",
        "      node_labels.update({node:r[node].split('*')[0]})\n",
        "  ######################################################## NOT OPTIMIZED\n",
        "\n",
        "  fig = plt.gcf()\n",
        "  fig.set_size_inches(width, height)\n",
        "  pos = nx.spring_layout(G)\n",
        "  nx.draw_networkx_nodes(G, pos, node_color=colors)\n",
        "  nx.draw_networkx_labels(G, pos, labels=node_labels)\n",
        "  nx.draw_networkx_edges(G, pos, edge_color=edge_colors, connectionstyle='arc3,rad=0.05')\n",
        "  nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels)\n",
        "  plt.legend()\n",
        "  plt.title(title)\n",
        "  fig.show()\n",
        "  plt.show()"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beh5OodzDB06",
        "cellView": "form"
      },
      "source": [
        "#@title batch_gen(df, entities, log_supervision_matches) { form-width: \"10%\" }\n",
        "def batch_gen(df: pd.DataFrame, entities: dict, remove_supervision_links: bool=True, log_supervision_matches: bool=False) -> dict:\n",
        "  graph = data_gen(df, remove_supervision_links=remove_supervision_links, log_supervision_matches=log_supervision_matches)\n",
        "  \n",
        "  home_teams = list()\n",
        "  away_teams = list()\n",
        "\n",
        "  nodes = nodes_gen(df)\n",
        "  \n",
        "  indices = dict()\n",
        "  for hash, index in nodes.items():\n",
        "    if '@' in hash:\n",
        "      player = hash.split('@')[0]\n",
        "      player_id = entities[player]\n",
        "      indices.update({index:player_id})\n",
        "    elif '*' in hash:\n",
        "      team = hash.split('*')[0]\n",
        "      team_id = entities[team]\n",
        "      indices.update({index: team_id})\n",
        "  for index, (h_team, a_team, result, h_lineup, a_lineup) in df.loc[df.index[-1 * graph.y.shape[0]]:, :].iterrows():\n",
        "      home_teams.append(nodes[f'{h_team}*{index}'])\n",
        "      away_teams.append(nodes[f'{a_team}*{index}'])\n",
        "\n",
        "  \n",
        "  features = torch.tensor(\n",
        "      [indices[i.item()] for i in graph.x],\n",
        "      device=DEVICE\n",
        "  )\n",
        "\n",
        "  # features[node_index: entity]\n",
        "  # indices[321]: 12\n",
        "  # indices[0]\n",
        "  # indices[1]\n",
        "  # indices = {node_index: entity_id}\n",
        "  # indices[654]: 12\n",
        "\n",
        "  # ali@15.entity: 12, ali@60.entity: 12\n",
        "  # ali@15.node_index: 321, ali@60.node_index: 654\n",
        "  # ali: 12\n",
        "\n",
        "  graph_data = {\n",
        "      \"x\": features,\n",
        "      \"edge_index\": graph.edge_index,\n",
        "      \"edge_type\": graph.edge_type,\n",
        "      \"home_teams\": home_teams,\n",
        "      \"away_teams\": away_teams,\n",
        "      \"y\": graph.y\n",
        "  }\n",
        "\n",
        "  return graph_data"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lB8wip7OtAJp",
        "cellView": "form"
      },
      "source": [
        "#@title train(model, dataset, optimizer, loss_fn) { form-width: \"15%\" }\n",
        "def train(model: GNN, graph_data: dict, optimizer: torch.optim, loss_fn: torch.nn.modules.loss) -> typing.Tuple[float, int, int]:\n",
        "  batch_loss = 0\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  out = model(\n",
        "      x=graph_data[\"x\"],\n",
        "      edge_index=graph_data[\"edge_index\"],\n",
        "      edge_type=graph_data[\"edge_type\"],\n",
        "      home_list=graph_data[\"home_teams\"],\n",
        "      away_list=graph_data[\"away_teams\"]\n",
        "  )\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  loss = loss_fn(out, graph_data[\"y\"])\n",
        "  batch_loss = loss.item()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  prediction = out.argmax(dim=-1)\n",
        "  correct = torch.tensor(\n",
        "      (prediction == graph_data[\"y\"]),\n",
        "      dtype=torch.int, device=DEVICE).sum().item()\n",
        "  all = graph_data[\"y\"].shape[0]\n",
        "\n",
        "  return batch_loss, correct, all"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yVJnE1o1V8a",
        "cellView": "form"
      },
      "source": [
        "#@title evaluate(model, dataset) { form-width: \"25px\" }\n",
        "@torch.no_grad()\n",
        "def evaluate(model: GNN, graph_data: dict) -> typing.Tuple[int, int]:\n",
        "  all = 0\n",
        "  correct = 0\n",
        "\n",
        "  model.eval()\n",
        "  out = model(\n",
        "      x=graph_data[\"x\"],\n",
        "      edge_index=graph_data[\"edge_index\"],\n",
        "      edge_type=graph_data[\"edge_type\"],\n",
        "      home_list=graph_data[\"home_teams\"],\n",
        "      away_list=graph_data[\"away_teams\"]\n",
        "  )\n",
        "\n",
        "  prediction = out.argmax(dim=-1)\n",
        "  correct = torch.tensor(\n",
        "      (prediction == graph_data[\"y\"]),\n",
        "      dtype=torch.int, device=DEVICE).sum().item()\n",
        "  all = graph_data[\"y\"].shape[0]\n",
        "  model.train()\n",
        "\n",
        "  return correct, all"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Cuee66-M_HL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "f7023b51-5d61-4fb5-9a2c-be1334b0fa35"
      },
      "source": [
        "#@title Dataset Download { form-width: \"15%\" }\n",
        "import requests\n",
        "from os import getcwd\n",
        "\n",
        "url_epl = \"https://raw.githubusercontent.com/jokecamp/FootballData/master/EPL%202011-2019/PL_scraped_ord.csv\"\n",
        "url_fk = \"https://raw.githubusercontent.com/masoudmousavi/Sports-Analysis-with-GNNs/main/FakeData_EPL.csv?token=ARGPVT5GGWQ4RGABHAF2TE3BKNB54\"\n",
        "# current_directory = getcwd()\n",
        "filename_rl = 'dataset.csv'\n",
        "filename_fk = 'fake.csv'\n",
        "req_rl = requests.get(url_rl)\n",
        "req_fk = requests.get(url_fk)\n",
        "\n",
        "if req_rl.status_code == 200:\n",
        "  with open(filename_rl, 'wb') as fp:\n",
        "    fp.write(req_rl.content)\n",
        "else:\n",
        "  print(f'Error downloading file at {url_rl}')\n",
        "if req_fk.status_code == 200:\n",
        "  with open(filename_fk, 'wb') as fp:\n",
        "    fp.write(req_fk.content)\n",
        "else:\n",
        "  print(f'Error downloading file at {url_fk}')"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error downloading file at https://raw.githubusercontent.com/masoudmousavi/Sports-Analysis-with-GNNs/main/FakeData_EPL.csv?token=ARGPVT5GGWQ4RGABHAF2TE3BKNB54\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PcBerm8OOKR",
        "cellView": "form"
      },
      "source": [
        "#@title Dataset Loading and Cleaning { form-width: \"15px\" }\n",
        "dataset = pd.read_csv(\n",
        "    filename_rl,\n",
        "    encoding='latin-1',\n",
        "    usecols=['home_team', 'away_team', 'result', 'home_lineup', 'away_lineup']\n",
        ")\n",
        "corrupted = dataset.loc[pd.isna(dataset['away_lineup']) | pd.isna(dataset['home_lineup'])]\n",
        "dataset = dataset.drop(corrupted.index, axis=0)\n",
        "dataset = dataset.reset_index(drop=True)\n"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2iqtsxu3A8k",
        "cellView": "form"
      },
      "source": [
        "#@title Log { form-width: \"15%\" }\n",
        "logging.basicConfig(\n",
        "    filename='model-logs.log',\n",
        "    filemode='w',\n",
        "    level=logging.INFO\n",
        ")\n"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3nK5OCX4nIw",
        "cellView": "form"
      },
      "source": [
        "#@title Hyperparameters File\n",
        "hp_file = open('hyperparameters.json', 'w')\n",
        "hyperparameters = {\n",
        "    \"learning_rate\": 1e-3,\n",
        "    \"num_epochs\": 200,\n",
        "    \"fc_dropout\":0.01,\n",
        "    \"conv_dropout\": 0.01,\n",
        "    \"emb_dropout\": 0.01,\n",
        "    \"train_messaging_graph_size\": 440,\n",
        "    \"val_messaging_graph_size\": 440,\n",
        "    \"test_messaging_graph_size\": 440,\n",
        "    \"iter_size\": 10,\n",
        "    \"val_week_denom\": 50,\n",
        "    \"test_week_denom\": 60,\n",
        "    \"embedding_dim\": 32,\n",
        "    \"conv_dims\":[\n",
        "          32,\n",
        "          32, \n",
        "          32,\n",
        "          32\n",
        "    ],\n",
        "    \"fully_connected_dims\":[\n",
        "              32,\n",
        "              32\n",
        "    ]\n",
        "}\n",
        "\n",
        "json.dump(hyperparameters, hp_file)\n",
        "hp_file.close()"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbAnO5WibS9g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da80789b-7308-4d5c-e6b2-3387d6fac217"
      },
      "source": [
        "#@title Model and Model Hyperparameters { form-width: \"15%\" }\n",
        "log_supervision_matches = True\n",
        "with open('hyperparameters.json', 'r') as hp_file:\n",
        "  hyperparameters = json.load(hp_file)\n",
        "learning_rate = hyperparameters[\"learning_rate\"]\n",
        "num_epochs = hyperparameters[\"num_epochs\"]\n",
        "fc_dropout = hyperparameters[\"fc_dropout\"]\n",
        "conv_dropout = hyperparameters[\"conv_dropout\"]\n",
        "emb_dropout = hyperparameters[\"emb_dropout\"]\n",
        "\n",
        "remove_supervision_links = False\n",
        "\n",
        "entities = gen_entities(dataset)\n",
        "\n",
        "######################################## Scheme 4\n",
        "train_messaging_graph_size = hyperparameters[\"train_messaging_graph_size\"]\n",
        "val_messaging_graph_size = hyperparameters[\"val_messaging_graph_size\"]\n",
        "test_messaging_graph_size = hyperparameters[\"test_messaging_graph_size\"]\n",
        "iter_size = hyperparameters[\"iter_size\"]\n",
        "val_week_denom = hyperparameters[\"val_week_denom\"]\n",
        "test_week_denom = hyperparameters[\"test_week_denom\"]\n",
        "######################################## Parameters\n",
        "\n",
        "model = GNN(\n",
        "    embedding_dims=(\n",
        "        max(entities.values()) + 1,\n",
        "        hyperparameters[\"embedding_dim\"]\n",
        "    ),\n",
        "    conv_dims=hyperparameters[\"conv_dims\"],\n",
        "    fully_connected_dims=hyperparameters[\"fully_connected_dims\"],\n",
        "    dropout={\n",
        "        \"emb\": emb_dropout,\n",
        "        \"conv\": conv_dropout,\n",
        "        \"fc\": fc_dropout\n",
        "    }\n",
        ").to(DEVICE)\n",
        "\n",
        "model.reset_parameters()\n",
        "\n",
        "print(model)\n",
        "\n",
        "optimizer = Adam(\n",
        "    model.parameters(),\n",
        "    lr=learning_rate\n",
        ")\n",
        "criterion = NLLLoss()"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GNN(\n",
            "  (embed): Embedding(1565, 32)\n",
            "  (conv_layers): ModuleList(\n",
            "    (0): RGCNConv(32, 32, num_relations=7)\n",
            "    (1): RGCNConv(32, 32, num_relations=7)\n",
            "    (2): RGCNConv(32, 32, num_relations=7)\n",
            "    (3): RGCNConv(32, 32, num_relations=7)\n",
            "  )\n",
            "  (batch_norm_layers): ModuleList(\n",
            "    (0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (1): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (fully_connected_layers): ModuleList(\n",
            "    (0): Linear(in_features=64, out_features=32, bias=True)\n",
            "    (1): Linear(in_features=32, out_features=32, bias=True)\n",
            "    (2): Linear(in_features=32, out_features=3, bias=True)\n",
            "  )\n",
            "  (classifier): LogSoftmax(dim=None)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mb39S2BEh2a"
      },
      "source": [
        "#@title Data Batch Maker { form-width: \"15%\" }\n",
        "train_batches = list()\n",
        "val_batches = list()\n",
        "test_batches = list()\n",
        "\n",
        "for i in range(train_messaging_graph_size, dataset.shape[0], iter_size):\n",
        "      if i % val_week_denom == 0:\n",
        "        ######################## Validation ########################\n",
        "        from_match = i - val_messaging_graph_size\n",
        "        to_match = i - 1\n",
        "        model.mode = 'dev'\n",
        "\n",
        "        validation_df = dataset.loc[from_match: to_match, :]\n",
        "        val_graph_data = batch_gen(\n",
        "              validation_df,\n",
        "              entities=entities,\n",
        "              remove_supervision_links=remove_supervision_links,\n",
        "              log_supervision_matches=log_supervision_matches\n",
        "          )\n",
        "        val_batches.append(val_graph_data)\n",
        "\n",
        "      elif i % test_week_denom == 0:\n",
        "        ######################## Test ########################\n",
        "        model.eval()\n",
        "        model.mode = 'test'\n",
        "        \n",
        "        from_match = i - test_messaging_graph_size\n",
        "        to_match = i - 1\n",
        "\n",
        "        test_df = dataset.loc[from_match: to_match, :]\n",
        "        test_graph_data = batch_gen(\n",
        "            test_df,\n",
        "            entities=entities,\n",
        "            remove_supervision_links=remove_supervision_links,\n",
        "            log_supervision_matches=log_supervision_matches\n",
        "        )\n",
        "        \n",
        "        test_batches.append(test_graph_data)\n",
        "\n",
        "      else:\n",
        "        ######################## Train ########################\n",
        "\n",
        "        from_match = i - train_messaging_graph_size\n",
        "        to_match = i - 1\n",
        "        model.mode = 'train'\n",
        "\n",
        "        train_df = dataset.loc[from_match: to_match, :]\n",
        "        train_graph_data = batch_gen(\n",
        "            train_df,\n",
        "            entities=entities,\n",
        "            remove_supervision_links=remove_supervision_links,\n",
        "            log_supervision_matches=log_supervision_matches\n",
        "        )\n",
        "\n",
        "        train_batches.append(train_graph_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cRCBDz5FJVj"
      },
      "source": [
        "#@title Model Fitting Scheme 4 { form-width: \"15%\" }\n",
        "try:\n",
        "  train_losses = list()\n",
        "  train_accuracies = list()\n",
        "  val_accuracies = list()\n",
        "  \n",
        "  for epoch in range(num_epochs):\n",
        "    epoch_loss = 0\n",
        "    val_correct = 0\n",
        "    val_all = 0\n",
        "    train_all = 0\n",
        "    train_correct = 0\n",
        "\n",
        "    for index, train_graph_data in enumerate(train_batches):\n",
        "       ######################## Train ########################\n",
        "        model.train()\n",
        "        model.mode = 'train'\n",
        "\n",
        "        train_batch_loss, train_batch_correct, train_batch_all = train(\n",
        "              model=model,\n",
        "              graph_data=train_graph_data,\n",
        "              optimizer=optimizer,\n",
        "              loss_fn=criterion\n",
        "          )\n",
        "\n",
        "        epoch_loss += train_batch_loss\n",
        "        train_correct += train_batch_correct\n",
        "        train_all += train_batch_all\n",
        "\n",
        "        ######################## Validation ########################\n",
        "        model.eval()\n",
        "        model.mode = 'dev'\n",
        "\n",
        "        val_batch_correct, val_batch_all = evaluate(\n",
        "            model=model,\n",
        "            graph_data=val_batches[index%len(val_batches)]\n",
        "        )\n",
        "\n",
        "        val_correct += val_batch_correct\n",
        "        val_all += val_batch_all\n",
        "      \n",
        "    ########## end of epoch ###########\n",
        "    print(f'{\"=\"*32} Epoch {epoch + 1} {\"=\"*32}')\n",
        "    print(f'Train Loss:          {epoch_loss:.4f}')\n",
        "    print(f'Train Cost:          {epoch_loss / train_all:.4f}')\n",
        "    print(f'Train Accuracy:      {train_correct * 100 / train_all:.3f}%')\n",
        "    print(f'Validation Accuracy: {val_correct * 100 / val_all:.3f}%')\n",
        "    logging.info(f'{\"=\"*32} Epoch {epoch + 1} {\"=\"*32}')\n",
        "    logging.info(f'Train Loss:          {epoch_loss:.4f}')\n",
        "    logging.info(f'Train Cost:          {epoch_loss / train_all:.4f}')\n",
        "    logging.info(f'Train Accuracy:      {train_correct * 100 / train_all:.3f}%')\n",
        "    logging.info(f'Validation Accuracy: {val_correct * 100 / val_all:.3f}%')\n",
        "\n",
        "    train_losses.append(epoch_loss)\n",
        "    train_accuracies.append(train_correct * 100 / train_all)\n",
        "    val_accuracies.append(val_correct * 100 / val_all)\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqnGTPwygA5O"
      },
      "source": [
        "#@title Results\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "t = [i for i in list(range(len(train_losses)))]\n",
        "t = np.array(t)\n",
        "y1 = np.array(train_losses)\n",
        "y2 = np.array(train_accuracies)\n",
        "y3 = np.array(val_accuracies)\n",
        "fig = plt.gcf()\n",
        "plt.plot(t, y1)\n",
        "plt.title(\"Train Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "#plt.legend(['Train', 'Validation'])\n",
        "fig.set_size_inches(20, 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnPbCyM_R3mE"
      },
      "source": [
        "#@title Model Test { form-width: \"25%\" }\n",
        "\n",
        "test_correct = 0\n",
        "test_all = 0\n",
        "\n",
        "for test_graph_data in test_batches:\n",
        "  model.eval()\n",
        "  model.mode = 'test'\n",
        "\n",
        "  test_batch_correct, test_batch_all = evaluate(\n",
        "      model=model,\n",
        "      graph_data=test_graph_data\n",
        "  )\n",
        "  test_correct += test_batch_correct\n",
        "  test_all += test_batch_all\n",
        "\n",
        "print(f'Test Accuracy: {test_correct * 100 / test_all:.3f}%')\n",
        "logging.info('=' * 70)\n",
        "logging.info(f'Test Accuracy: {test_correct * 100 / test_all:.3f}%')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CawLz0bIJkCD"
      },
      "source": [
        "# @title Model Save\n",
        "torch.save(model.state_dict(), 'model-2.pth')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}