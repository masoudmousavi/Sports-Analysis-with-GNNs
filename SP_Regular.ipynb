{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZyhQYkmSdwkI",
        "outputId": "1b76295c-9217-4bd2-d4f3-2b1cc7dad0f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 7.9 MB 5.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 16.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 482 kB 4.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 41 kB 425 kB/s \n",
            "\u001b[?25h  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# #@title\n",
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-1.10.0+cu111.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-1.10.0+cu111.html\n",
        "!pip install -q git+https://github.com/rusty1s/pytorch_geometric.git\n",
        "!pip install -q torchinfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q2itbyTzwJkk",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "import torch\n",
        "torch.version.cuda\n",
        "#@title\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')\n",
        "#@title\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "53btBN3VYJqa"
      },
      "outputs": [],
      "source": [
        "#@title PRE-REQ { form-width: \"15%\" }\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.nn import Module,\\\n",
        "                     ModuleList,\\\n",
        "                     Embedding,\\\n",
        "                     BatchNorm1d,\\\n",
        "                     LogSoftmax,\\\n",
        "                     Softmax,\\\n",
        "                     Linear,\\\n",
        "                     NLLLoss,\\\n",
        "                     CrossEntropyLoss\n",
        "from torch.optim import Adam\n",
        "import torch.nn.functional as F\n",
        "import torch_geometric as PyG\n",
        "from torch_geometric.data import Data, HeteroData\n",
        "from torch_geometric.nn.conv import RGCNConv, GINConv, GATConv, HeteroConv, GCNConv\n",
        "from torch_geometric.utils import to_networkx\n",
        "from collections import OrderedDict as od\n",
        "import logging\n",
        "import json\n",
        "from typing import NoReturn\n",
        "import typing\n",
        "import enum\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "from torchinfo import summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "8-5N1m4yYp4l"
      },
      "outputs": [],
      "source": [
        "#@title UTILS { form-width: \"15%\" }\n",
        "class Globals(enum.Enum):\n",
        "    WON = 0\n",
        "    LOST_TO = 1\n",
        "    TIED_WITH = 2\n",
        "    PLAYED_IN = 3\n",
        "    USED = 4\n",
        "    BEFORE = 5\n",
        "    AFTER = 6\n",
        "    DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "\n",
        "\n",
        "def stats(df: pd.DataFrame, show_players: bool=False, show_teams: bool=False, show_results: bool=False) -> NoReturn:\n",
        "  players_set = set()\n",
        "  players_list = list()\n",
        "  teams_set = set()\n",
        "\n",
        "  teams_list = list()\n",
        "  results = dict()\n",
        "  # index, (league, season, week, h_team, a_team, result, h_lineup, a_lineup)\n",
        "  for index, (league, season, week, h_team, a_team, result, h_lineup, a_lineup) in df.iterrows():\n",
        "    home_players, away_players = extract_players(h_lineup, a_lineup)\n",
        "    players_set.update(home_players + away_players)\n",
        "    players_list.extend(home_players + away_players)\n",
        "    if result == 'home':\n",
        "      results.update({f'{h_team} #Wins': results.get(f'{h_team} #Wins', 0)+1})\n",
        "      results.update({f'{a_team} #Losses': results.get(f'{a_team} #Losses', 0)+1})\n",
        "    elif result == 'tie':\n",
        "      results.update({f'{h_team} #Ties': results.get(f'{h_team} #Ties', 0)+1})\n",
        "      results.update({f'{a_team} #Ties': results.get(f'{a_team} #Ties', 0)+1})\n",
        "    else:\n",
        "      results.update({f'{a_team} #Wins': results.get(f'{a_team} #Wins', 0)+1})\n",
        "      results.update({f'{h_team} #Losses': results.get(f'{h_team} #Losses', 0)+1})\n",
        "\n",
        "    teams_list.extend([h_team, a_team])\n",
        "    teams_set.update([h_team, a_team])\n",
        "    \n",
        "  if show_players:\n",
        "    for player in players_set:\n",
        "      print(f'{player} played in {players_list.count(player)} matches.')\n",
        "  if show_teams:\n",
        "    for team in teams_set:\n",
        "      print(f'{team} played {teams_list.count(team)} matches.')\n",
        "  if show_results:\n",
        "    results = od(sorted(results.items()))\n",
        "    for key, val in results.items():\n",
        "      print(f'{key}: {val}')\n",
        "\n",
        "\n",
        "def home_result(result: str) -> int:\n",
        "  if result == 'win':\n",
        "    return Globals.WON.value\n",
        "  elif result == 'tie':\n",
        "    return Globals.TIED_WITH.value\n",
        "  elif result == 'loss':\n",
        "    return Globals.LOST_TO.value\n",
        "\n",
        "\n",
        "def remove_redundancy(players: list) -> list:\n",
        "  new_players = list()\n",
        "\n",
        "  for player in players:\n",
        "    if 'Own' in player:\n",
        "      player = player.replace('Own', '')\n",
        "    if 'Pen. Scored' in player:\n",
        "      player = player.replace('Pen. Scored', '')\n",
        "    if 'Pen. Score' in player:\n",
        "      player = player.replace('Pen. Score', '')\n",
        "    if 'Own' in player or 'Scored' in player or 'Score' in player:\n",
        "      print(player)\n",
        "      #SHOULD NOT PRINT IF CODE IS CORRECT\n",
        "    else:\n",
        "      new_players.append(player.strip())\n",
        "  return new_players\n",
        "\n",
        "\n",
        "def extract_players(home_lineup: str, away_lineup: str, seperator: str=' - ') -> list:\n",
        "  home_players = home_lineup[:].split(seperator)\n",
        "  away_players = away_lineup[:].split(seperator)\n",
        "  \n",
        "  return remove_redundancy(home_players), remove_redundancy(away_players)\n",
        "\n",
        "\n",
        "def extract_entities(df: pd.DataFrame) -> typing.Tuple[set, set]:\n",
        "  players_set = set()\n",
        "  players_list = list()\n",
        "  teams_set = set()\n",
        "\n",
        "  teams_list = list()\n",
        "  # results = dict()\n",
        "  for index, (league, season, week, h_team, a_team, result, h_lineup, a_lineup) in df.iterrows():\n",
        "    home_players, away_players = extract_players(h_lineup, a_lineup)\n",
        "\n",
        "    players_set.update(home_players + away_players)\n",
        "    teams_set.update([h_team, a_team])\n",
        "    \n",
        "  return teams_set, players_set\n",
        "\n",
        "\n",
        "def gen_entities(df: pd.DataFrame) -> dict:\n",
        "  teams, players = extract_entities(df)\n",
        "  entities = {entity: index for index, entity in enumerate(list(players) + list(teams))}\n",
        "  return entities\n",
        "\n",
        "\n",
        "def nodes_gen(df: pd.DataFrame) -> typing.Tuple[dict, dict]:\n",
        "  player_nodes = dict()\n",
        "  team_nodes = dict()\n",
        "  player_node_counter = 0\n",
        "  team_node_counter = 0\n",
        "\n",
        "  for index, (league, season, week, h_team, a_team, result, h_lineup, a_lineup) in df.iterrows():\n",
        "      home_players, away_players = extract_players(h_lineup, a_lineup)\n",
        "\n",
        "      for player_index, player in enumerate(home_players):\n",
        "        player_nodes[f'{player}@{index}'] = player_node_counter\n",
        "        player_node_counter += 1\n",
        "      for player_index, player in enumerate(away_players):\n",
        "        player_nodes[f'{player}@{index}'] = player_node_counter\n",
        "        player_node_counter += 1\n",
        "\n",
        "      team_nodes[f'{h_team}*{index}'] = team_node_counter\n",
        "      team_node_counter += 1\n",
        "\n",
        "      team_nodes[f'{a_team}*{index}'] = team_node_counter\n",
        "      team_node_counter += 1\n",
        "\n",
        "  return player_nodes, team_nodes\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rmQxMLzZZDa0",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title GNN { form-width: \"15%\" }\n",
        "#@title\n",
        "class HeteroGNN(Module):\n",
        "  def __init__(self, embedding_dims: tuple, conv_dims: list, fully_connected_dims: list, dropout: dict)-> NoReturn:\n",
        "    super(HeteroGNN, self).__init__()\n",
        "\n",
        "    self.mode = None # 'train' or 'test' or 'dev' later \n",
        "    self.output_dim = 3 #home_result: win, lose, tie\n",
        "    self.num_relations = 7 #win/lose/tie/play/use/after/before\n",
        "    self.dropout = dropout\n",
        "\n",
        "    #one-hot to latent\n",
        "    self.embed = Embedding(embedding_dims[0], embedding_dims[1])\n",
        "    self.entity_bn = BatchNorm1d(embedding_dims[-1])\n",
        "    \n",
        "    conv_list = [\n",
        "                  HeteroConv(\n",
        "                      {\n",
        "                          ('team', 'won', 'team'): GCNConv(embedding_dims[-1], conv_dims[0]),\n",
        "                          ('team', 'lost_to', 'team'): GCNConv(embedding_dims[-1], conv_dims[0]),\n",
        "                          ('team', 'tied_with', 'team'): GCNConv(embedding_dims[-1], conv_dims[0]),\n",
        "                          ('player', 'played_for', 'team'): GATConv(embedding_dims[-1], conv_dims[0], heads=1),\n",
        "                          ('team', 'used', 'player'): GATConv(embedding_dims[-1], conv_dims[0], heads=1),\n",
        "                          ('player', 'is_before', 'player'): GCNConv(embedding_dims[-1], conv_dims[0]),\n",
        "                          ('player', 'is_after', 'player'): GCNConv(embedding_dims[-1], conv_dims[0]),\n",
        "                          ('team', 'is_before', 'team'): GCNConv(embedding_dims[-1], conv_dims[0]),\n",
        "                          ('team', 'is_after', 'team'): GCNConv(embedding_dims[-1], conv_dims[0])\n",
        "                      }, aggr='sum'\n",
        "                  )\n",
        "                ] + \\\n",
        "                [\n",
        "                  HeteroConv(\n",
        "                      {\n",
        "                          ('team', 'won', 'team'): GCNConv(conv_dims[i], conv_dims[i+1]),\n",
        "                          ('team', 'lost_to', 'team'): GCNConv(conv_dims[i], conv_dims[i+1]),\n",
        "                          ('team', 'tied_with', 'team'): GCNConv(conv_dims[i], conv_dims[i+1]),\n",
        "                          ('player', 'played_for', 'team'): GATConv(conv_dims[i], conv_dims[i+1], heads=1),\n",
        "                          ('team', 'used', 'player'): GATConv(conv_dims[i], conv_dims[i+1], heads=1),\n",
        "                          ('player', 'is_before', 'player'): GCNConv(conv_dims[i], conv_dims[i+1]),\n",
        "                          ('player', 'is_after', 'player'): GCNConv(conv_dims[i], conv_dims[i+1]),\n",
        "                          ('team', 'is_before', 'team'): GCNConv(conv_dims[i], conv_dims[i+1]),\n",
        "                          ('team', 'is_after', 'team'): GCNConv(conv_dims[i], conv_dims[i+1])\n",
        "                      }, aggr='sum'\n",
        "                  )\n",
        "                  for i in range(len(conv_dims[:-1]))\n",
        "                ]\n",
        "\n",
        "\n",
        "              \n",
        "    self.conv_bn = ModuleList(\n",
        "        [BatchNorm1d(i) for i in conv_dims]\n",
        "    )\n",
        "  \n",
        "    # batch_norm_list = [\n",
        "    #                      BatchNorm1d(conv_dims[i])\n",
        "    #                      for i in range(len(conv_dims[:-1]))\n",
        "    #                   ]\n",
        "\n",
        "    if len(fully_connected_dims) !=0:\n",
        "      fully_connected_list =   [\n",
        "                                  Linear(2*conv_dims[-1], fully_connected_dims[0])\n",
        "                              ] + \\\n",
        "                              [\n",
        "                                  Linear(fully_connected_dims[i], fully_connected_dims[i+1])\n",
        "                                  for i in range(len(fully_connected_dims[:-1]))\n",
        "                              ] + \\\n",
        "                              [\n",
        "                                  Linear(fully_connected_dims[-1], self.output_dim)\n",
        "                              ]\n",
        "    else:\n",
        "      fully_connected_list = [\n",
        "                              Linear(2*conv_dims[-1], self.output_dim)\n",
        "                            ]\n",
        "    self.fc_bn = ModuleList(\n",
        "        [ BatchNorm1d(i) for i in fully_connected_dims ]\n",
        "    )\n",
        "    #graph conv layers\n",
        "    self.conv_layers = ModuleList(conv_list)\n",
        "    #batch normalization layers\n",
        "\n",
        "    # self.batch_norm_layers = ModuleList(batch_norm_list)\n",
        "\n",
        "    #fully connected dense layers\n",
        "    self.fully_connected_layers = ModuleList(fully_connected_list)\n",
        "\n",
        "    self.classifier = LogSoftmax(dim=1)\n",
        "      \n",
        "\n",
        "  def reset_parameters(self):\n",
        "      self.embed.reset_parameters()\n",
        "      for conv in self.conv_layers:\n",
        "          # for layer in conv:\n",
        "          #   layer.reset_parameters()\n",
        "          conv.reset_parameters()\n",
        "      # for bn in self.batch_norm_layers:\n",
        "      #     bn.reset_parameters()\n",
        "      for fc in self.fully_connected_layers:\n",
        "          fc.reset_parameters()\n",
        "\n",
        "\n",
        "  def forward(self, data: HeteroData) -> torch.Tensor:\n",
        "    x_dict = data.x_dict\n",
        "    home_list = data.home_list\n",
        "    away_list = data.away_list\n",
        "\n",
        "    #print('1111', x_dict['player'][70180])\n",
        "\n",
        "    edge_index_dict = data.edge_index_dict\n",
        "    x_dict = {key: self.embed(x) for key, x in x_dict.items()}\n",
        "    x_dict = {key: self.entity_bn(x) for key, x in x_dict.items()}\n",
        "    \n",
        "    if self.training:\n",
        "      x_dict = {key: F.dropout(x, p=self.dropout[\"emb\"]) for key, x in x_dict.items()}\n",
        "\n",
        "    # for conv, bn in zip(self.conv_layers[:-1], self.batch_norm_layers):\n",
        "    for (conv, bn) in zip(self.conv_layers, self.conv_bn):\n",
        "      x_dict = conv(x_dict, edge_index_dict=edge_index_dict)\n",
        "      x_dict = {key: bn(x) for key, x in x_dict.items()}\n",
        "      x_dict = {key: F.relu(x) for key, x in x_dict.items()}\n",
        "      if self.training:\n",
        "        x_dict = {key: F.dropout(x, p=self.dropout[\"conv\"]) for key, x in x_dict.items()}\n",
        "\n",
        "    #XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXxx\n",
        "\n",
        "    # print(x_dict['player'][data.home_p_list].shape)\n",
        "    self.h_p_dict = data.home_p_dict\n",
        "    self.h_p_strength = x_dict['player'][list(data.home_p_dict.values())]\n",
        "\n",
        "    #YYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYYy\n",
        "\n",
        "\n",
        "    ##################################### End of Encoder \n",
        "    h = torch.cat(\n",
        "        (x_dict['team'][home_list], x_dict['team'][away_list]),\n",
        "        dim=1\n",
        "    )\n",
        "\n",
        "    for (fc, bn) in zip(self.fully_connected_layers[:-1], self.fc_bn):\n",
        "      h = fc(h)\n",
        "      h = bn(h)\n",
        "      h = F.relu(h)\n",
        "      if self.training:\n",
        "        h = F.dropout(h, p=self.dropout[\"fc\"])\n",
        "\n",
        "    h = self.fully_connected_layers[-1](h)\n",
        "    # if self.training:\n",
        "    #   h = F.dropout(h, p=self.dropout[\"fc\"])\n",
        "\n",
        "    return self.classifier(h)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "IVH9MBoUZM9b"
      },
      "outputs": [],
      "source": [
        "#@title Graph { form-width: \"15%\" }\n",
        "#@title\n",
        "def home_won_gen(df: pd.DataFrame, full_data_frame=None) -> typing.Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
        "\n",
        "  home_winning_matches = df.loc[df['result'] == 'win']\n",
        "  home_winners = home_winning_matches['home_team']\n",
        "  away_losers = home_winning_matches['away_team']\n",
        "\n",
        "  winning_hashes = list()\n",
        "  losing_hashes = list()\n",
        "\n",
        "  for home, away, match in zip(home_winners, away_losers, home_winners.index):\n",
        "    winning_hashes.append(f'{home}*{match}')\n",
        "    losing_hashes.append(f'{away}*{match}')\n",
        "\n",
        "  winning_nodes = list()\n",
        "  losing_nodes = list()\n",
        "\n",
        "  if full_data_frame is None:\n",
        "    full_data_frame = df\n",
        "  _, team_nodes = nodes_gen(full_data_frame)\n",
        "\n",
        "  for winner, loser in zip(winning_hashes, losing_hashes):\n",
        "    winning_nodes.append(team_nodes[winner]) \n",
        "    losing_nodes.append(team_nodes[loser])\n",
        "\n",
        "  won_edges = torch.tensor(\n",
        "      [\n",
        "      winning_nodes,\n",
        "      losing_nodes\n",
        "      ], \n",
        "      dtype=torch.long,\n",
        "      device=Globals.DEVICE.value\n",
        "  )\n",
        "\n",
        "  lost_edges = torch.tensor(\n",
        "      [\n",
        "      losing_nodes,\n",
        "      winning_nodes\n",
        "      ],\n",
        "      dtype=torch.long,\n",
        "      device=Globals.DEVICE.value\n",
        "  )\n",
        "\n",
        "  return won_edges, lost_edges\n",
        "\n",
        "\n",
        "def away_won_gen(df: pd.DataFrame, full_data_frame=None) -> typing.Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
        "  away_winning_matches = df.loc[df['result'] == 'loss']\n",
        "  away_winners = away_winning_matches['away_team']\n",
        "  home_losers = away_winning_matches['home_team']\n",
        "\n",
        "  winning_hashes = list()\n",
        "  losing_hashes = list()\n",
        "\n",
        "  for home, away, match in zip(home_losers, away_winners, away_winners.index):\n",
        "    winning_hashes.append(f'{away}*{match}')\n",
        "    losing_hashes.append(f'{home}*{match}')\n",
        "\n",
        "  winning_nodes = list()\n",
        "  losing_nodes = list()\n",
        "\n",
        "  if full_data_frame is None:\n",
        "    full_data_frame = df\n",
        "  _, team_nodes = nodes_gen(full_data_frame)\n",
        "\n",
        "  for winner, loser in zip(winning_hashes, losing_hashes):\n",
        "    winning_nodes.append(team_nodes[winner]) \n",
        "    losing_nodes.append(team_nodes[loser])\n",
        "\n",
        "  won_edges = torch.tensor(\n",
        "      [\n",
        "      winning_nodes,\n",
        "      losing_nodes\n",
        "      ],\n",
        "      dtype=torch.long,\n",
        "      device=Globals.DEVICE.value\n",
        "  )\n",
        "\n",
        "  lost_edges = torch.tensor(\n",
        "      [\n",
        "      losing_nodes,\n",
        "      winning_nodes\n",
        "      ],\n",
        "      dtype=torch.long,\n",
        "      device=Globals.DEVICE.value\n",
        "  )\n",
        "  \n",
        "  return won_edges, lost_edges\n",
        "\n",
        "\n",
        "def tied_gen(df: pd.DataFrame, full_data_frame=None) -> typing.Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
        "  tied_matches = df.loc[df['result'] == 'tie']\n",
        "  home_teams = tied_matches['home_team']\n",
        "  away_teams = tied_matches['away_team']\n",
        "\n",
        "  home_hashes = list()\n",
        "  away_hashes = list()\n",
        "\n",
        "  for home, away, match in zip(home_teams, away_teams, away_teams.index):\n",
        "    away_hashes.append(f'{away}*{match}')\n",
        "    home_hashes.append(f'{home}*{match}')\n",
        "\n",
        "  home_nodes = list()\n",
        "  away_nodes = list()\n",
        "\n",
        "  if full_data_frame is None:\n",
        "    full_data_frame = df\n",
        "  _, team_nodes = nodes_gen(full_data_frame)\n",
        "\n",
        "  for home, away in zip(home_hashes, away_hashes):\n",
        "    home_nodes.append(team_nodes[home]) \n",
        "    away_nodes.append(team_nodes[away])\n",
        "\n",
        "  home_tied_edges = torch.tensor(\n",
        "      [\n",
        "      home_nodes,\n",
        "      away_nodes\n",
        "      ],\n",
        "      dtype=torch.long,\n",
        "      device=Globals.DEVICE.value\n",
        "  )\n",
        "\n",
        "  away_tied_edges = torch.tensor(\n",
        "      [\n",
        "      away_nodes,\n",
        "      home_nodes\n",
        "      ], \n",
        "      dtype=torch.long,\n",
        "      device=Globals.DEVICE.value\n",
        "  )\n",
        "\n",
        "  return home_tied_edges, away_tied_edges\n",
        "\n",
        "\n",
        "def played_used_gen(df: pd.DataFrame) -> typing.Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
        "  team_nodes = list()\n",
        "  player_nodes = list()\n",
        "\n",
        "  p_nodes, t_nodes = nodes_gen(df)\n",
        "\n",
        "  for index, (league, season, week, h_team, a_team, result, h_lineup, a_lineup) in df.iterrows():\n",
        "    home_players, away_players = extract_players(h_lineup, a_lineup)\n",
        "\n",
        "    for home_player, away_player in zip(home_players, away_players):\n",
        "      player_nodes.append(p_nodes[f'{home_player}@{index}'])\n",
        "      team_nodes.append(t_nodes[f'{h_team}*{index}'])\n",
        "      player_nodes.append(p_nodes[f'{away_player}@{index}'])\n",
        "      team_nodes.append(t_nodes[f'{a_team}*{index}'])\n",
        "\n",
        "  played_in_edges = torch.tensor(\n",
        "      [\n",
        "       player_nodes,\n",
        "       team_nodes\n",
        "      ],\n",
        "      dtype=torch.long,\n",
        "      device=Globals.DEVICE.value\n",
        "  )\n",
        "\n",
        "  used_edges = torch.tensor(\n",
        "      [\n",
        "       team_nodes,\n",
        "       player_nodes\n",
        "      ],\n",
        "      dtype=torch.long,\n",
        "      device=Globals.DEVICE.value\n",
        "  ) \n",
        "\n",
        "  return played_in_edges, used_edges\n",
        "\n",
        "\n",
        "def players_before_after_gen(df: pd.DataFrame) -> typing.Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
        "  player_match_hashes = list()\n",
        "\n",
        "  for index, (league, season, week, h_team, a_team, result, h_lineup, a_lineup) in df.iterrows():\n",
        "      home_players, away_players = extract_players(h_lineup, a_lineup)\n",
        "\n",
        "      for player in home_players + away_players:\n",
        "        player_match_hashes.append(f'{player}@{index}')\n",
        "\n",
        "\n",
        "\n",
        "  sorted_hashes = sorted(\n",
        "      player_match_hashes,\n",
        "      key=lambda w: (w.split('@')[0], int(w.split('@')[1]))\n",
        "  )\n",
        "\n",
        "  before_nodes = list()\n",
        "  after_nodes = list()\n",
        "\n",
        "  player_nodes, _ = nodes_gen(df)\n",
        "\n",
        "  for index, hash in enumerate(sorted_hashes):\n",
        "    player, match = hash.split('@')\n",
        "    before_node = player_nodes[hash]\n",
        "    try:\n",
        "      after_node = player_nodes[sorted_hashes[index+1]]\n",
        "      before_name = player_match_hashes[before_node].split('@')[0]\n",
        "      after_name = player_match_hashes[after_node].split('@')[0]\n",
        "      if before_name == after_name:\n",
        "        before_nodes.append(before_node)\n",
        "        after_nodes.append(after_node)\n",
        "    except:\n",
        "      pass\n",
        "  before_edges = torch.tensor(\n",
        "      [\n",
        "      before_nodes,\n",
        "      after_nodes\n",
        "      ], dtype=torch.long,\n",
        "      device=Globals.DEVICE.value\n",
        "  )\n",
        "\n",
        "  after_edges = torch.tensor(\n",
        "      [\n",
        "      after_nodes,\n",
        "      before_nodes\n",
        "      ], dtype=torch.long,\n",
        "      device=Globals.DEVICE.value\n",
        "  )\n",
        "\n",
        "  return before_edges, after_edges\n",
        "\n",
        "\n",
        "def teams_before_after_gen(df: pd.DataFrame) -> typing.Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
        "  team_match_hashes = list()\n",
        "\n",
        "  for index, (league, season, week, h_team, a_team, result, h_lineup, a_lineup) in df.iterrows():\n",
        "      team_match_hashes.append(f'{h_team}*{index}')\n",
        "      team_match_hashes.append(f'{a_team}*{index}')\n",
        "\n",
        "  sorted_hashes = sorted(\n",
        "      team_match_hashes,\n",
        "      key= lambda w: (w.split('*')[0], int(w.split('*')[1]))\n",
        "  )\n",
        "\n",
        "  before_nodes = list()\n",
        "  after_nodes = list()\n",
        "\n",
        "  _, team_nodes = nodes_gen(df)\n",
        "\n",
        "  for index, hash in enumerate(sorted_hashes):\n",
        "    team, match = hash.split('*')\n",
        "    before_node = team_nodes[hash]\n",
        "    try:\n",
        "      after_node = team_nodes[sorted_hashes[index+1]]\n",
        "      before_name = team_match_hashes[before_node].split('*')[0]\n",
        "      after_name = team_match_hashes[after_node].split('*')[0]\n",
        "      if before_name == after_name:\n",
        "        before_nodes.append(before_node)\n",
        "        after_nodes.append(after_node)\n",
        "    except:\n",
        "      pass\n",
        "  before_edges = torch.tensor(\n",
        "      [\n",
        "      before_nodes,\n",
        "      after_nodes\n",
        "      ], dtype=torch.long,\n",
        "      device=Globals.DEVICE.value\n",
        "  )\n",
        "\n",
        "  after_edges = torch.tensor(\n",
        "      [\n",
        "      after_nodes,\n",
        "      before_nodes\n",
        "      ], dtype=torch.long,\n",
        "      device=Globals.DEVICE.value\n",
        "  )\n",
        "\n",
        "  return before_edges, after_edges\n",
        "\n",
        "\n",
        "def complete_graph_gen(df: pd.DataFrame, for_players: bool=True, for_teams: bool=True) -> dict:\n",
        "  home_won, away_lost = home_won_gen(df)\n",
        "  away_won, home_lost = away_won_gen(df)\n",
        "  home_tied, away_tied = tied_gen(df)\n",
        "  player_played, team_used = played_used_gen(df)\n",
        "\n",
        "  if for_players:\n",
        "    player_before, player_after = players_before_after_gen(df)\n",
        "  if for_teams:\n",
        "    team_before, team_after = teams_before_after_gen(df)\n",
        "  won_edge_index = torch.cat(\n",
        "      (home_won, away_won),\n",
        "      dim=1\n",
        "  )\n",
        "  lost_edge_index = torch.cat(\n",
        "      (away_lost, home_lost),\n",
        "      dim=1\n",
        "  )\n",
        "  tied_edge_index = torch.cat(\n",
        "      (home_tied, away_tied),\n",
        "      dim=1\n",
        "  )\n",
        "  edge_index = {\n",
        "      'won': won_edge_index,\n",
        "      'lost': lost_edge_index,\n",
        "      'tied': tied_edge_index,\n",
        "      'played': player_played,\n",
        "      'used': team_used,\n",
        "      'p_after':player_after,\n",
        "      'p_before': player_before,\n",
        "      't_after': team_after,\n",
        "      't_before': team_after\n",
        "  }   \n",
        "  return edge_index\n",
        "\n",
        "\n",
        "def supervision_graph_gen(df : pd.DataFrame, messaging: list, supervision: list, for_players: bool=True, for_teams: bool=True, log_supervision_matches: bool=False) -> typing.Tuple[torch.Tensor, torch.Tensor]:\n",
        "    #   if log_supervision_matches:\n",
        "    #     if model.mode == 'train':\n",
        "    #       mode = 'training'\n",
        "    #     elif model.mode == 'dev':\n",
        "    #       mode = 'validating'\n",
        "    #     elif model.mode == 'test':\n",
        "    #       mode = 'testing'\n",
        "    #     logging.info(\n",
        "    #         f'Messaging on matches ({messaging[0] + 1} -> {messaging[-1] + 1:>5}),\\ Model is {mode} on matches ({last_match+2} -> {last_match + 11})'\n",
        "    #     )\n",
        "  target_for_nodes = df\n",
        "\n",
        "  home_won, away_lost = home_won_gen(df.loc[messaging], full_data_frame=target_for_nodes)\n",
        "  away_won, home_lost = away_won_gen(df.loc[messaging], full_data_frame=target_for_nodes)\n",
        "  home_tied, away_tied = tied_gen(df.loc[messaging], full_data_frame=target_for_nodes)\n",
        "\n",
        "  player_played, team_used = played_used_gen(df)\n",
        "\n",
        "  if for_players:\n",
        "    player_before, player_after = players_before_after_gen(df)\n",
        "  if for_teams:\n",
        "    team_before, team_after = teams_before_after_gen(df)\n",
        "  won_edge_index = torch.cat(\n",
        "      (home_won, away_won),\n",
        "      dim=1\n",
        "  )\n",
        "  lost_edge_index = torch.cat(\n",
        "      (away_lost, home_lost),\n",
        "      dim=1\n",
        "  )\n",
        "  tied_edge_index = torch.cat(\n",
        "      (home_tied, away_tied),\n",
        "      dim=1\n",
        "  )\n",
        "  edge_index = {\n",
        "      'won': won_edge_index,\n",
        "      'lost': lost_edge_index,\n",
        "      'tied': tied_edge_index,\n",
        "      'played': player_played,\n",
        "      'used': team_used,\n",
        "      'p_after':player_after,\n",
        "      'p_before': player_before,\n",
        "      't_after': team_after,\n",
        "      't_before': team_after\n",
        "  }  \n",
        "  return edge_index\n",
        "\n",
        "\n",
        "def data_gen(df: pd.DataFrame, messaging: list, supervision: list=None, remove_supervision_links: bool=True, for_players: bool=True, for_teams: bool=True, print_edges: bool=False, log_supervision_matches: bool=False) -> HeteroData:\n",
        "    #   if print_edges:\n",
        "    #     show_edges(df, edge_index, edge_type)\n",
        "  if remove_supervision_links:\n",
        "    edge_index = supervision_graph_gen(\n",
        "        df,\n",
        "        messaging=messaging,\n",
        "        supervision=supervision,\n",
        "        for_players=for_players,\n",
        "        for_teams=for_teams,\n",
        "        log_supervision_matches=log_supervision_matches\n",
        "    )\n",
        "    y = torch.tensor(\n",
        "        df.loc[supervision]['result'].map(home_result).values,\n",
        "        device=Globals.DEVICE.value\n",
        "    )\n",
        "\n",
        "  else:\n",
        "    if supervision is None:\n",
        "      supervision = df.index\n",
        "    if messaging is None:\n",
        "      messaging = df.index\n",
        "    edge_index = complete_graph_gen(df, for_players, for_teams)\n",
        "    y = torch.tensor(\n",
        "        df.loc[supervision]['result'].map(home_result).values,\n",
        "        device=Globals.DEVICE.value\n",
        "    )\n",
        "\n",
        "  data = HeteroData()\n",
        "  data['player'].x = torch.unique(edge_index['played'][0]).to(Globals.DEVICE.value).type(torch.int64)\n",
        "  data['team'].x = torch.unique(edge_index['used'][0]).to(Globals.DEVICE.value).type(torch.int64)\n",
        "  \n",
        "  data['team', 'won', 'team'].edge_index = edge_index['won']\n",
        "  data['team', 'lost_to', 'team'].edge_index = edge_index['lost']\n",
        "  data['team', 'tied_with', 'team'].edge_index = edge_index['tied']\n",
        "  data['player', 'played_for', 'team'].edge_index = edge_index['played']\n",
        "  data['team', 'used', 'player'].edge_index = edge_index['used']\n",
        "  data['player', 'is_before', 'player'].edge_index = edge_index['p_before']\n",
        "  data['player', 'is_after', 'player'].edge_index = edge_index['p_after']\n",
        "  data['team', 'is_before', 'team'].edge_index = edge_index['t_before']\n",
        "  data['team', 'is_after', 'team'].edge_index = edge_index['t_after']\n",
        "  data.y = y\n",
        "\n",
        "  return data\n",
        "\n",
        "\n",
        "def batch_gen(df: pd.DataFrame, entities: dict, messaging: list=None, supervision: list=None, remove_supervision_links: bool=True, log_supervision_matches: bool=False) -> HeteroData:\n",
        "  graph = data_gen(\n",
        "      df,\n",
        "      messaging=messaging,\n",
        "      supervision=supervision, \n",
        "      remove_supervision_links=remove_supervision_links,\n",
        "      log_supervision_matches=log_supervision_matches\n",
        "  )\n",
        "  \n",
        "  home_teams = list()\n",
        "  away_teams = list()\n",
        "\n",
        "  p_nodes, t_nodes = nodes_gen(df)\n",
        "  nodes = {**p_nodes, **t_nodes}\n",
        "  \n",
        "  if supervision is None:\n",
        "    supervision = df.index\n",
        "\n",
        "  indices = dict()\n",
        "  for hash, index in nodes.items():\n",
        "    if '@' in hash:\n",
        "      player = hash.split('@')[0]\n",
        "      player_id = entities[player]\n",
        "      indices.update({index:player_id})\n",
        "    elif '*' in hash:\n",
        "      team = hash.split('*')[0]\n",
        "      team_id = entities[team]\n",
        "      indices.update({index: team_id})\n",
        "  home_players = list()\n",
        "  away_players = list()\n",
        "\n",
        "\n",
        "  graph.home_p_dict = dict()\n",
        "  for index, (league, season, week, h_team, a_team, result, h_lineup, a_lineup) in df.loc[supervision].iterrows():\n",
        "      home_teams.append(nodes[f'{h_team}*{index}'])\n",
        "      away_teams.append(nodes[f'{a_team}*{index}'])\n",
        "      h_players, a_players = extract_players(h_lineup, a_lineup)\n",
        "      h_players = list(map(lambda s: s+f'@{index}', h_players))\n",
        "      a_players = list(map(lambda s: s+f'@{index}', a_players))\n",
        "      home_players.append(list(map(lambda s: nodes[s], h_players)))\n",
        "      away_players.append(list(map(lambda s: nodes[s], a_players)))\n",
        "\n",
        "      graph.home_p_dict.update(dict(zip(h_players, list(map(lambda s: nodes[s], h_players)))))\n",
        "\n",
        "\n",
        "      # print(h_players)\n",
        "      # print('-'*20)\n",
        "      # print(list(map(lambda s: nodes[s], h_players)))\n",
        "      # print('='*60)\n",
        "\n",
        "\n",
        "      \n",
        "  features_player = torch.tensor(\n",
        "      [indices[i.item()] for i in graph['player'].x],\n",
        "      device=Globals.DEVICE.value\n",
        "  )\n",
        "  features_team = torch.tensor(\n",
        "      [indices[i.item()] for i in graph['team'].x],\n",
        "      device=Globals.DEVICE.value\n",
        "  )\n",
        "\n",
        "  graph['player'].x = features_player\n",
        "  graph['team'].x = features_team\n",
        "  graph.home_list = home_teams\n",
        "  graph.away_list = away_teams\n",
        "  graph.home_p_list = torch.tensor(home_players).to(Globals.DEVICE.value)\n",
        "  graph.away_p_list = torch.tensor(away_players).to(Globals.DEVICE.value)\n",
        "  \n",
        "  return graph\n",
        "\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "TVHmd0EWZkqD"
      },
      "outputs": [],
      "source": [
        "#@title Learning { form-width: \"15%\" }\n",
        "#@title\n",
        "def train(model: HeteroGNN, data: HeteroData, optimizer: torch.optim, loss_fn: torch.nn.modules.loss) -> typing.Tuple[float, int, int]:\n",
        "  batch_loss = 0\n",
        "\n",
        "  model.train()\n",
        "  out = model(data)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  loss = loss_fn(out, data.y)\n",
        "  batch_loss = loss.item()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  prediction = out.argmax(dim=-1)\n",
        "  correct = (prediction == data.y).sum().item()\n",
        "  all = data.y.shape[0]\n",
        "\n",
        "  return batch_loss, correct, all\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model: HeteroGNN, data: HeteroData) -> typing.Tuple[int, int]:\n",
        "  model.eval()\n",
        "\n",
        "  # for child in model.children():\n",
        "  #   for ii in range(len(child)):\n",
        "  #       if type(child[ii]) == BatchNorm1d:\n",
        "  #           child[ii].track_running_stats = False\n",
        "\n",
        "  out = model(data)\n",
        "  prediction = out.argmax(dim=-1)\n",
        "  correct = (prediction == data.y).sum().item()\n",
        "  all = data.y.shape[0]\n",
        "  model.train()\n",
        "\n",
        "  return correct, all"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z7vo4ykoZrlS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8a461f3-531b-4de0-b080-a78e1b0586ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HeteroGNN(\n",
            "  (embed): Embedding(300, 2)\n",
            "  (entity_bn): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv_bn): ModuleList(\n",
            "    (0): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (fc_bn): ModuleList(\n",
            "    (0): BatchNorm1d(2, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (conv_layers): ModuleList(\n",
            "    (0): HeteroConv(num_relations=9)\n",
            "  )\n",
            "  (fully_connected_layers): ModuleList(\n",
            "    (0): Linear(in_features=4, out_features=2, bias=True)\n",
            "    (1): Linear(in_features=2, out_features=3, bias=True)\n",
            "  )\n",
            "  (classifier): LogSoftmax(dim=1)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "#@title MAIN { form-width: \"15%\" }\n",
        "#@title\n",
        "dataset_filename = 'FakeData_EPL.csv'\n",
        "# dataset_filename = 'Vec2_14Players/FakeData_EPL.csv'\n",
        "hp_file = open('hyperparameters.json', 'w')\n",
        "hyperparameters = {\n",
        "    \"learning_rate\": 9e-3,\n",
        "    \"num_epochs\": 200,\n",
        "    \"fc_dropout\":0.01,\n",
        "    \"conv_dropout\": 0.01,\n",
        "    \"reg_param\": 1e-7,\n",
        "    \"emb_dropout\": 0.01,\n",
        "    \"embedding_dim\": 2,\n",
        "    \"conv_dims\":[\n",
        "          2\n",
        "    ],\n",
        "    \"fully_connected_dims\":[\n",
        "          2\n",
        "    ]\n",
        "}\n",
        "\n",
        "json.dump(hyperparameters, hp_file, indent= 4)\n",
        "hp_file.close()\n",
        "\n",
        "dataset = pd.read_csv(\n",
        "    dataset_filename,\n",
        "    encoding='latin-1',\n",
        "    usecols=['league', 'season', 'week', 'home_team', 'away_team', 'result', 'home_lineup', 'away_lineup']\n",
        ")\n",
        "corrupted = dataset.loc[pd.isna(dataset['away_lineup']) | pd.isna(dataset['home_lineup'])]\n",
        "dataset = dataset.drop(corrupted.index, axis=0).reset_index(drop=True)\n",
        "# dataset = dataset.loc[dataset['league'] == 'England Premier League'].reset_index(drop=True)\n",
        "\n",
        "with open('hyperparameters.json', 'r') as hp_file:\n",
        "    hyperparameters = json.load(hp_file)\n",
        "\n",
        "learning_rate = hyperparameters[\"learning_rate\"]\n",
        "num_epochs = hyperparameters[\"num_epochs\"]\n",
        "fc_dropout = hyperparameters[\"fc_dropout\"]\n",
        "conv_dropout = hyperparameters[\"conv_dropout\"]\n",
        "emb_dropout = hyperparameters[\"emb_dropout\"]\n",
        "reg_param = hyperparameters[\"reg_param\"]\n",
        "\n",
        "entities = gen_entities(dataset)\n",
        "\n",
        "model = HeteroGNN(\n",
        "    embedding_dims=(\n",
        "        max(entities.values()) + 1,\n",
        "        hyperparameters[\"embedding_dim\"]\n",
        "    ),\n",
        "    conv_dims=hyperparameters[\"conv_dims\"],\n",
        "    fully_connected_dims=hyperparameters[\"fully_connected_dims\"],\n",
        "    dropout={\n",
        "        \"emb\": emb_dropout,\n",
        "        \"conv\": conv_dropout,\n",
        "        \"fc\": fc_dropout\n",
        "    }\n",
        ").to(Globals.DEVICE.value)\n",
        "\n",
        "print(model)\n",
        "\n",
        "optimizer = Adam(\n",
        "    model.parameters(),\n",
        "    lr=learning_rate,\n",
        "    weight_decay=reg_param\n",
        ")\n",
        "criterion = NLLLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rlwyfhEhtGzv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "1a5e42cf33534a46bdc3a3982f2b8bcd",
            "b0febd66318b436997e921de98e3edcd",
            "8d71a47bf3664dd5881bcdc8f6631941",
            "33221a739510430c95f3c85e3512a662",
            "fde66ef1705a454087abe571757a48ce",
            "1f2b0c1d64a349efa485b2e4ad3df112",
            "b34cefe8f61640fbb1da4e7b22589056",
            "b2cbbcfd665242a598f18d2e1ceb40ac",
            "8f162ea179d7460cb04c5fa4ae3cbfe0",
            "5130e0d1ef7f4b19805c2a129b28b85e",
            "12f92a7d5f2b4d7d9b1cd50fa5379a7f"
          ]
        },
        "outputId": "7b0a8061-6f64-4751-84df-be5429296ad8",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1a5e42cf33534a46bdc3a3982f2b8bcd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/320 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#@title DATASET SPLIT 2 { form-width: \"5%\" }\n",
        "validation_indcs = dataset.sample(n=300).index.values.reshape(-1)\n",
        "# validation_indcs = dataset.index[-int(dataset.shape[0]*0.1):].values\n",
        "\n",
        "_dataset = dataset.drop(validation_indcs)\n",
        "\n",
        "test_indcs = _dataset.sample(n=300).index.values\n",
        "# test_indcs = _dataset.index[-int(dataset.shape[0]*0.1):].values\n",
        "_dataset = _dataset.drop(test_indcs)\n",
        "\n",
        "val_graph_indcs = np.concatenate(\n",
        "    (_dataset.index.values, validation_indcs),\n",
        "    axis=0\n",
        ")\n",
        "hd_val = batch_gen(\n",
        "    df=dataset.loc[val_graph_indcs],\n",
        "    entities=entities,\n",
        "    remove_supervision_links=True,\n",
        "    messaging=_dataset.index,\n",
        "    supervision=validation_indcs\n",
        ")\n",
        "test_graph_indcs = np.concatenate(\n",
        "    (_dataset.index.values, validation_indcs, test_indcs),\n",
        "    axis=0\n",
        ")\n",
        "hd_test = batch_gen(\n",
        "    df=dataset.loc[test_graph_indcs],\n",
        "    entities=entities,\n",
        "    remove_supervision_links=True,\n",
        "    messaging=np.concatenate((_dataset.index.values, validation_indcs), axis=0),\n",
        "    supervision=test_indcs\n",
        ")\n",
        "\n",
        "\n",
        "hd_train = list()\n",
        "\n",
        "try:\n",
        "  for i in tqdm(range(0, _dataset.shape[0], 10)):\n",
        "    train_supervision_indcs = _dataset.loc[_dataset.index[i]: _dataset.index[i + 9], :].index\n",
        "    train_messaging_indcs = _dataset.drop(train_supervision_indcs).index\n",
        "    hd = batch_gen(\n",
        "        df=_dataset,\n",
        "        entities=entities,\n",
        "        remove_supervision_links=True,\n",
        "        messaging=train_messaging_indcs,\n",
        "        supervision=train_supervision_indcs\n",
        "    )\n",
        "    hd_train.append(hd)\n",
        "except KeyboardInterrupt:\n",
        "  pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4iLowqR_e6YB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c1e53ee-0b1a-4817-c4fb-d92e83726058"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================= EPOCH 1 ===================================\n",
            "Loss: 353.0727853178978, Train Acc:  0.367\n",
            "Dev Acc:  0.420\n",
            "======================================= EPOCH 2 ===================================\n",
            "Loss: 340.3767827153206, Train Acc:  0.401\n",
            "Dev Acc:  0.507\n",
            "======================================= EPOCH 3 ===================================\n",
            "Loss: 319.15332770347595, Train Acc:  0.486\n",
            "Dev Acc:  0.483\n",
            "======================================= EPOCH 4 ===================================\n",
            "Loss: 300.87257796525955, Train Acc:  0.548\n",
            "Dev Acc:  0.470\n",
            "======================================= EPOCH 5 ===================================\n",
            "Loss: 294.3703348040581, Train Acc:  0.549\n",
            "Dev Acc:  0.473\n",
            "======================================= EPOCH 6 ===================================\n",
            "Loss: 293.9388901591301, Train Acc:  0.550\n",
            "Dev Acc:  0.460\n",
            "======================================= EPOCH 7 ===================================\n",
            "Loss: 288.23350954055786, Train Acc:  0.565\n",
            "Dev Acc:  0.537\n",
            "======================================= EPOCH 8 ===================================\n",
            "Loss: 280.48498114943504, Train Acc:  0.577\n",
            "Dev Acc:  0.593\n",
            "======================================= EPOCH 9 ===================================\n",
            "Loss: 273.04720824956894, Train Acc:  0.596\n",
            "Dev Acc:  0.587\n",
            "======================================= EPOCH 10 ===================================\n",
            "Loss: 267.7306964099407, Train Acc:  0.605\n",
            "Dev Acc:  0.530\n",
            "======================================= EPOCH 11 ===================================\n",
            "Loss: 260.6169168353081, Train Acc:  0.619\n",
            "Dev Acc:  0.497\n",
            "======================================= EPOCH 12 ===================================\n",
            "Loss: 255.6579369008541, Train Acc:  0.631\n",
            "Dev Acc:  0.603\n",
            "======================================= EPOCH 13 ===================================\n",
            "Loss: 252.68600189685822, Train Acc:  0.633\n",
            "Dev Acc:  0.543\n",
            "======================================= EPOCH 14 ===================================\n",
            "Loss: 248.950966745615, Train Acc:  0.643\n",
            "Dev Acc:  0.577\n",
            "======================================= EPOCH 15 ===================================\n",
            "Loss: 247.53590565919876, Train Acc:  0.647\n",
            "Dev Acc:  0.570\n",
            "======================================= EPOCH 16 ===================================\n",
            "Loss: 245.1151061952114, Train Acc:  0.661\n",
            "Dev Acc:  0.730\n",
            "======================================= EPOCH 17 ===================================\n",
            "Loss: 243.96762311458588, Train Acc:  0.657\n",
            "Dev Acc:  0.727\n",
            "======================================= EPOCH 18 ===================================\n",
            "Loss: 239.93583011627197, Train Acc:  0.660\n",
            "Dev Acc:  0.713\n",
            "======================================= EPOCH 19 ===================================\n",
            "Loss: 239.7337790131569, Train Acc:  0.659\n",
            "Dev Acc:  0.723\n",
            "======================================= EPOCH 20 ===================================\n",
            "Loss: 235.03333646059036, Train Acc:  0.679\n",
            "Dev Acc:  0.750\n",
            "======================================= EPOCH 21 ===================================\n",
            "Loss: 233.9944695532322, Train Acc:  0.680\n",
            "Dev Acc:  0.657\n",
            "======================================= EPOCH 22 ===================================\n",
            "Loss: 232.63035580515862, Train Acc:  0.684\n",
            "Dev Acc:  0.693\n",
            "======================================= EPOCH 23 ===================================\n",
            "Loss: 229.32029870152473, Train Acc:  0.682\n",
            "Dev Acc:  0.740\n",
            "======================================= EPOCH 24 ===================================\n",
            "Loss: 222.5480633676052, Train Acc:  0.693\n",
            "Dev Acc:  0.693\n",
            "======================================= EPOCH 25 ===================================\n",
            "Loss: 222.25922605395317, Train Acc:  0.692\n",
            "Dev Acc:  0.710\n",
            "======================================= EPOCH 26 ===================================\n",
            "Loss: 218.75979286432266, Train Acc:  0.702\n",
            "Dev Acc:  0.680\n",
            "======================================= EPOCH 27 ===================================\n",
            "Loss: 213.94658230245113, Train Acc:  0.706\n",
            "Dev Acc:  0.707\n",
            "======================================= EPOCH 28 ===================================\n",
            "Loss: 212.60805483162403, Train Acc:  0.705\n",
            "Dev Acc:  0.700\n",
            "======================================= EPOCH 29 ===================================\n",
            "Loss: 211.09174898266792, Train Acc:  0.707\n",
            "Dev Acc:  0.710\n",
            "======================================= EPOCH 30 ===================================\n",
            "Loss: 214.40130957961082, Train Acc:  0.692\n",
            "Dev Acc:  0.723\n",
            "======================================= EPOCH 31 ===================================\n",
            "Loss: 210.20068311691284, Train Acc:  0.697\n",
            "Dev Acc:  0.710\n",
            "======================================= EPOCH 32 ===================================\n",
            "Loss: 208.16585910320282, Train Acc:  0.694\n",
            "Dev Acc:  0.743\n",
            "======================================= EPOCH 33 ===================================\n",
            "Loss: 204.4076185822487, Train Acc:  0.714\n",
            "Dev Acc:  0.747\n",
            "======================================= EPOCH 34 ===================================\n",
            "Loss: 202.25803172588348, Train Acc:  0.713\n",
            "Dev Acc:  0.740\n",
            "======================================= EPOCH 35 ===================================\n",
            "Loss: 200.0639897286892, Train Acc:  0.719\n",
            "Dev Acc:  0.740\n",
            "======================================= EPOCH 36 ===================================\n",
            "Loss: 200.513756275177, Train Acc:  0.717\n",
            "Dev Acc:  0.757\n",
            "======================================= EPOCH 37 ===================================\n",
            "Loss: 198.5739690065384, Train Acc:  0.723\n",
            "Dev Acc:  0.737\n",
            "======================================= EPOCH 38 ===================================\n",
            "Loss: 197.0477051138878, Train Acc:  0.722\n",
            "Dev Acc:  0.747\n",
            "======================================= EPOCH 39 ===================================\n",
            "Loss: 196.44469675421715, Train Acc:  0.720\n",
            "Dev Acc:  0.737\n",
            "======================================= EPOCH 40 ===================================\n",
            "Loss: 195.10806503891945, Train Acc:  0.723\n",
            "Dev Acc:  0.713\n",
            "======================================= EPOCH 41 ===================================\n",
            "Loss: 193.29569932818413, Train Acc:  0.727\n",
            "Dev Acc:  0.740\n",
            "======================================= EPOCH 42 ===================================\n",
            "Loss: 193.35252912342548, Train Acc:  0.734\n",
            "Dev Acc:  0.697\n",
            "======================================= EPOCH 43 ===================================\n",
            "Loss: 193.12849247455597, Train Acc:  0.728\n",
            "Dev Acc:  0.780\n",
            "======================================= EPOCH 44 ===================================\n",
            "Loss: 192.36242367327213, Train Acc:  0.726\n",
            "Dev Acc:  0.740\n",
            "======================================= EPOCH 45 ===================================\n",
            "Loss: 194.8821295797825, Train Acc:  0.729\n",
            "Dev Acc:  0.767\n",
            "======================================= EPOCH 46 ===================================\n",
            "Loss: 189.37663358449936, Train Acc:  0.741\n",
            "Dev Acc:  0.803\n",
            "======================================= EPOCH 47 ===================================\n",
            "Loss: 188.63618817925453, Train Acc:  0.731\n",
            "Dev Acc:  0.770\n",
            "======================================= EPOCH 48 ===================================\n",
            "Loss: 188.94876722991467, Train Acc:  0.736\n",
            "Dev Acc:  0.753\n",
            "======================================= EPOCH 49 ===================================\n",
            "Loss: 191.39322543144226, Train Acc:  0.724\n",
            "Dev Acc:  0.747\n",
            "======================================= EPOCH 50 ===================================\n",
            "Loss: 186.24571493268013, Train Acc:  0.746\n",
            "Dev Acc:  0.780\n",
            "======================================= EPOCH 51 ===================================\n",
            "Loss: 186.58227457106113, Train Acc:  0.742\n",
            "Dev Acc:  0.783\n",
            "======================================= EPOCH 52 ===================================\n",
            "Loss: 188.63822907209396, Train Acc:  0.738\n",
            "Dev Acc:  0.730\n",
            "======================================= EPOCH 53 ===================================\n",
            "Loss: 186.1149345189333, Train Acc:  0.733\n",
            "Dev Acc:  0.753\n",
            "======================================= EPOCH 54 ===================================\n",
            "Loss: 185.6798813790083, Train Acc:  0.744\n",
            "Dev Acc:  0.757\n",
            "======================================= EPOCH 55 ===================================\n",
            "Loss: 186.5980513393879, Train Acc:  0.738\n",
            "Dev Acc:  0.757\n",
            "======================================= EPOCH 56 ===================================\n",
            "Loss: 188.24617090821266, Train Acc:  0.745\n",
            "Dev Acc:  0.777\n",
            "======================================= EPOCH 57 ===================================\n",
            "Loss: 184.00655023753643, Train Acc:  0.749\n",
            "Dev Acc:  0.753\n",
            "======================================= EPOCH 58 ===================================\n",
            "Loss: 185.4971426129341, Train Acc:  0.742\n",
            "Dev Acc:  0.763\n",
            "======================================= EPOCH 59 ===================================\n",
            "Loss: 184.81624329090118, Train Acc:  0.746\n",
            "Dev Acc:  0.773\n",
            "======================================= EPOCH 60 ===================================\n",
            "Loss: 180.7772386521101, Train Acc:  0.753\n",
            "Dev Acc:  0.767\n",
            "======================================= EPOCH 61 ===================================\n",
            "Loss: 185.02516549825668, Train Acc:  0.745\n",
            "Dev Acc:  0.743\n",
            "======================================= EPOCH 62 ===================================\n",
            "Loss: 186.01582837104797, Train Acc:  0.751\n",
            "Dev Acc:  0.750\n",
            "======================================= EPOCH 63 ===================================\n",
            "Loss: 184.4255951344967, Train Acc:  0.742\n",
            "Dev Acc:  0.777\n",
            "======================================= EPOCH 64 ===================================\n",
            "Loss: 181.14690633118153, Train Acc:  0.760\n",
            "Dev Acc:  0.703\n",
            "======================================= EPOCH 65 ===================================\n",
            "Loss: 184.17531928420067, Train Acc:  0.748\n",
            "Dev Acc:  0.757\n",
            "======================================= EPOCH 66 ===================================\n",
            "Loss: 182.34527170658112, Train Acc:  0.752\n",
            "Dev Acc:  0.757\n",
            "======================================= EPOCH 67 ===================================\n",
            "Loss: 185.8095007389784, Train Acc:  0.737\n",
            "Dev Acc:  0.770\n",
            "======================================= EPOCH 68 ===================================\n",
            "Loss: 182.2009924352169, Train Acc:  0.748\n",
            "Dev Acc:  0.770\n",
            "======================================= EPOCH 69 ===================================\n",
            "Loss: 182.75055441260338, Train Acc:  0.748\n",
            "Dev Acc:  0.767\n",
            "======================================= EPOCH 70 ===================================\n",
            "Loss: 182.2400225996971, Train Acc:  0.748\n",
            "Dev Acc:  0.783\n",
            "======================================= EPOCH 71 ===================================\n",
            "Loss: 183.02702286839485, Train Acc:  0.752\n",
            "Dev Acc:  0.767\n",
            "======================================= EPOCH 72 ===================================\n",
            "Loss: 186.81993199884892, Train Acc:  0.744\n",
            "Dev Acc:  0.757\n",
            "======================================= EPOCH 73 ===================================\n",
            "Loss: 181.9178228378296, Train Acc:  0.753\n",
            "Dev Acc:  0.737\n",
            "======================================= EPOCH 74 ===================================\n",
            "Loss: 177.8014712780714, Train Acc:  0.763\n",
            "Dev Acc:  0.743\n",
            "======================================= EPOCH 75 ===================================\n",
            "Loss: 178.14975081384182, Train Acc:  0.761\n",
            "Dev Acc:  0.753\n",
            "======================================= EPOCH 76 ===================================\n",
            "Loss: 183.4668992459774, Train Acc:  0.745\n",
            "Dev Acc:  0.750\n",
            "======================================= EPOCH 77 ===================================\n",
            "Loss: 181.6771925985813, Train Acc:  0.755\n",
            "Dev Acc:  0.770\n",
            "======================================= EPOCH 78 ===================================\n",
            "Loss: 183.35697558522224, Train Acc:  0.751\n",
            "Dev Acc:  0.733\n",
            "======================================= EPOCH 79 ===================================\n",
            "Loss: 184.57675197720528, Train Acc:  0.748\n",
            "Dev Acc:  0.780\n",
            "======================================= EPOCH 80 ===================================\n",
            "Loss: 185.05511844158173, Train Acc:  0.757\n",
            "Dev Acc:  0.797\n",
            "======================================= EPOCH 81 ===================================\n",
            "Loss: 181.597805082798, Train Acc:  0.751\n",
            "Dev Acc:  0.767\n",
            "======================================= EPOCH 82 ===================================\n",
            "Loss: 182.60073395073414, Train Acc:  0.755\n",
            "Dev Acc:  0.727\n",
            "======================================= EPOCH 83 ===================================\n",
            "Loss: 180.02486772835255, Train Acc:  0.760\n",
            "Dev Acc:  0.750\n",
            "======================================= EPOCH 84 ===================================\n",
            "Loss: 182.65860641002655, Train Acc:  0.753\n",
            "Dev Acc:  0.737\n",
            "======================================= EPOCH 85 ===================================\n",
            "Loss: 180.07454599440098, Train Acc:  0.753\n",
            "Dev Acc:  0.747\n",
            "======================================= EPOCH 86 ===================================\n",
            "Loss: 178.65185104310513, Train Acc:  0.752\n",
            "Dev Acc:  0.770\n",
            "======================================= EPOCH 87 ===================================\n",
            "Loss: 182.89594189822674, Train Acc:  0.749\n",
            "Dev Acc:  0.780\n",
            "======================================= EPOCH 88 ===================================\n",
            "Loss: 174.95073887705803, Train Acc:  0.761\n",
            "Dev Acc:  0.753\n",
            "======================================= EPOCH 89 ===================================\n",
            "Loss: 180.06300953030586, Train Acc:  0.753\n",
            "Dev Acc:  0.753\n",
            "======================================= EPOCH 90 ===================================\n",
            "Loss: 182.07569298148155, Train Acc:  0.746\n",
            "Dev Acc:  0.733\n",
            "======================================= EPOCH 91 ===================================\n",
            "Loss: 181.43167029321194, Train Acc:  0.756\n",
            "Dev Acc:  0.740\n",
            "======================================= EPOCH 92 ===================================\n",
            "Loss: 177.32598786056042, Train Acc:  0.757\n",
            "Dev Acc:  0.750\n",
            "======================================= EPOCH 93 ===================================\n",
            "Loss: 178.19544750452042, Train Acc:  0.760\n",
            "Dev Acc:  0.740\n",
            "======================================= EPOCH 94 ===================================\n",
            "Loss: 184.4906515777111, Train Acc:  0.748\n",
            "Dev Acc:  0.760\n",
            "======================================= EPOCH 95 ===================================\n",
            "Loss: 175.63467080891132, Train Acc:  0.764\n",
            "Dev Acc:  0.747\n",
            "======================================= EPOCH 96 ===================================\n",
            "Loss: 176.3857950270176, Train Acc:  0.764\n",
            "Dev Acc:  0.770\n",
            "======================================= EPOCH 97 ===================================\n",
            "Loss: 177.43271443247795, Train Acc:  0.755\n",
            "Dev Acc:  0.733\n",
            "======================================= EPOCH 98 ===================================\n",
            "Loss: 178.00477787852287, Train Acc:  0.762\n",
            "Dev Acc:  0.703\n",
            "======================================= EPOCH 99 ===================================\n",
            "Loss: 188.63905745744705, Train Acc:  0.755\n",
            "Dev Acc:  0.740\n",
            "======================================= EPOCH 100 ===================================\n",
            "Loss: 176.4316820204258, Train Acc:  0.764\n",
            "Dev Acc:  0.727\n",
            "======================================= EPOCH 101 ===================================\n",
            "Loss: 181.74893328547478, Train Acc:  0.753\n",
            "Dev Acc:  0.733\n",
            "======================================= EPOCH 102 ===================================\n",
            "Loss: 179.76657231152058, Train Acc:  0.760\n",
            "Dev Acc:  0.747\n",
            "======================================= EPOCH 103 ===================================\n",
            "Loss: 176.449380338192, Train Acc:  0.755\n",
            "Dev Acc:  0.683\n",
            "======================================= EPOCH 104 ===================================\n",
            "Loss: 173.10721132159233, Train Acc:  0.769\n",
            "Dev Acc:  0.737\n",
            "======================================= EPOCH 105 ===================================\n",
            "Loss: 176.01223416626453, Train Acc:  0.765\n",
            "Dev Acc:  0.753\n",
            "======================================= EPOCH 106 ===================================\n",
            "Loss: 179.06692656874657, Train Acc:  0.755\n",
            "Dev Acc:  0.707\n",
            "======================================= EPOCH 107 ===================================\n",
            "Loss: 178.39467819035053, Train Acc:  0.760\n",
            "Dev Acc:  0.720\n",
            "======================================= EPOCH 108 ===================================\n",
            "Loss: 183.89959532022476, Train Acc:  0.743\n",
            "Dev Acc:  0.760\n",
            "======================================= EPOCH 109 ===================================\n",
            "Loss: 175.0383195579052, Train Acc:  0.763\n",
            "Dev Acc:  0.743\n",
            "======================================= EPOCH 110 ===================================\n",
            "Loss: 178.6534190028906, Train Acc:  0.759\n",
            "Dev Acc:  0.767\n",
            "======================================= EPOCH 111 ===================================\n",
            "Loss: 177.93447397649288, Train Acc:  0.758\n",
            "Dev Acc:  0.743\n",
            "======================================= EPOCH 112 ===================================\n",
            "Loss: 172.76066981256008, Train Acc:  0.762\n",
            "Dev Acc:  0.743\n",
            "======================================= EPOCH 113 ===================================\n",
            "Loss: 177.32210496068, Train Acc:  0.765\n",
            "Dev Acc:  0.760\n",
            "======================================= EPOCH 114 ===================================\n",
            "Loss: 177.2054846137762, Train Acc:  0.758\n",
            "Dev Acc:  0.747\n",
            "======================================= EPOCH 115 ===================================\n",
            "Loss: 177.34140586853027, Train Acc:  0.760\n",
            "Dev Acc:  0.757\n",
            "======================================= EPOCH 116 ===================================\n",
            "Loss: 178.36159197986126, Train Acc:  0.758\n",
            "Dev Acc:  0.763\n",
            "======================================= EPOCH 117 ===================================\n",
            "Loss: 178.0577762722969, Train Acc:  0.767\n",
            "Dev Acc:  0.757\n",
            "======================================= EPOCH 118 ===================================\n",
            "Loss: 176.43449588119984, Train Acc:  0.759\n",
            "Dev Acc:  0.760\n",
            "======================================= EPOCH 119 ===================================\n",
            "Loss: 174.08312022686005, Train Acc:  0.767\n",
            "Dev Acc:  0.757\n",
            "======================================= EPOCH 120 ===================================\n",
            "Loss: 180.03733837604523, Train Acc:  0.754\n",
            "Dev Acc:  0.767\n",
            "======================================= EPOCH 121 ===================================\n",
            "Loss: 178.6744523793459, Train Acc:  0.764\n",
            "Dev Acc:  0.737\n",
            "======================================= EPOCH 122 ===================================\n",
            "Loss: 174.77365346252918, Train Acc:  0.769\n",
            "Dev Acc:  0.747\n",
            "======================================= EPOCH 123 ===================================\n",
            "Loss: 176.5208874642849, Train Acc:  0.766\n",
            "Dev Acc:  0.747\n",
            "======================================= EPOCH 124 ===================================\n",
            "Loss: 177.23809529840946, Train Acc:  0.768\n",
            "Dev Acc:  0.760\n",
            "======================================= EPOCH 125 ===================================\n",
            "Loss: 174.93826633691788, Train Acc:  0.769\n",
            "Dev Acc:  0.757\n",
            "======================================= EPOCH 126 ===================================\n",
            "Loss: 175.94362725317478, Train Acc:  0.765\n",
            "Dev Acc:  0.763\n",
            "======================================= EPOCH 127 ===================================\n",
            "Loss: 174.9253397732973, Train Acc:  0.761\n",
            "Dev Acc:  0.757\n",
            "======================================= EPOCH 128 ===================================\n",
            "Loss: 175.77035143971443, Train Acc:  0.763\n",
            "Dev Acc:  0.747\n",
            "======================================= EPOCH 129 ===================================\n",
            "Loss: 176.88489075005054, Train Acc:  0.766\n",
            "Dev Acc:  0.723\n",
            "======================================= EPOCH 130 ===================================\n",
            "Loss: 177.69906915724277, Train Acc:  0.765\n",
            "Dev Acc:  0.733\n",
            "======================================= EPOCH 131 ===================================\n",
            "Loss: 173.53863206505775, Train Acc:  0.766\n",
            "Dev Acc:  0.763\n",
            "======================================= EPOCH 132 ===================================\n",
            "Loss: 177.19165568053722, Train Acc:  0.763\n",
            "Dev Acc:  0.747\n",
            "======================================= EPOCH 133 ===================================\n",
            "Loss: 178.92261070013046, Train Acc:  0.757\n",
            "Dev Acc:  0.740\n",
            "======================================= EPOCH 134 ===================================\n",
            "Loss: 175.0439170897007, Train Acc:  0.764\n",
            "Dev Acc:  0.750\n",
            "======================================= EPOCH 135 ===================================\n",
            "Loss: 177.13199378550053, Train Acc:  0.762\n",
            "Dev Acc:  0.737\n",
            "======================================= EPOCH 136 ===================================\n",
            "Loss: 174.98240730166435, Train Acc:  0.767\n",
            "Dev Acc:  0.773\n",
            "======================================= EPOCH 137 ===================================\n",
            "Loss: 175.19437827169895, Train Acc:  0.768\n",
            "Dev Acc:  0.753\n",
            "======================================= EPOCH 138 ===================================\n",
            "Loss: 177.11601594090462, Train Acc:  0.762\n",
            "Dev Acc:  0.760\n",
            "======================================= EPOCH 139 ===================================\n",
            "Loss: 172.6213765591383, Train Acc:  0.760\n",
            "Dev Acc:  0.723\n",
            "======================================= EPOCH 140 ===================================\n",
            "Loss: 173.59569109976292, Train Acc:  0.766\n",
            "Dev Acc:  0.750\n",
            "======================================= EPOCH 141 ===================================\n",
            "Loss: 176.57000322639942, Train Acc:  0.768\n",
            "Dev Acc:  0.757\n",
            "======================================= EPOCH 142 ===================================\n",
            "Loss: 177.66593992710114, Train Acc:  0.765\n",
            "Dev Acc:  0.760\n",
            "======================================= EPOCH 143 ===================================\n",
            "Loss: 175.55184784531593, Train Acc:  0.765\n",
            "Dev Acc:  0.753\n",
            "======================================= EPOCH 144 ===================================\n",
            "Loss: 176.187140583992, Train Acc:  0.767\n",
            "Dev Acc:  0.760\n",
            "======================================= EPOCH 145 ===================================\n",
            "Loss: 169.49257615208626, Train Acc:  0.772\n",
            "Dev Acc:  0.757\n",
            "======================================= EPOCH 146 ===================================\n",
            "Loss: 174.61267426609993, Train Acc:  0.766\n",
            "Dev Acc:  0.757\n",
            "======================================= EPOCH 147 ===================================\n",
            "Loss: 174.60282149910927, Train Acc:  0.771\n",
            "Dev Acc:  0.760\n",
            "======================================= EPOCH 148 ===================================\n",
            "Loss: 178.4050471931696, Train Acc:  0.763\n",
            "Dev Acc:  0.740\n",
            "======================================= EPOCH 149 ===================================\n",
            "Loss: 173.98738203942776, Train Acc:  0.769\n",
            "Dev Acc:  0.753\n",
            "======================================= EPOCH 150 ===================================\n",
            "Loss: 179.766671448946, Train Acc:  0.755\n",
            "Dev Acc:  0.743\n",
            "======================================= EPOCH 151 ===================================\n",
            "Loss: 172.19612462818623, Train Acc:  0.766\n",
            "Dev Acc:  0.717\n",
            "======================================= EPOCH 152 ===================================\n",
            "Loss: 169.44871959090233, Train Acc:  0.771\n",
            "Dev Acc:  0.760\n",
            "======================================= EPOCH 153 ===================================\n",
            "Loss: 179.9201877862215, Train Acc:  0.756\n",
            "Dev Acc:  0.763\n",
            "======================================= EPOCH 154 ===================================\n",
            "Loss: 174.2875251621008, Train Acc:  0.765\n",
            "Dev Acc:  0.730\n"
          ]
        }
      ],
      "source": [
        "#@title Train/Val/Test { form-width: \"15%\" }\n",
        "try:\n",
        "  for epoch in range(400):\n",
        "    all = 0\n",
        "    correct = 0\n",
        "    loss = 0\n",
        "    for hd in hd_train:\n",
        "      _, __, ___ = train(model, hd, optimizer, criterion)\n",
        "      loss += _\n",
        "      correct += __\n",
        "      all += ___\n",
        "    print(f'======================================= EPOCH {epoch + 1} ===================================')\n",
        "    print(f'Loss: {loss}, Train Acc: {correct / all: .3f}')\n",
        "    # loss_list.append(loss)\n",
        "    # train_acc_list.append(correct / all)\n",
        "    # home_p_dict_list.append(model.h_p_dict)\n",
        "    # home_p_strength_list.append(model.h_p_strength.detach().cpu())\n",
        "    \n",
        "    correct, all = evaluate(model, hd_val)\n",
        "    print(f'Dev Acc: {correct / all: .3f}')\n",
        "    # eval_acc_list.append(correct / all)\n",
        "    # if (epoch+1) % 20 == 0:\n",
        "      # torch.save(model, 'Regular/model.torch')\n",
        "      # with open('Regular/losses_lists.list', 'wb') as p_file:\n",
        "        # pickle.dump((loss_list, train_acc_list, eval_acc_list), p_file)\n",
        "      # print('Model Saved!')\n",
        "except KeyboardInterrupt:\n",
        "  pass\n",
        "correct, all = evaluate(model, hd_test)\n",
        "print(f'Test Acc: {correct / all: .3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-bgwaIJI1zTg",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "# %cd /content/gdrive/MyDrive/Colab Notebooks/Sports-Analysis-with-GNNs.zip (Unzipped Files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "M8_Ru0xwL6Dt"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "summary(model, depth=3)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "# del hd_val.edge_index_dict[]\n",
        "# del hd_val.edge_index_dict['team', 'lost_to', 'team']\n",
        "# hd_val.edge_index_dict[('team', 'used', 'player')].edge_index = torch.empty([])\n",
        "# hd_val.edge_index_dict\n",
        "# hd_train[0].edge_index_dict\n"
      ],
      "metadata": {
        "id": "K_aqd1GDiRto",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "XBJMqsOJL6Du"
      },
      "outputs": [],
      "source": [
        "#@title DATASET SPLIT INCREMENTAL { form-width: \"5%\" }\n",
        "graph_list = []\n",
        "try:\n",
        "    for season, season_df in tqdm(dataset.groupby('season')):\n",
        "        for week, week_df in tqdm(season_df.groupby('week'), leave=False):\n",
        "            g = batch_gen(\n",
        "                df=dataset.loc[:week_df.index[-1], :],\n",
        "                entities=entities,\n",
        "                messaging=dataset.index[:week_df.index[0]],\n",
        "                supervision=week_df.index,\n",
        "                remove_supervision_links=True\n",
        "            )\n",
        "            graph_list.append(g)\n",
        "except KeyboardInterrupt:\n",
        "    pass\n",
        "\n",
        "test_portion = 0.1\n",
        "validation_portion = 0.1\n",
        "test_indcs = np.arange(int((1-test_portion)*len(graph_list)), len(graph_list))\n",
        "eval_indcs = np.arange(int((1-(test_portion+validation_portion))*len(graph_list)), int((1-test_portion)*len(graph_list)))\n",
        "train_indcs = np.arange(0, int((1-(test_portion+validation_portion))*len(graph_list)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "o3vvQLUCL6Du"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "len(graph_list)\n",
        "#@title\n",
        "#Saving Data\n",
        "with open('temp/graphs.data', 'wb') as p_file:\n",
        "    pickle.dump(graph_list, p_file)\n",
        "with open('temp/split_indcs.lists', 'wb') as p_file:\n",
        "    pickle.dump((train_indcs, eval_indcs, test_indcs), p_file)\n",
        "#@title\n",
        "#Loading Data\n",
        "with open('temp/graphs.data', 'rb') as p_file:\n",
        "    graph_list = pickle.load(p_file)\n",
        "with open('temp/split_indcs.lists', 'rb') as p_file:\n",
        "    train_indcs, eval_indcs, test_indcs = pickle.load(p_file)\n",
        "#@title\n",
        "with open('Regular/hd_train.data', 'wb') as p_file:\n",
        "  pickle.dump(hd_train, p_file)\n",
        "with open('Regular/hd_eval.data', 'wb') as p_file:\n",
        "  pickle.dump(hd_val, p_file)\n",
        "with open('Regular/hd_test.data', 'wb') as p_file:\n",
        "  pickle.dump(hd_test, p_file)\n",
        "with open('Regular/hd_train.data', 'rb') as p_file:\n",
        "  hd_train = pickle.load(p_file)\n",
        "with open('Regular/hd_eval.data', 'rb') as p_file:\n",
        "  hd_val = pickle.load(p_file)\n",
        "with open('Regular/hd_test.data', 'rb') as p_file:\n",
        "  hd_train = pickle.load(p_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pE70YIBVChEy",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "HF_hFXiIL6Dw",
        "outputId": "5f05f614-7152-4c36-eed1-e3887e484639"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "103"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#@title\n",
        "entities['Emmanuel Adebayor']\n",
        "dataset.loc[np.logical_or(dataset['home_lineup'].str.contains('Emmanuel Adebayor').to_numpy(), dataset['away_lineup'].str.contains('Emmanuel Adebayor').to_numpy()), :]\n",
        "graph_list[1].edge_index_dict[('player', 'played_for', 'team')].shape\n",
        "model.embed(torch.tensor([entities['Emmanuel Adebayor']], device=Globals.DEVICE.value)).detach().cpu()\n",
        "pre_train = model.embed(torch.tensor([entities['Emmanuel Adebayor']], device=Globals.DEVICE.value)).detach().cpu()\n",
        "train(model, graph_list[1], optimizer, criterion)\n",
        "post_train = model.embed(torch.tensor([entities['Emmanuel Adebayor']], device=Globals.DEVICE.value)).detach().cpu()\n",
        "model.embed(torch.tensor([entities['Emmanuel Adebayor']], device=Globals.DEVICE.value)).detach().cpu()\n",
        "pre_train == post_train\n",
        "correct, all = evaluate(model, graph_list[20])\n",
        "model.embed(torch.tensor([287]).to(Globals.DEVICE.value))\n",
        "type(graph_list[0])\n",
        "np.array(graph_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Nskf9LJqkHb",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "model.reset_parameters()\n",
        "home_p_dict_list = []\n",
        "home_p_strength_list = []\n",
        "loss_list = []\n",
        "train_acc_list = []\n",
        "eval_acc_list = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "9FEkUqOuL6Dz"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "#Phase 1: Training ONLY on train data\n",
        "print(\"################### Phase 1: Training ONLY on train data ###################\")\n",
        "try:\n",
        "    for epoch in range(200):\n",
        "        all = 0\n",
        "        correct = 0\n",
        "        loss = 0\n",
        "        for idx in train_indcs:\n",
        "            graph = graph_list[idx]\n",
        "            _, __, ___ = train(model, graph, optimizer, criterion)\n",
        "            loss += _\n",
        "            correct += __\n",
        "            all += ___\n",
        "        print(f'======================================= EPOCH {epoch + 1} ===================================')\n",
        "        print(f'Loss: {loss}, Train Acc: {correct / all: .3f}')\n",
        "        # loss_list.append(loss)\n",
        "        # train_acc_list.append(correct / all)\n",
        "        # home_p_dict_list.append(model.h_p_dict)\n",
        "        # home_p_strength_list.append(model.h_p_strength.detach().cpu())\n",
        "\n",
        "\n",
        "        correct = 0\n",
        "        all = 0\n",
        "        for idx in eval_indcs:\n",
        "            graph = graph_list[idx]\n",
        "            _, __ = evaluate(model, graph)\n",
        "            correct += _\n",
        "            all += __\n",
        "        print(f'Dev Acc: {correct / all: .3f}')\n",
        "        # eval_acc_list.append(correct / all)\n",
        "        if (epoch+1) % 5 == 0:\n",
        "            # torch.save(model, 'temp/model.torch')\n",
        "            # with open('temp/losses_lists.list', 'wb') as p_file:\n",
        "                # pickle.dump((loss_list, train_acc_list, eval_acc_list), p_file)\n",
        "            print('Model Saved!')\n",
        "except KeyboardInterrupt:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "qpNyyXdUL6Dz"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "correct = 0\n",
        "all = 0\n",
        "for idx in test_indcs:\n",
        "    graph = graph_list[idx]\n",
        "    _, __ = evaluate(model, graph)\n",
        "    correct += _\n",
        "    all += __\n",
        "print(f'Test Acc: {correct / all: .3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "KrUZlW4tL6D0"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "#Phase 2: Training on the train + eval data\n",
        "print(\"################### Phase 2: Training on the train + eval data ###################\")\n",
        "indcs = np.concatenate((train_indcs, eval_indcs))\n",
        "try:\n",
        "    for epoch in range(20):\n",
        "        all = 0\n",
        "        correct = 0\n",
        "        loss = 0\n",
        "        for idx in indcs:\n",
        "            graph = graph_list[idx]\n",
        "            _, __, ___ = train(model, graph, optimizer, criterion)\n",
        "            loss += _\n",
        "            correct += __\n",
        "            all += ___\n",
        "        print(f'======================================= EPOCH {epoch + 1} ===================================')\n",
        "        print(f'Loss: {loss}, Train Acc: {correct / all: .3f}')\n",
        "        loss_list.append(loss)\n",
        "        train_acc_list.append(correct / all)\n",
        "        home_p_dict_list.append(model.h_p_dict)\n",
        "        home_p_strength_list.append(model.h_p_strength.detach().cpu())\n",
        "\n",
        "\n",
        "        correct = 0\n",
        "        all = 0\n",
        "        for idx in test_indcs:\n",
        "            graph = graph_list[idx]\n",
        "            _, __ = evaluate(model, graph)\n",
        "            correct += _\n",
        "            all += __\n",
        "        print(f'Test Acc: {correct / all: .3f}')\n",
        "\n",
        "        if (epoch+1) % 20 == 0:\n",
        "            torch.save(model, 'temp/model.torch')\n",
        "            with open('temp/losses_lists.list', 'wb') as p_file:\n",
        "                pickle.dump((loss_list, train_acc_list, eval_acc_list), p_file)\n",
        "            print('Model Saved!')\n",
        "except KeyboardInterrupt:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "2cawufpcL6D0"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "#Phase 3: Testing and training on the test\n",
        "print(\"################### Phase 3: Testing and training on the test ###################\")\n",
        "indcs = np.concatenate((train_indcs, eval_indcs))\n",
        "try:\n",
        "    test_all = 0\n",
        "    test_correct = 0\n",
        "    for ti in test_indcs:\n",
        "        print(f'======================================= Test {ti} ===================================')\n",
        "        _, __ = evaluate(model, graph_list[ti])\n",
        "        print((_, __))\n",
        "        test_correct += _\n",
        "        test_all += __\n",
        "        all = 0\n",
        "        correct = 0\n",
        "        loss = 0\n",
        "        indcs = np.concatenate((indcs, [ti]))\n",
        "        for idx in indcs:\n",
        "            graph = graph_list[idx]\n",
        "            _, __, ___ = train(model, graph, optimizer, criterion)\n",
        "            loss += _\n",
        "            correct += __\n",
        "            all += ___\n",
        "        print(f'Loss: {loss}, Train Acc: {correct / all: .3f}')\n",
        "        loss_list.append(loss)\n",
        "        train_acc_list.append(correct / all)\n",
        "        home_p_dict_list.append(model.h_p_dict)\n",
        "        home_p_strength_list.append(model.h_p_strength.detach().cpu())\n",
        "\n",
        "    print(f'Test Accuracy: {test_correct / test_all: .3f}')\n",
        "    \n",
        "    torch.save(model, 'temp/model.torch')\n",
        "    with open('temp/losses_lists.list', 'wb') as p_file:\n",
        "        pickle.dump((loss_list, train_acc_list, eval_acc_list), p_file)\n",
        "    print('Model Saved!')\n",
        "except KeyboardInterrupt:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dXi7h95_GvUu",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "model = torch.load('Regular/model.torch')\n",
        "print(model)\n",
        "with open('Regular/losses_lists.list', 'rb') as p_file:\n",
        "      loss_list, train_acc_list, eval_acc_list = pickle.load(p_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O85CTGaRdJAL",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "fig, ax = plt.subplots()\n",
        "x = np.arange(len(loss_list))\n",
        "y = np.array(loss_list)\n",
        "ax.plot(x, y)\n",
        "ax.set_title('Loss Over Time')\n",
        "ax.set_xlabel('Epoch')\n",
        "ax.set_ylabel('Loss')\n",
        "fig.set_size_inches((15,10))\n",
        "fig.set_facecolor('w')\n",
        "fig.savefig('Regular/Loss.png', dpi=300)\n",
        "#@title\n",
        "fig, ax = plt.subplots()\n",
        "x = np.arange(len(train_acc_list))\n",
        "y = np.array(train_acc_list)*100\n",
        "y2 = np.array(eval_acc_list)*100\n",
        "ax.plot(x, y, x, y2)\n",
        "ax.set_title('Accuracy Over Time')\n",
        "ax.set_xlabel('Epoch')\n",
        "ax.set_ylabel('Accuracy')\n",
        "ax.legend(['Train', 'Validation'])\n",
        "fig.set_size_inches((15,10))\n",
        "fig.set_facecolor('w')\n",
        "fig.savefig('Regular/Accuracy.png', dpi=300)\n",
        "#@title\n",
        "PStrength_df = pd.read_json('Vec2_25Players/Player_Strength.json', encoding='latin-1', orient='index')\n",
        "#@title\n",
        "home_p_strength_list[0].device\n",
        "#@title\n",
        "x = torch.stack(home_p_strength_list)[:,-2,:][:,0]\n",
        "y = torch.stack(home_p_strength_list)[:,-2,:][:,1]\n",
        "\n",
        "z = PStrength_df.loc['Kemy Agustien'].to_numpy()\n",
        "w = model.embed(torch.tensor(entities['Kemy Agustien']).to(Globals.DEVICE.value)).detach().cpu()\n",
        "n = range(torch.stack(home_p_strength_list)[:,-2,:][:,0].shape[0])\n",
        "fig, ax = plt.subplots()\n",
        "ax.scatter(x, y, s=80)\n",
        "ax.scatter(z[0], z[1])\n",
        "ax.scatter(w[0], w[1])\n",
        "\n",
        "# z2 = PStrength_df.loc['Ricardo Fuller'].to_numpy()\n",
        "# w2 = model.embed(torch.tensor(entities['Ricardo Fuller']).to(Globals.DEVICE.value)).detach().cpu()\n",
        "# x2 = torch.stack(home_p_strength_list)[:,2,:][:,0]\n",
        "# y2 = torch.stack(home_p_strength_list)[:,2,:][:,1]\n",
        "# ax.scatter(x2, y2, s=80)\n",
        "# ax.scatter(z2[0], z2[1])\n",
        "# ax.scatter(w2[0], w2[1])\n",
        "\n",
        "\n",
        "z2 = PStrength_df.loc['Davide Santon'].to_numpy()\n",
        "w2 = model.embed(torch.tensor(entities['Davide Santon']).to(Globals.DEVICE.value)).detach().cpu()\n",
        "x2 = torch.stack(home_p_strength_list)[:,-1,:][:,0]\n",
        "y2 = torch.stack(home_p_strength_list)[:,-1,:][:,1]\n",
        "ax.scatter(x2, y2, s=80)\n",
        "ax.scatter(z2[0], z2[1])\n",
        "ax.scatter(w2[0], w2[1])\n",
        "\n",
        "fig.set_size_inches(20,10)\n",
        "for i, txt in enumerate(n):\n",
        "    ax.annotate(txt, (x[i], y[i]), fontsize= 12)\n",
        "for i, txt in enumerate(n):\n",
        "    ax.annotate(txt, (x2[i], y2[i]), fontsize= 12)\n",
        "ax.annotate('z', (z[0], z[1]), fontsize= 12)\n",
        "ax.annotate('w', (w[0], w[1]), fontsize= 12)\n",
        "ax.annotate('z2', (z2[0], z2[1]), fontsize= 12)\n",
        "ax.annotate('w2', (w2[0], w2[1]), fontsize= 12)\n",
        "#@title\n",
        "torch.stack(home_p_strength_list)[:,1,:]\n",
        "#@title\n",
        "entities['Samir Nasri']\n",
        "#@title\n",
        "model.embed(torch.tensor([166]).to(Globals.DEVICE.value))\n",
        "#@title\n",
        "home_p_dict_list"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "SP_Regular.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1a5e42cf33534a46bdc3a3982f2b8bcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b0febd66318b436997e921de98e3edcd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8d71a47bf3664dd5881bcdc8f6631941",
              "IPY_MODEL_33221a739510430c95f3c85e3512a662",
              "IPY_MODEL_fde66ef1705a454087abe571757a48ce"
            ]
          }
        },
        "b0febd66318b436997e921de98e3edcd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8d71a47bf3664dd5881bcdc8f6631941": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1f2b0c1d64a349efa485b2e4ad3df112",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b34cefe8f61640fbb1da4e7b22589056"
          }
        },
        "33221a739510430c95f3c85e3512a662": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b2cbbcfd665242a598f18d2e1ceb40ac",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 320,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 320,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8f162ea179d7460cb04c5fa4ae3cbfe0"
          }
        },
        "fde66ef1705a454087abe571757a48ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5130e0d1ef7f4b19805c2a129b28b85e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 320/320 [33:15&lt;00:00,  6.22s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_12f92a7d5f2b4d7d9b1cd50fa5379a7f"
          }
        },
        "1f2b0c1d64a349efa485b2e4ad3df112": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b34cefe8f61640fbb1da4e7b22589056": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b2cbbcfd665242a598f18d2e1ceb40ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8f162ea179d7460cb04c5fa4ae3cbfe0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5130e0d1ef7f4b19805c2a129b28b85e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "12f92a7d5f2b4d7d9b1cd50fa5379a7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}